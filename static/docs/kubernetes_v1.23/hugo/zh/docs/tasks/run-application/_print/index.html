<!doctype html>
<html lang="zh" class="no-js">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    
<meta name="ROBOTS" content="NOINDEX, NOFOLLOW">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-36037335-10"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-36037335-10');
</script>


<link rel="alternate" hreflang="en" href="http://localhost:1313/docs/tasks/run-application/">
<link rel="alternate" hreflang="ko" href="http://localhost:1313/ko/docs/tasks/run-application/">
<link rel="alternate" hreflang="ja" href="http://localhost:1313/ja/docs/tasks/run-application/">
<link rel="alternate" hreflang="fr" href="http://localhost:1313/fr/docs/tasks/run-application/">
<link rel="alternate" hreflang="de" href="http://localhost:1313/de/docs/tasks/run-application/">
<link rel="alternate" hreflang="es" href="http://localhost:1313/es/docs/tasks/run-application/">
<link rel="alternate" hreflang="id" href="http://localhost:1313/id/docs/tasks/run-application/">

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.87.0" />
<link rel="canonical" type="text/html" href="http://localhost:1313/zh/docs/tasks/run-application/">
<link rel="shortcut icon" type="image/png" href="/images/favicon.png">
<link rel="apple-touch-icon" href="/favicons/apple-touch-icon-180x180.png" sizes="180x180">
<link rel="manifest" href="/manifest.webmanifest">
<link rel="apple-touch-icon" href="/images/kubernetes-192x192.png">
<title>运行应用 | Kubernetes</title><meta property="og:title" content="运行应用" />
<meta property="og:description" content="运行和管理无状态和有状态的应用程序。" />
<meta property="og:type" content="website" />
<meta property="og:url" content="http://localhost:1313/zh/docs/tasks/run-application/" /><meta property="og:site_name" content="Kubernetes" />

<meta itemprop="name" content="运行应用">
<meta itemprop="description" content="运行和管理无状态和有状态的应用程序。"><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="运行应用"/>
<meta name="twitter:description" content="运行和管理无状态和有状态的应用程序。"/>






<link href="/scss/main.css" rel="stylesheet">


<script
  src="/js/jquery-3.3.1.min.js"
  integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
  crossorigin="anonymous"></script>





<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "url": "https://kubernetes.io",
    "logo": "https://kubernetes.io/images/favicon.png",
    "potentialAction": {
      "@type": "SearchAction",
      "target": "http://localhost:1313/search/?q={search_term_string}",
      "query-input": "required name=search_term_string"
    }

  }
</script>
<meta name="theme-color" content="#326ce5">




<link rel="stylesheet" href="/css/feature-states.css">



<meta name="description" content="运行和管理无状态和有状态的应用程序。">
<meta property="og:description" content="运行和管理无状态和有状态的应用程序。">
<meta name="twitter:description" content="运行和管理无状态和有状态的应用程序。">
<meta property="og:url" content="http://localhost:1313/zh/docs/tasks/run-application/">
<meta property="og:title" content="运行应用">
<meta name="twitter:title" content="运行应用">
<meta name="twitter:image" content="https://kubernetes.io/images/favicon.png" />

<meta name="twitter:image:alt" content="Kubernetes">

<meta property="og:image" content="/images/kubernetes-horizontal-color.png">

<meta property="og:type" content="article">

<script src="/js/script.js"></script>


  </head>
  <body class="td-section">
    <header>
      
<nav class="js-navbar-scroll navbar navbar-expand navbar-dark  flex-column flex-md-row td-navbar" data-auto-burger="primary">
        <a class="navbar-brand" href="/zh/"></a>
	<div class="td-navbar-nav-scroll ml-md-auto" id="main_navbar">
		
		<ul class="navbar-nav mt-2 mt-lg-0">
			
			
			
			
			<li class="nav-item mr-2 mb-lg-0">
				
				<a class="nav-link active" href="/zh/docs/" >文档</a>
			</li>
			
			
			
			<li class="nav-item mr-2 mb-lg-0">
				
				<a class="nav-link" href="/zh/blog/" >Kubernetes 博客</a>
			</li>
			
			
			
			<li class="nav-item mr-2 mb-lg-0">
				
				<a class="nav-link" href="/zh/training/" >培训</a>
			</li>
			
			
			
			<li class="nav-item mr-2 mb-lg-0">
				
				<a class="nav-link" href="/zh/partners/" >合作伙伴</a>
			</li>
			
			
			
			<li class="nav-item mr-2 mb-lg-0">
				
				<a class="nav-link" href="/zh/community/" >社区</a>
			</li>
			
			
			
			<li class="nav-item mr-2 mb-lg-0">
				
				<a class="nav-link" href="/zh/case-studies/" >案例分析</a>
			</li>
			
			
			
			<li class="nav-item dropdown">
				<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
	Versions
</a>
<div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdownMenuLink">
	
	<a class="dropdown-item" href="/releases">Release Information</a>
	
	<a class="dropdown-item" href="https://kubernetes.io/zh/docs/tasks/run-application/">v1.23</a>
	
	<a class="dropdown-item" href="https://v1-22.docs.kubernetes.io/zh/docs/tasks/run-application/">v1.22</a>
	
	<a class="dropdown-item" href="https://v1-21.docs.kubernetes.io/zh/docs/tasks/run-application/">v1.21</a>
	
	<a class="dropdown-item" href="https://v1-20.docs.kubernetes.io/zh/docs/tasks/run-application/">v1.20</a>
	
	<a class="dropdown-item" href="https://v1-19.docs.kubernetes.io/zh/docs/tasks/run-application/">v1.19</a>
	
</div>
			</li>
			
			
			<li class="nav-item dropdown">
				

<a class="nav-link dropdown-toggle" href="#" id="navbarDropdownMenuLink" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
	中文 Chinese
</a>
<div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdownMenuLink">
	
	<a class="dropdown-item" href="/docs/tasks/run-application/">English</a>
	
	<a class="dropdown-item" href="/ko/docs/tasks/run-application/">한국어 Korean</a>
	
	<a class="dropdown-item" href="/ja/docs/tasks/run-application/">日本語 Japanese</a>
	
	<a class="dropdown-item" href="/fr/docs/tasks/run-application/">Français</a>
	
	<a class="dropdown-item" href="/de/docs/tasks/run-application/">Deutsch</a>
	
	<a class="dropdown-item" href="/es/docs/tasks/run-application/">Español</a>
	
	<a class="dropdown-item" href="/id/docs/tasks/run-application/">Bahasa Indonesia</a>
	
</div>

			</li>
			
		</ul>
	</div>
	<button id="hamburger" onclick="kub.toggleMenu()" data-auto-burger-exclude><div></div></button>
</nav>
    </header>
    <div class="container-fluid td-outer">
      <div class="td-main">
        <div class="row flex-xl-nowrap">
          <main class="col-12 col-md-9 col-xl-8 pl-md-5" role="main">
            




<div class="td-content">
<div class="pageinfo pageinfo-primary d-print-none">
<p>
这是本节的多页打印视图。
<a href="#" onclick="print();return false;">点击此处打印</a>.
</p><p>
<a href="/zh/docs/tasks/run-application/">返回本页常规视图</a>.
</p>
</div>



<h1 class="title">运行应用</h1>
<div class="lead">运行和管理无状态和有状态的应用程序。</div>




    <ul>
    
  
  
  
  

  
    
    
	
<li>1: <a href="#pg-790ea02857492b3a822e981e93e3a98b">使用 Deployment 运行一个无状态应用</a></li>


    
  
    
    
	
<li>2: <a href="#pg-43398a6f5dc7ce19df59f5f4c2e7922d">运行一个单实例有状态应用</a></li>


    
  
    
    
	
<li>3: <a href="#pg-95b3d561509c573e53bec2368264cf6a">运行一个有状态的应用程序</a></li>


    
  
    
    
	
<li>4: <a href="#pg-c43537b0ee1da992ecb7488f87e6c934">删除 StatefulSet</a></li>


    
  
    
    
	
<li>5: <a href="#pg-f5f2f7a74377a9d45325c5253353fa8f">强制删除 StatefulSet 中的 Pods</a></li>


    
  
    
    
	
<li>6: <a href="#pg-0c0bb1bd76d2a9069e50e2cec6d20c2a">Pod 水平自动扩缩</a></li>


    
  
    
    
	
<li>7: <a href="#pg-8138226ce9660ac8e3e82ff86fff8ad2">Horizontal Pod Autoscaler 演练</a></li>


    
  
    
    
	
<li>8: <a href="#pg-fbe2744f00d1aa4df4cdf4eea6a082d4">为应用程序设置干扰预算（Disruption Budget）</a></li>


    
  
    
    
	
<li>9: <a href="#pg-52cd10ee3fc7c74a6c31043a2d489878">从 Pod 中访问 Kubernetes API</a></li>


    
  
    
    
	
<li>10: <a href="#pg-7a9b5779e228083ba3fdeaf414fe704e">扩缩 StatefulSet</a></li>


    
  

    </ul>


<div class="content">
      
</div>
</div>


  
  
  
  

  
  

  
    
    
	
    

<div class="td-content" style="">
    
	<h1 id="pg-790ea02857492b3a822e981e93e3a98b">1 - 使用 Deployment 运行一个无状态应用</h1>
    
	<!-- overview -->
<!--
This page shows how to run an application using a Kubernetes Deployment object.
-->
<p>本文介绍如何通过 Kubernetes Deployment 对象去运行一个应用.</p>
<h2 id="objectives">Objectives</h2>
<!--
* Create an nginx deployment.
* Use kubectl to list information about the deployment.
* Update the deployment.
-->
<ul>
<li>创建一个 nginx Deployment.</li>
<li>使用 kubectl 列举关于 Deployment 的信息.</li>
<li>更新 Deployment。</li>
</ul>
<h2 id="before-you-begin">Before you begin</h2>
<p><p>你必须拥有一个 Kubernetes 的集群，同时你的 Kubernetes 集群必须带有 kubectl 命令行工具。
建议在至少有两个节点的集群上运行本教程，且这些节点不作为控制平面主机。
如果你还没有集群，你可以通过 <a href="https://minikube.sigs.k8s.io/docs/tutorials/multi_node/">Minikube</a>
构建一个你自己的集群，或者你可以使用下面任意一个 Kubernetes 工具构建：</p>
<!--
You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. It is recommended to run this tutorial on a cluster with at least two nodes that are not acting as control plane hosts. If you do not already have a
cluster, you can create one by using
[minikube](https://minikube.sigs.k8s.io/docs/tutorials/multi_node/)
or you can use one of these Kubernetes playgrounds:
-->
<ul>
<li><a href="https://www.katacoda.com/courses/kubernetes/playground">Katacoda</a></li>
<li><a href="http://labs.play-with-k8s.com/">玩转 Kubernetes</a></li>
</ul>
 

Your Kubernetes server must be at or later than version v1.9.
 To check the version, enter <code>kubectl version</code>.
</p>
<!-- lessoncontent -->
<!--
## Creating and exploring an nginx deployment

You can run an application by creating a Kubernetes Deployment object, and you
can describe a Deployment in a YAML file. For example, this YAML file describes
a Deployment that runs the nginx:1.14.2 Docker image:
-->
<h2 id="创建并了解一个-nginx-deployment">创建并了解一个 nginx Deployment</h2>
<p>你可以通过创建一个 Kubernetes Deployment 对象来运行一个应用, 且你可以在一个
YAML 文件中描述 Deployment。例如, 下面这个 YAML 文件描述了一个运行 nginx:1.14.2
Docker 镜像的 Deployment：</p>


 













<div class="highlight">
    <div class="copy-code-icon" style="text-align:right">
    <a href="https://raw.githubusercontent.com/kubernetes/website/main/content/zh/examples/application/deployment.yaml" download="application/deployment.yaml"><code>application/deployment.yaml</code>
    </a>
    <img src="/images/copycode.svg" style="max-height:24px; cursor: pointer" onclick="copyCode('application-deployment-yaml')" title="Copy application/deployment.yaml to clipboard">
    </img>
    </div>
    <div class="includecode" id="application-deployment-yaml">
    <div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>apps/v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Deployment<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>nginx-deployment<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">matchLabels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">replicas</span>:<span style="color:#bbb"> </span><span style="color:#666">2</span><span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># tells deployment to run 2 pods matching the template</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">template</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">containers</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">image</span>:<span style="color:#bbb"> </span>nginx:1.14.2<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">ports</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">containerPort</span>:<span style="color:#bbb"> </span><span style="color:#666">80</span><span style="color:#bbb">
</span></code></pre></div>
    </div>
</div>


<!--
1. Create a Deployment based on the YAML file:
-->
<ol>
<li>
<p>通过 YAML 文件创建一个 Deployment：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl apply -f https://k8s.io/examples/application/deployment.yaml
</code></pre></div></li>
</ol>
<!--
1. Display information about the Deployment:
-->
<ol start="2">
<li>
<p>显示 Deployment 相关信息：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl describe deployment nginx-deployment
</code></pre></div><!-- 
The output is similar to this:
-->
<p>输出类似于这样：</p>
<pre><code>Name:     nginx-deployment
Namespace:    default
CreationTimestamp:  Tue, 30 Aug 2016 18:11:37 -0700
Labels:     app=nginx
Annotations:    deployment.kubernetes.io/revision=1
Selector:   app=nginx
Replicas:   2 desired | 2 updated | 2 total | 2 available | 0 unavailable
StrategyType:   RollingUpdate
MinReadySeconds:  0
RollingUpdateStrategy:  1 max unavailable, 1 max surge
Pod Template:
  Labels:       app=nginx
  Containers:
   nginx:
    Image:              nginx:1.7.9
    Port:               80/TCP
    Environment:        &lt;none&gt;
    Mounts:             &lt;none&gt;
  Volumes:              &lt;none&gt;
Conditions:
  Type          Status  Reason
  ----          ------  ------
  Available     True    MinimumReplicasAvailable
  Progressing   True    NewReplicaSetAvailable
OldReplicaSets:   &lt;none&gt;
NewReplicaSet:    nginx-deployment-1771418926 (2/2 replicas created)
No events.
</code></pre></li>
</ol>
<!--
1. List the Pods created by the deployment:
-->
<ol start="3">
<li>
<p>列出 Deployment 创建的 Pods：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pods -l <span style="color:#b8860b">app</span><span style="color:#666">=</span>nginx
</code></pre></div><!--
The output is similar to this:
-->
<p>输出类似于这样：</p>
<pre><code>NAME                                READY     STATUS    RESTARTS   AGE
nginx-deployment-1771418926-7o5ns   1/1       Running   0          16h
nginx-deployment-1771418926-r18az   1/1       Running   0          16h
</code></pre></li>
</ol>
<!--
1. Display information about a Pod:
-->
<ol start="4">
<li>
<p>展示某一个 Pod 信息：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl describe pod &lt;pod-name&gt;
</code></pre></div><!--
where `<pod-name>` is the name of one of your Pods.
-->
<p>这里的 <code>&lt;pod-name&gt;</code> 是某一 Pod 的名称。</p>
</li>
</ol>
<!--
## Updating the deployment

You can update the deployment by applying a new YAML file. This YAML file
specifies that the deployment should be updated to use nginx 1.16.1.
-->
<h2 id="更新-deployment">更新 Deployment</h2>
<p>你可以通过更新一个新的 YAML 文件来更新 Deployment。下面的 YAML 文件指定该
Deployment 镜像更新为 nginx 1.16.1。</p>


 













<div class="highlight">
    <div class="copy-code-icon" style="text-align:right">
    <a href="https://raw.githubusercontent.com/kubernetes/website/main/content/zh/examples/application/deployment-update.yaml" download="application/deployment-update.yaml"><code>application/deployment-update.yaml</code>
    </a>
    <img src="/images/copycode.svg" style="max-height:24px; cursor: pointer" onclick="copyCode('application-deployment-update-yaml')" title="Copy application/deployment-update.yaml to clipboard">
    </img>
    </div>
    <div class="includecode" id="application-deployment-update-yaml">
    <div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>apps/v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Deployment<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>nginx-deployment<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">matchLabels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">replicas</span>:<span style="color:#bbb"> </span><span style="color:#666">2</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">template</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">containers</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">image</span>:<span style="color:#bbb"> </span>nginx:1.16.1<span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># Update the version of nginx from 1.14.2 to 1.16.1</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">ports</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">containerPort</span>:<span style="color:#bbb"> </span><span style="color:#666">80</span><span style="color:#bbb">
</span></code></pre></div>
    </div>
</div>


<!--
1. Apply the new YAML file:
-->
<ol>
<li>
<p>应用新的 YAML：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl apply -f https://k8s.io/examples/application/deployment-update.yaml
</code></pre></div></li>
</ol>
<!--
1. Watch the deployment create pods with new names and delete the old pods:
-->
<ol start="2">
<li>
<p>查看该 Deployment 以新的名称创建 Pods 同时删除旧的 Pods：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pods -l <span style="color:#b8860b">app</span><span style="color:#666">=</span>nginx
</code></pre></div></li>
</ol>
<!--
## Scaling the application by increasing the replica count

You can increase the number of Pods in your Deployment by applying a new YAML
file. This YAML file sets `replicas` to 4, which specifies that the Deployment
should have four Pods:
-->
<h2 id="通过增加副本数来扩缩应用">通过增加副本数来扩缩应用</h2>
<p>你可以通过应用新的 YAML 文件来增加 Deployment 中 Pods 的数量。
下面的 YAML 文件将 <code>replicas</code> 设置为 4，指定该 Deployment 应有 4 个 Pods：</p>


 













<div class="highlight">
    <div class="copy-code-icon" style="text-align:right">
    <a href="https://raw.githubusercontent.com/kubernetes/website/main/content/zh/examples/application/deployment-scale.yaml" download="application/deployment-scale.yaml"><code>application/deployment-scale.yaml</code>
    </a>
    <img src="/images/copycode.svg" style="max-height:24px; cursor: pointer" onclick="copyCode('application-deployment-scale-yaml')" title="Copy application/deployment-scale.yaml to clipboard">
    </img>
    </div>
    <div class="includecode" id="application-deployment-scale-yaml">
    <div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>apps/v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Deployment<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>nginx-deployment<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">matchLabels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">replicas</span>:<span style="color:#bbb"> </span><span style="color:#666">4</span><span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># Update the replicas from 2 to 4</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">template</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">containers</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">image</span>:<span style="color:#bbb"> </span>nginx:1.14.2<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">ports</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">containerPort</span>:<span style="color:#bbb"> </span><span style="color:#666">80</span><span style="color:#bbb">
</span></code></pre></div>
    </div>
</div>


<!--
1. Apply the new YAML file:
-->
<ol>
<li>
<p>应用新的 YAML 文件：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl apply -f https://k8s.io/examples/application/deployment-scale.yaml
</code></pre></div></li>
</ol>
<!--
1. Verify that the Deployment has four Pods:
-->
<ol start="2">
<li>
<p>验证 Deployment 有 4 个 Pods：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pods -l <span style="color:#b8860b">app</span><span style="color:#666">=</span>nginx
</code></pre></div><!--
The output is similar to this:
-->
<p>输出的结果类似于:</p>
<pre><code>NAME                               READY     STATUS    RESTARTS   AGE
nginx-deployment-148880595-4zdqq   1/1       Running   0          25s
nginx-deployment-148880595-6zgi1   1/1       Running   0          25s
nginx-deployment-148880595-fxcez   1/1       Running   0          2m
nginx-deployment-148880595-rwovn   1/1       Running   0          2m
</code></pre></li>
</ol>
<!--
## Deleting a deployment

Delete the deployment by name:
-->
<h2 id="删除-deployment">删除 Deployment</h2>
<p>基于名称删除 Deployment：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl delete deployment nginx-deployment
</code></pre></div><!--
## ReplicationControllers -- the Old Way

The preferred way to create a replicated application is to use a Deployment,
which in turn uses a ReplicaSet. Before the Deployment and ReplicaSet were
added to Kubernetes, replicated applications were configured using a
[ReplicationController](/docs/concepts/workloads/controllers/replicationcontroller/).
-->
<h2 id="replicationcontrollers-旧的方式">ReplicationControllers -- 旧的方式</h2>
<p>创建一个多副本应用首选方法是使用 Deployment，Deployment 内部使用 ReplicaSet。
在 Deployment 和 ReplicaSet 被引入到 Kubernetes 之前，多副本应用通过
<a href="/zh/docs/concepts/workloads/controllers/replicationcontroller/">ReplicationController</a>
来配置。</p>
<h2 id="what-s-next">What's next</h2>
<!--
* Learn more about [Deployment objects](/docs/concepts/workloads/controllers/deployment/).
-->
<ul>
<li>进一步了解 <a href="/zh/docs/concepts/workloads/controllers/deployment/">Deployment 对象</a>。</li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-43398a6f5dc7ce19df59f5f4c2e7922d">2 - 运行一个单实例有状态应用</h1>
    
	<!-- overview -->
<!--
This page shows you how to run a single-instance stateful application
in Kubernetes using a PersistentVolume and a Deployment. The
application is MySQL.
-->
<p>本文介绍在 Kubernetes 中如何使用 PersistentVolume 和 Deployment 运行一个单实例有状态应用。该应用是 MySQL.</p>
<h2 id="objectives">Objectives</h2>
<!--
* Create a PersistentVolume referencing a disk in your environment.
* Create a MySQL Deployment.
* Expose MySQL to other pods in the cluster at a known DNS name.
-->
<ul>
<li>在你的环境中创建一个引用磁盘的 PersistentVolume</li>
<li>创建一个 MySQL Deployment.</li>
<li>在集群内以一个已知的 DNS 名称将 MySQL 暴露给其他 Pod</li>
</ul>
<h2 id="before-you-begin">Before you begin</h2>
<ul>
<li><p>你必须拥有一个 Kubernetes 的集群，同时你的 Kubernetes 集群必须带有 kubectl 命令行工具。
建议在至少有两个节点的集群上运行本教程，且这些节点不作为控制平面主机。
如果你还没有集群，你可以通过 <a href="https://minikube.sigs.k8s.io/docs/tutorials/multi_node/">Minikube</a>
构建一个你自己的集群，或者你可以使用下面任意一个 Kubernetes 工具构建：</p>
<!--
You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. It is recommended to run this tutorial on a cluster with at least two nodes that are not acting as control plane hosts. If you do not already have a
cluster, you can create one by using
[minikube](https://minikube.sigs.k8s.io/docs/tutorials/multi_node/)
or you can use one of these Kubernetes playgrounds:
-->
<ul>
<li><a href="https://www.katacoda.com/courses/kubernetes/playground">Katacoda</a></li>
<li><a href="http://labs.play-with-k8s.com/">玩转 Kubernetes</a></li>
</ul>
 
 To check the version, enter <code>kubectl version</code>.
</li>
<li><p>你需要有一个带有默认 <a href="/zh/docs/concepts/storage/storage-classes/">StorageClass</a>的
<a href="/zh/docs/concepts/storage/dynamic-provisioning/">动态 PersistentVolume 供应程序</a>，
或者自己<a href="/zh/docs/concepts/storage/persistent-volumes/#provisioning">静态的提供 PersistentVolume</a>
来满足这里使用的 <a href="/zh/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims">PersistentVolumeClaim</a>。</p>
<!--
You need to either have a [dynamic PersistentVolume provisioner](/docs/concepts/storage/dynamic-provisioning/) with a default
[StorageClass](/docs/concepts/storage/storage-classes/),
or [statically provision PersistentVolumes](/docs/concepts/storage/persistent-volumes/#provisioning)
yourself to satisfy the [PersistentVolumeClaims](/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims)
used here.
-->
</li>
</ul>
<!-- lessoncontent -->
<h2 id="deploy-mysql">部署 MySQL  </h2>
<!--
You can run a stateful application by creating a Kubernetes Deployment
and connecting it to an existing PersistentVolume using a
PersistentVolumeClaim.  For example, this YAML file describes a
Deployment that runs MySQL and references the PersistentVolumeClaim. The file
defines a volume mount for /var/lib/mysql, and then creates a
PersistentVolumeClaim that looks for a 20G volume. This claim is
satisfied by any existing volume that meets the requirements,
or by a dynamic provisioner.
-->
<p>你可以通过创建一个 Kubernetes Deployment 并使用 PersistentVolumeClaim 将其连接到
某已有的 PV 卷来运行一个有状态的应用。
例如，这里的 YAML 描述的是一个运行 MySQL 的 Deployment，其中引用了 PVC 申领。
文件为 /var/lib/mysql 定义了加载卷，并创建了一个 PVC 申领，寻找一个 20G 大小的卷。
该申领可以通过现有的满足需求的卷来满足，也可以通过动态供应卷的机制来满足。</p>
<!--
Note: The password is defined in the config yaml, and this is insecure. See
[Kubernetes Secrets](/docs/concepts/configuration/secret/)
for a secure solution.
-->
<p>注意：在配置的 YAML 文件中定义密码的做法是不安全的。具体安全解决方案请参考
<a href="/zh/docs/concepts/configuration/secret/">Kubernetes Secrets</a>.</p>
<p>

 













<div class="highlight">
    <div class="copy-code-icon" style="text-align:right">
    <a href="https://raw.githubusercontent.com/kubernetes/website/main/content/zh/examples/application/mysql/mysql-deployment.yaml" download="application/mysql/mysql-deployment.yaml"><code>application/mysql/mysql-deployment.yaml</code>
    </a>
    <img src="/images/copycode.svg" style="max-height:24px; cursor: pointer" onclick="copyCode('application-mysql-mysql-deployment-yaml')" title="Copy application/mysql/mysql-deployment.yaml to clipboard">
    </img>
    </div>
    <div class="includecode" id="application-mysql-mysql-deployment-yaml">
    <div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Service<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">ports</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">port</span>:<span style="color:#bbb"> </span><span style="color:#666">3306</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">clusterIP</span>:<span style="color:#bbb"> </span>None<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#00f;font-weight:bold">---</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>apps/v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Deployment<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">matchLabels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">strategy</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Recreate<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">template</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">containers</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">image</span>:<span style="color:#bbb"> </span>mysql:5.6<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">env</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#080;font-style:italic"># Use secret in real usage</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>MYSQL_ROOT_PASSWORD<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">value</span>:<span style="color:#bbb"> </span>password<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">ports</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">containerPort</span>:<span style="color:#bbb"> </span><span style="color:#666">3306</span><span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">volumeMounts</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>mysql-persistent-storage<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">mountPath</span>:<span style="color:#bbb"> </span>/var/lib/mysql<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">volumes</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>mysql-persistent-storage<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">persistentVolumeClaim</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">claimName</span>:<span style="color:#bbb"> </span>mysql-pv-claim<span style="color:#bbb">
</span></code></pre></div>
    </div>
</div>




 













<div class="highlight">
    <div class="copy-code-icon" style="text-align:right">
    <a href="https://raw.githubusercontent.com/kubernetes/website/main/content/zh/examples/application/mysql/mysql-pv.yaml" download="application/mysql/mysql-pv.yaml"><code>application/mysql/mysql-pv.yaml</code>
    </a>
    <img src="/images/copycode.svg" style="max-height:24px; cursor: pointer" onclick="copyCode('application-mysql-mysql-pv-yaml')" title="Copy application/mysql/mysql-pv.yaml to clipboard">
    </img>
    </div>
    <div class="includecode" id="application-mysql-mysql-pv-yaml">
    <div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>PersistentVolume<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>mysql-pv-volume<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>local<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">storageClassName</span>:<span style="color:#bbb"> </span>manual<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">capacity</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">storage</span>:<span style="color:#bbb"> </span>20Gi<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">accessModes</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span>- ReadWriteOnce<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">hostPath</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">path</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;/mnt/data&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#00f;font-weight:bold">---</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>PersistentVolumeClaim<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>mysql-pv-claim<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">storageClassName</span>:<span style="color:#bbb"> </span>manual<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">accessModes</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span>- ReadWriteOnce<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">requests</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">storage</span>:<span style="color:#bbb"> </span>20Gi<span style="color:#bbb">
</span></code></pre></div>
    </div>
</div>

</p>
<ol>
<li>
<!--Deploy the PV and PVC of the YAML file-->
<p>部署 YAML 文件中定义的 PV 和 PVC：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl apply -f https://k8s.io/examples/application/mysql/mysql-pv.yaml
</code></pre></div></li>
<li>
<!-- Deploy the contents of the YAML file -->
<p>部署 YAML 文件中定义的 Deployment：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl apply -f https://k8s.io/examples/application/mysql/mysql-deployment.yaml
</code></pre></div></li>
<li>
<!-- Display information about the Deployment -->
<p>展示 Deployment 相关信息:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl describe deployment mysql
</code></pre></div><!--
The output is similar to this:
-->
<p>输出类似于：</p>
<pre><code>Name:                 mysql
Namespace:            default
CreationTimestamp:    Tue, 01 Nov 2016 11:18:45 -0700
Labels:               app=mysql
Annotations:          deployment.kubernetes.io/revision=1
Selector:             app=mysql
Replicas:             1 desired | 1 updated | 1 total | 0 available | 1 unavailable
StrategyType:         Recreate
MinReadySeconds:      0
Pod Template:
  Labels:       app=mysql
  Containers:
   mysql:
    Image:      mysql:5.6
    Port:       3306/TCP
    Environment:
      MYSQL_ROOT_PASSWORD:      password
    Mounts:
      /var/lib/mysql from mysql-persistent-storage (rw)
  Volumes:
   mysql-persistent-storage:
    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
    ClaimName:  mysql-pv-claim
    ReadOnly:   false
    Conditions:
      Type          Status  Reason
      ----          ------  ------
      Available     False   MinimumReplicasUnavailable
      Progressing   True    ReplicaSetUpdated
      OldReplicaSets:       &lt;none&gt;
      NewReplicaSet:        mysql-63082529 (1/1 replicas created)
      Events:
        FirstSeen    LastSeen    Count    From                SubobjectPath    Type        Reason            Message
        ---------    --------    -----    ----                -------------    --------    ------            -------
        33s          33s         1        {deployment-controller }             Normal      ScalingReplicaSet Scaled up replica set mysql-63082529 to 1
</code></pre></li>
<li>
<!-- List the pods created by the Deployment -->
<p>列举出 Deployment 创建的 pods:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pods -l <span style="color:#b8860b">app</span><span style="color:#666">=</span>mysql
</code></pre></div><!--
The output is similar to this:
-->
<p>输出类似于：</p>
<pre><code>NAME                   READY     STATUS    RESTARTS   AGE
mysql-63082529-2z3ki   1/1       Running   0          3m
</code></pre></li>
<li>
<!-- Inspect the PersistentVolumeClaim -->
<p>查看 PersistentVolumeClaim：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl describe pvc mysql-pv-claim
</code></pre></div><!--
The output is similar to this:
-->
<p>输出类似于：</p>
<pre><code>Name:         mysql-pv-claim
Namespace:    default
StorageClass:
Status:       Bound
Volume:       mysql-pv-volume
Labels:       &lt;none&gt;
Annotations:    pv.kubernetes.io/bind-completed=yes
                pv.kubernetes.io/bound-by-controller=yes
Capacity:     20Gi
Access Modes: RWO
Events:       &lt;none&gt;
</code></pre></li>
</ol>
<!--
## Accessing the MySQL instance

The preceding YAML file creates a service that
allows other Pods in the cluster to access the database. The Service option
`clusterIP: None` lets the Service DNS name resolve directly to the
Pod's IP address. This is optimal when you have only one Pod
behind a Service and you don't intend to increase the number of Pods.

Run a MySQL client to connect to the server:
-->
<h2 id="accessing-the-mysql-instance">访问 MySQL 实例  </h2>
<p>前面 YAML 文件中创建了一个允许集群内其他 Pod 访问的数据库服务。该服务中选项
<code>clusterIP: None</code> 让服务 DNS 名称直接解析为 Pod 的 IP 地址。
当在一个服务下只有一个 Pod 并且不打算增加 Pod 的数量这是最好的.</p>
<p>运行 MySQL 客户端以连接到服务器:</p>
<pre><code>kubectl run -it --rm --image=mysql:5.6 --restart=Never mysql-client -- mysql -h mysql -ppassword
</code></pre><!--
This command creates a new Pod in the cluster running a MySQL client
and connects it to the server through the Service. If it connects, you
know your stateful MySQL database is up and running.
-->
<p>此命令在集群内创建一个新的 Pod 并运行 MySQL 客户端，并通过 Service 连接到服务器。
如果连接成功，你就知道有状态的 MySQL 数据库正处于运行状态。</p>
<pre><code>Waiting for pod default/mysql-client-274442439-zyp6i to be running, status is Pending, pod ready: false
If you don't see a command prompt, try pressing enter.

mysql&gt;
</code></pre><!--
## Updating

The image or any other part of the Deployment can be updated as usual
with the `kubectl apply` command. Here are some precautions that are
specific to stateful apps:
-->
<h2 id="updating">更新  </h2>
<p>Deployment 中镜像或其他部分同往常一样可以通过 <code>kubectl apply</code> 命令更新。
以下是特定于有状态应用的一些注意事项:</p>
<!--
* Don't scale the app. This setup is for single-instance apps
  only. The underlying PersistentVolume can only be mounted to one
  Pod. For clustered stateful apps, see the
  [StatefulSet documentation](/docs/concepts/workloads/controllers/statefulset/).
* Use `strategy:` `type: Recreate` in the Deployment configuration
  YAML file. This instructs Kubernetes to _not_ use rolling
  updates. Rolling updates will not work, as you cannot have more than
  one Pod running at a time. The `Recreate` strategy will stop the
  first pod before creating a new one with the updated configuration.
-->
<ul>
<li>不要对应用进行规模扩缩。这里的设置仅适用于单实例应用。下层的 PersistentVolume
仅只能挂载到一个 Pod 上。对于集群级有状态应用，请参考
<a href="/zh/docs/concepts/workloads/controllers/statefulset/">StatefulSet 文档</a>.</li>
<li>在 Deployment 的 YAML 文件中使用 <code>strategy:</code> <code>type: Recreate</code>。
该选项指示 Kubernetes <em>不</em> 使用滚动升级。滚动升级无法工作，因为这里一次不能
运行多个 Pod。在使用更新的配置文件创建新的 Pod 前，<code>Recreate</code> 策略将
保证先停止第一个 Pod。</li>
</ul>
<!--
## Deleting a deployment

Delete the deployed objects by name:
-->
<h2 id="deleting-a-deployment">删除 Deployment   </h2>
<p>通过名称删除部署的对象:</p>
<pre><code>kubectl delete deployment,svc mysql
kubectl delete pvc mysql-pv-claim
kubectl delete pv mysql-pv-volume
</code></pre><!--
If you manually provisioned a PersistentVolume, you also need to manually
delete it, as well as release the underlying resource.
If you used a dynamic provisioner, it automatically deletes the
PersistentVolume when it sees that you deleted the PersistentVolumeClaim.
Some dynamic provisioners (such as those for EBS and PD) also release the
underlying resource upon deleting the PersistentVolume.
-->
<p>如果通过手动的方式供应 PersistentVolume, 那么也需要手动删除它以释放下层资源。
如果是用动态供应方式创建的 PersistentVolume，在删除 PersistentVolumeClaim 后
PersistentVolume 将被自动删除。
一些存储服务（比如 EBS 和 PD）也会在 PersistentVolume 被删除时自动回收下层资源。</p>
<h2 id="what-s-next">What's next</h2>
<!--
* Learn more about [Deployment objects](/docs/concepts/workloads/controllers/deployment/).

* Learn more about [Deploying applications](/docs/tasks/run-application/run-stateless-application-deployment/)

* [kubectl run documentation](/docs/reference/generated/kubectl/kubectl-commands/#run)

* [Volumes](/docs/concepts/storage/volumes/) and [Persistent Volumes](/docs/concepts/storage/persistent-volumes/)
-->
<ul>
<li>
<p>欲进一步了解 Deployment 对象，请参考 <a href="/zh/docs/concepts/workloads/controllers/deployment/">Deployment 对象</a></p>
</li>
<li>
<p>进一步了解<a href="/zh/docs/tasks/run-application/run-stateless-application-deployment/">部署应用</a></p>
</li>
<li>
<p>参阅 <a href="/docs/reference/generated/kubectl/kubectl-commands/#run">kubectl run 文档</a></p>
</li>
<li>
<p>参阅<a href="/zh/docs/concepts/storage/volumes/">卷</a>和<a href="/zh/docs/concepts/storage/persistent-volumes/">持久卷</a></p>
</li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-95b3d561509c573e53bec2368264cf6a">3 - 运行一个有状态的应用程序</h1>
    
	<!--
reviewers:
- enisoc
- erictune
- foxish
- janetkuo
- kow3ns
- smarterclayton
title: Run a Replicated Stateful Application
content_type: tutorial
weight: 30
-->
<!-- overview -->
<!--
This page shows how to run a replicated stateful application using a
[StatefulSet](/docs/concepts/workloads/controllers/statefulset/) controller.
This application is a replicated MySQL database. The example topology has a
single primary server and multiple replicas, using asynchronous row-based
replication.
-->
<p>本页展示如何使用 <a href="/zh/docs/concepts/workloads/controllers/statefulset/">StatefulSet</a>
控制器运行一个有状态的应用程序。此例是多副本的 MySQL 数据库。
示例应用的拓扑结构有一个主服务器和多个副本，使用异步的基于行（Row-Based）
的数据复制。</p>
<!--
**this is not a production configuration**.
In particular, MySQL settings remain on insecure defaults to keep the focus
on general patterns for running stateful applications in Kubernetes.
-->
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> <strong>这不是生产环境下配置</strong>。
尤其注意，MySQL 设置都使用的是不安全的默认值，这是因为我们想把重点放在 Kubernetes
中运行有状态应用程序的一般模式上。
</div>
<h2 id="before-you-begin">Before you begin</h2>
<ul>
<li><p>你必须拥有一个 Kubernetes 的集群，同时你的 Kubernetes 集群必须带有 kubectl 命令行工具。
建议在至少有两个节点的集群上运行本教程，且这些节点不作为控制平面主机。
如果你还没有集群，你可以通过 <a href="https://minikube.sigs.k8s.io/docs/tutorials/multi_node/">Minikube</a>
构建一个你自己的集群，或者你可以使用下面任意一个 Kubernetes 工具构建：</p>
<!--
You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. It is recommended to run this tutorial on a cluster with at least two nodes that are not acting as control plane hosts. If you do not already have a
cluster, you can create one by using
[minikube](https://minikube.sigs.k8s.io/docs/tutorials/multi_node/)
or you can use one of these Kubernetes playgrounds:
-->
<ul>
<li><a href="https://www.katacoda.com/courses/kubernetes/playground">Katacoda</a></li>
<li><a href="http://labs.play-with-k8s.com/">玩转 Kubernetes</a></li>
</ul>
 
 To check the version, enter <code>kubectl version</code>.
</li>
<li><p>你需要有一个带有默认 <a href="/zh/docs/concepts/storage/storage-classes/">StorageClass</a>的
<a href="/zh/docs/concepts/storage/dynamic-provisioning/">动态 PersistentVolume 供应程序</a>，
或者自己<a href="/zh/docs/concepts/storage/persistent-volumes/#provisioning">静态的提供 PersistentVolume</a>
来满足这里使用的 <a href="/zh/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims">PersistentVolumeClaim</a>。</p>
<!--
You need to either have a [dynamic PersistentVolume provisioner](/docs/concepts/storage/dynamic-provisioning/) with a default
[StorageClass](/docs/concepts/storage/storage-classes/),
or [statically provision PersistentVolumes](/docs/concepts/storage/persistent-volumes/#provisioning)
yourself to satisfy the [PersistentVolumeClaims](/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims)
used here.
-->
</li>
</ul>
<!--
* This tutorial assumes you are familiar with
  [PersistentVolumes](/docs/concepts/storage/persistent-volumes/)
  and [StatefulSets](/docs/concepts/workloads/controllers/statefulset/),
  as well as other core concepts like [Pods](/docs/concepts/workloads/pods/),
  [Services](/docs/concepts/services-networking/service/), and
  [ConfigMaps](/docs/tasks/configure-pod-container/configure-pod-configmap/).
* Some familiarity with MySQL helps, but this tutorial aims to present
  general patterns that should be useful for other systems.
* You are using the default namespace or another namespace that does not contain any conflicting objects.
-->
<ul>
<li>本教程假定你熟悉
<a href="/zh/docs/concepts/storage/persistent-volumes/">PersistentVolumes</a>
与 <a href="/zh/docs/concepts/workloads/controllers/statefulset/">StatefulSet</a>,
以及其他核心概念，例如 <a href="/zh/docs/concepts/workloads/pods/">Pod</a>、
<a href="/zh/docs/concepts/services-networking/service/">服务</a> 与
<a href="/zh/docs/tasks/configure-pod-container/configure-pod-configmap/">ConfigMap</a>.</li>
<li>熟悉 MySQL 会有所帮助，但是本教程旨在介绍对其他系统应该有用的常规模式。</li>
<li>您正在使用默认命名空间或不包含任何冲突对象的另一个命名空间。</li>
</ul>
<h2 id="objectives">Objectives</h2>
<!--
* Deploy a replicated MySQL topology with a StatefulSet controller.
* Send MySQL client traffic.
* Observe resistance to downtime.
* Scale the StatefulSet up and down.
-->
<ul>
<li>使用 StatefulSet 控制器部署多副本 MySQL 拓扑架构。</li>
<li>发送 MySQL 客户端请求</li>
<li>观察对宕机的抵抗力</li>
<li>扩缩 StatefulSet 的规模</li>
</ul>
<!-- lessoncontent -->
<!--
## Deploy MySQL

The example MySQL deployment consists of a ConfigMap, two Services,
and a StatefulSet.
-->
<h2 id="deploy-mysql">部署 MySQL </h2>
<p>MySQL 示例部署包含一个 ConfigMap、两个 Service 与一个 StatefulSet。</p>
<h3 id="configmap">ConfigMap</h3>
<!--
Create the ConfigMap from the following YAML configuration file:
-->
<p>使用以下的 YAML 配置文件创建 ConfigMap ：</p>


 













<div class="highlight">
    <div class="copy-code-icon" style="text-align:right">
    <a href="https://raw.githubusercontent.com/kubernetes/website/main/content/zh/examples/application/mysql/mysql-configmap.yaml" download="application/mysql/mysql-configmap.yaml"><code>application/mysql/mysql-configmap.yaml</code>
    </a>
    <img src="/images/copycode.svg" style="max-height:24px; cursor: pointer" onclick="copyCode('application-mysql-mysql-configmap-yaml')" title="Copy application/mysql/mysql-configmap.yaml to clipboard">
    </img>
    </div>
    <div class="includecode" id="application-mysql-mysql-configmap-yaml">
    <div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>ConfigMap<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">data</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">primary.cnf</span>:<span style="color:#bbb"> </span>|<span style="color:#b44;font-style:italic">
</span><span style="color:#b44;font-style:italic">    # Apply this config only on the primary.
</span><span style="color:#b44;font-style:italic">    [mysqld]
</span><span style="color:#b44;font-style:italic">    log-bin
</span><span style="color:#b44;font-style:italic">    datadir=/var/lib/mysql/mysql</span><span style="color:#bbb">    
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">replica.cnf</span>:<span style="color:#bbb"> </span>|<span style="color:#b44;font-style:italic">
</span><span style="color:#b44;font-style:italic">    # Apply this config only on replicas.
</span><span style="color:#b44;font-style:italic">    [mysqld]
</span><span style="color:#b44;font-style:italic">    super-read-only
</span><span style="color:#b44;font-style:italic">    datadir=/var/lib/mysql/mysql</span><span style="color:#bbb">    
</span><span style="color:#bbb">
</span></code></pre></div>
    </div>
</div>


<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl apply -f https://k8s.io/examples/application/mysql/mysql-configmap.yaml
</code></pre></div><!--
This ConfigMap provides `my.cnf` overrides that let you independently control
configuration on the primary MySQL server and replicas.
In this case, you want the primary server to be able to serve replication logs to replicas
and you want repicas to reject any writes that don't come via replication. 
-->
<p>这个 ConfigMap 提供 <code>my.cnf</code> 覆盖设置，使你可以独立控制 MySQL 主服务器和从服务器的配置。
在这里，你希望主服务器能够将复制日志提供给副本服务器，并且希望副本服务器拒绝任何不是通过
复制进行的写操作。</p>
<!--
There's nothing special about the ConfigMap itself that causes different
portions to apply to different Pods.
Each Pod decides which portion to look at as it's initializing,
based on information provided by the StatefulSet controller. 
-->
<p>ConfigMap 本身没有什么特别之处，因而也不会出现不同部分应用于不同的 Pod 的情况。
每个 Pod 都会在初始化时基于 StatefulSet 控制器提供的信息决定要查看的部分。</p>
<!--
### Services 

Create the Services from the following YAML configuration file: 
-->
<h3 id="services">服务 </h3>
<p>使用以下 YAML 配置文件创建服务：</p>


 













<div class="highlight">
    <div class="copy-code-icon" style="text-align:right">
    <a href="https://raw.githubusercontent.com/kubernetes/website/main/content/zh/examples/application/mysql/mysql-services.yaml" download="application/mysql/mysql-services.yaml"><code>application/mysql/mysql-services.yaml</code>
    </a>
    <img src="/images/copycode.svg" style="max-height:24px; cursor: pointer" onclick="copyCode('application-mysql-mysql-services-yaml')" title="Copy application/mysql/mysql-services.yaml to clipboard">
    </img>
    </div>
    <div class="includecode" id="application-mysql-mysql-services-yaml">
    <div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#080;font-style:italic"># Headless service for stable DNS entries of StatefulSet members.</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Service<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">ports</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">port</span>:<span style="color:#bbb"> </span><span style="color:#666">3306</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">clusterIP</span>:<span style="color:#bbb"> </span>None<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#00f;font-weight:bold">---</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#080;font-style:italic"># Client service for connecting to any MySQL instance for reads.</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#080;font-style:italic"># For writes, you must instead connect to the primary: mysql-0.mysql.</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Service<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>mysql-read<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">ports</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">port</span>:<span style="color:#bbb"> </span><span style="color:#666">3306</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span></code></pre></div>
    </div>
</div>


<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl apply -f https://k8s.io/examples/application/mysql/mysql-services.yaml
</code></pre></div><!--
The Headless Service provides a home for the DNS entries that the StatefulSet
controller creates for each Pod that's part of the set.
Because the Headless Service is named `mysql`, the Pods are accessible by
resolving `<pod-name>.mysql` from within any other Pod in the same Kubernetes
cluster and namespace. 
-->
<p>这个无头服务给 StatefulSet 控制器为集合中每个 Pod 创建的 DNS 条目提供了一个宿主。
因为无头服务名为 <code>mysql</code>，所以可以通过在同一 Kubernetes 集群和命名空间中的任何其他 Pod
内解析 <code>&lt;Pod 名称&gt;.mysql</code> 来访问 Pod。</p>
<!--
The Client Service, called `mysql-read`, is a normal Service with its own
cluster IP that distributes connections across all MySQL Pods that report
being Ready. The set of potential endpoints includes the primary MySQL server and all
replicas. 
-->
<p>客户端服务称为 <code>mysql-read</code>，是一种常规服务，具有其自己的集群 IP。
该集群 IP 在报告就绪的所有MySQL Pod 之间分配连接。
可能的端点集合包括 MySQL 主节点和所有副本节点。</p>
<!--
Note that only read queries can use the load-balanced Client Service.
Because there is only one primary MySQL server, clients should connect directly to the
primary MySQL Pod (through its DNS entry within the Headless Service) to execute
writes. 
-->
<p>请注意，只有读查询才能使用负载平衡的客户端服务。
因为只有一个 MySQL 主服务器，所以客户端应直接连接到 MySQL 主服务器 Pod
（通过其在无头服务中的 DNS 条目）以执行写入操作。</p>
<h3 id="statefulset">StatefulSet</h3>
<!--
Finally, create the StatefulSet from the following YAML configuration file: 
-->
<p>最后，使用以下 YAML 配置文件创建 StatefulSet：</p>


 













<div class="highlight">
    <div class="copy-code-icon" style="text-align:right">
    <a href="https://raw.githubusercontent.com/kubernetes/website/main/content/zh/examples/application/mysql/mysql-statefulset.yaml" download="application/mysql/mysql-statefulset.yaml"><code>application/mysql/mysql-statefulset.yaml</code>
    </a>
    <img src="/images/copycode.svg" style="max-height:24px; cursor: pointer" onclick="copyCode('application-mysql-mysql-statefulset-yaml')" title="Copy application/mysql/mysql-statefulset.yaml to clipboard">
    </img>
    </div>
    <div class="includecode" id="application-mysql-mysql-statefulset-yaml">
    <div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>apps/v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>StatefulSet<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">matchLabels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">serviceName</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">replicas</span>:<span style="color:#bbb"> </span><span style="color:#666">3</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">template</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">initContainers</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>init-mysql<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">image</span>:<span style="color:#bbb"> </span>mysql:5.7<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">command</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- bash<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#b44">&#34;-c&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span>- |<span style="color:#b44;font-style:italic">
</span><span style="color:#b44;font-style:italic">          set -ex
</span><span style="color:#b44;font-style:italic">          # 基于 Pod 序号生成 MySQL 服务器的 ID。
</span><span style="color:#b44;font-style:italic">          [[ `hostname` =~ -([0-9]+)$ ]] || exit 1
</span><span style="color:#b44;font-style:italic">          ordinal=${BASH_REMATCH[1]}
</span><span style="color:#b44;font-style:italic">          echo [mysqld] &gt; /mnt/conf.d/server-id.cnf
</span><span style="color:#b44;font-style:italic">          # 添加偏移量以避免使用 server-id=0 这一保留值。
</span><span style="color:#b44;font-style:italic">          echo server-id=$((100 + $ordinal)) &gt;&gt; /mnt/conf.d/server-id.cnf
</span><span style="color:#b44;font-style:italic">          # Copy appropriate conf.d files from config-map to emptyDir.
</span><span style="color:#b44;font-style:italic">          # 将合适的 conf.d 文件从 config-map 复制到 emptyDir。
</span><span style="color:#b44;font-style:italic">          if [[ $ordinal -eq 0 ]]; then
</span><span style="color:#b44;font-style:italic">            cp /mnt/config-map/primary.cnf /mnt/conf.d/
</span><span style="color:#b44;font-style:italic">          else
</span><span style="color:#b44;font-style:italic">            cp /mnt/config-map/replica.cnf /mnt/conf.d/
</span><span style="color:#b44;font-style:italic">          fi</span><span style="color:#bbb">          
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">volumeMounts</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>conf<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">mountPath</span>:<span style="color:#bbb"> </span>/mnt/conf.d<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>config-map<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">mountPath</span>:<span style="color:#bbb"> </span>/mnt/config-map<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>clone-mysql<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">image</span>:<span style="color:#bbb"> </span>gcr.io/google-samples/xtrabackup:1.0<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">command</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- bash<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#b44">&#34;-c&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span>- |<span style="color:#b44;font-style:italic">
</span><span style="color:#b44;font-style:italic">          set -ex
</span><span style="color:#b44;font-style:italic">          # 如果已有数据，则跳过克隆。
</span><span style="color:#b44;font-style:italic">          [[ -d /var/lib/mysql/mysql ]] &amp;&amp; exit 0
</span><span style="color:#b44;font-style:italic">          # 跳过主实例（序号索引 0）的克隆。
</span><span style="color:#b44;font-style:italic">          [[ `hostname` =~ -([0-9]+)$ ]] || exit 1
</span><span style="color:#b44;font-style:italic">          ordinal=${BASH_REMATCH[1]}
</span><span style="color:#b44;font-style:italic">          [[ $ordinal -eq 0 ]] &amp;&amp; exit 0
</span><span style="color:#b44;font-style:italic">          # 从原来的对等节点克隆数据。
</span><span style="color:#b44;font-style:italic">          ncat --recv-only mysql-$(($ordinal-1)).mysql 3307 | xbstream -x -C /var/lib/mysql
</span><span style="color:#b44;font-style:italic">          # 准备备份。
</span><span style="color:#b44;font-style:italic">          xtrabackup --prepare --target-dir=/var/lib/mysql</span><span style="color:#bbb">          
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">volumeMounts</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>data<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">mountPath</span>:<span style="color:#bbb"> </span>/var/lib/mysql<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">subPath</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>conf<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">mountPath</span>:<span style="color:#bbb"> </span>/etc/mysql/conf.d<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">containers</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">image</span>:<span style="color:#bbb"> </span>mysql:5.7<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">env</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>MYSQL_ALLOW_EMPTY_PASSWORD<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">value</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;1&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">ports</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">containerPort</span>:<span style="color:#bbb"> </span><span style="color:#666">3306</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">volumeMounts</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>data<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">mountPath</span>:<span style="color:#bbb"> </span>/var/lib/mysql<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">subPath</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>conf<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">mountPath</span>:<span style="color:#bbb"> </span>/etc/mysql/conf.d<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">requests</span>:<span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">cpu</span>:<span style="color:#bbb"> </span>500m<span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">memory</span>:<span style="color:#bbb"> </span>1Gi<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">livenessProbe</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">exec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">command</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">&#34;mysqladmin&#34;</span>,<span style="color:#bbb"> </span><span style="color:#b44">&#34;ping&#34;</span>]<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">initialDelaySeconds</span>:<span style="color:#bbb"> </span><span style="color:#666">30</span><span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">periodSeconds</span>:<span style="color:#bbb"> </span><span style="color:#666">10</span><span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">timeoutSeconds</span>:<span style="color:#bbb"> </span><span style="color:#666">5</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">readinessProbe</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">exec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#080;font-style:italic"># 检查我们是否可以通过 TCP 执行查询（skip-networking 是关闭的）。</span><span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">command</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">&#34;mysql&#34;</span>,<span style="color:#bbb"> </span><span style="color:#b44">&#34;-h&#34;</span>,<span style="color:#bbb"> </span><span style="color:#b44">&#34;127.0.0.1&#34;</span>,<span style="color:#bbb"> </span><span style="color:#b44">&#34;-e&#34;</span>,<span style="color:#bbb"> </span><span style="color:#b44">&#34;SELECT 1&#34;</span>]<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">initialDelaySeconds</span>:<span style="color:#bbb"> </span><span style="color:#666">5</span><span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">periodSeconds</span>:<span style="color:#bbb"> </span><span style="color:#666">2</span><span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">timeoutSeconds</span>:<span style="color:#bbb"> </span><span style="color:#666">1</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>xtrabackup<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">image</span>:<span style="color:#bbb"> </span>gcr.io/google-samples/xtrabackup:1.0<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">ports</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>xtrabackup<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">containerPort</span>:<span style="color:#bbb"> </span><span style="color:#666">3307</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">command</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- bash<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#b44">&#34;-c&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span>- |<span style="color:#b44;font-style:italic">
</span><span style="color:#b44;font-style:italic">          set -ex
</span><span style="color:#b44;font-style:italic">          cd /var/lib/mysql
</span><span style="color:#b44;font-style:italic">
</span><span style="color:#b44;font-style:italic">          # 确定克隆数据的 binlog 位置（如果有的话）。
</span><span style="color:#b44;font-style:italic">          if [[ -f xtrabackup_slave_info &amp;&amp; &#34;x$(&lt;xtrabackup_slave_info)&#34; != &#34;x&#34; ]]; then
</span><span style="color:#b44;font-style:italic">            # XtraBackup 已经生成了部分的 “CHANGE MASTER TO” 查询
</span><span style="color:#b44;font-style:italic">            # 因为我们从一个现有副本进行克隆。(需要删除末尾的分号!)
</span><span style="color:#b44;font-style:italic">            cat xtrabackup_slave_info | sed -E &#39;s/;$//g&#39; &gt; change_master_to.sql.in
</span><span style="color:#b44;font-style:italic">            # 在这里要忽略 xtrabackup_binlog_info （它是没用的）。
</span><span style="color:#b44;font-style:italic">            rm -f xtrabackup_slave_info xtrabackup_binlog_info
</span><span style="color:#b44;font-style:italic">          elif [[ -f xtrabackup_binlog_info ]]; then
</span><span style="color:#b44;font-style:italic">            # 我们直接从主实例进行克隆。解析 binlog 位置。
</span><span style="color:#b44;font-style:italic">            [[ `cat xtrabackup_binlog_info` =~ ^(.*?)[[:space:]]+(.*?)$ ]] || exit 1
</span><span style="color:#b44;font-style:italic">            rm -f xtrabackup_binlog_info xtrabackup_slave_info
</span><span style="color:#b44;font-style:italic">            echo &#34;CHANGE MASTER TO MASTER_LOG_FILE=&#39;${BASH_REMATCH[1]}&#39;,\
</span><span style="color:#b44;font-style:italic">                  MASTER_LOG_POS=${BASH_REMATCH[2]}&#34; &gt; change_master_to.sql.in
</span><span style="color:#b44;font-style:italic">          fi
</span><span style="color:#b44;font-style:italic">
</span><span style="color:#b44;font-style:italic">          # 检查我们是否需要通过启动复制来完成克隆。
</span><span style="color:#b44;font-style:italic">          if [[ -f change_master_to.sql.in ]]; then
</span><span style="color:#b44;font-style:italic">            echo &#34;Waiting for mysqld to be ready (accepting connections)&#34;
</span><span style="color:#b44;font-style:italic">            until mysql -h 127.0.0.1 -e &#34;SELECT 1&#34;; do sleep 1; done
</span><span style="color:#b44;font-style:italic">
</span><span style="color:#b44;font-style:italic">            echo &#34;Initializing replication from clone position&#34;
</span><span style="color:#b44;font-style:italic">            mysql -h 127.0.0.1 \
</span><span style="color:#b44;font-style:italic">                  -e &#34;$(&lt;change_master_to.sql.in), \
</span><span style="color:#b44;font-style:italic">                          MASTER_HOST=&#39;mysql-0.mysql&#39;, \
</span><span style="color:#b44;font-style:italic">                          MASTER_USER=&#39;root&#39;, \
</span><span style="color:#b44;font-style:italic">                          MASTER_PASSWORD=&#39;&#39;, \
</span><span style="color:#b44;font-style:italic">                          MASTER_CONNECT_RETRY=10; \
</span><span style="color:#b44;font-style:italic">                        START SLAVE;&#34; || exit 1
</span><span style="color:#b44;font-style:italic">            # 如果容器重新启动，最多尝试一次。
</span><span style="color:#b44;font-style:italic">            mv change_master_to.sql.in change_master_to.sql.orig
</span><span style="color:#b44;font-style:italic">          fi
</span><span style="color:#b44;font-style:italic">
</span><span style="color:#b44;font-style:italic">          # 当对等点请求时，启动服务器发送备份。
</span><span style="color:#b44;font-style:italic">          exec ncat --listen --keep-open --send-only --max-conns=1 3307 -c \
</span><span style="color:#b44;font-style:italic">            &#34;xtrabackup --backup --slave-info --stream=xbstream --host=127.0.0.1 --user=root&#34;</span><span style="color:#bbb">          
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">volumeMounts</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>data<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">mountPath</span>:<span style="color:#bbb"> </span>/var/lib/mysql<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">subPath</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>conf<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">mountPath</span>:<span style="color:#bbb"> </span>/etc/mysql/conf.d<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">requests</span>:<span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">cpu</span>:<span style="color:#bbb"> </span>100m<span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">memory</span>:<span style="color:#bbb"> </span>100Mi<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">volumes</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>conf<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">emptyDir</span>:<span style="color:#bbb"> </span>{}<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>config-map<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">configMap</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>mysql<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">volumeClaimTemplates</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>data<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">accessModes</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">&#34;ReadWriteOnce&#34;</span>]<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">requests</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">storage</span>:<span style="color:#bbb"> </span>10Gi<span style="color:#bbb">
</span></code></pre></div>
    </div>
</div>


<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl apply -f https://k8s.io/examples/application/mysql/mysql-statefulset.yaml
</code></pre></div><!--
You can watch the startup progress by running: 
-->
<p>你可以通过运行以下命令查看启动进度：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pods -l <span style="color:#b8860b">app</span><span style="color:#666">=</span>mysql --watch
</code></pre></div><!--
After a while, you should see all 3 Pods become Running: 
-->
<p>一段时间后，你应该看到所有 3 个 Pod 进入 Running 状态：</p>
<pre><code>NAME      READY     STATUS    RESTARTS   AGE
mysql-0   2/2       Running   0          2m
mysql-1   2/2       Running   0          1m
mysql-2   2/2       Running   0          1m
</code></pre><!--
Press **Ctrl+C** to cancel the watch.
If you don't see any progress, make sure you have a dynamic PersistentVolume
provisioner enabled as mentioned in the [prerequisites](#before-you-begin). 
-->
<p>输入 <strong>Ctrl+C</strong> 结束 watch 操作。
如果你看不到任何进度，确保已启用<a href="#%E5%87%86%E5%A4%87%E5%BC%80%E5%A7%8B">前提条件</a>
中提到的动态 PersistentVolume 预配器。</p>
<!--
This manifest uses a variety of techniques for managing stateful Pods as part of
a StatefulSet. The next section highlights some of these techniques to explain
what happens as the StatefulSet creates Pods. 
-->
<p>此清单使用多种技术来管理作为 StatefulSet 的一部分的有状态 Pod。
下一节重点介绍其中的一些技巧，以解释 StatefulSet 创建 Pod 时发生的状况。</p>
<!--
## Understanding stateful Pod initialization 

The StatefulSet controller starts Pods one at a time, in order by their
ordinal index.
It waits until each Pod reports being Ready before starting the next one. 
-->
<h2 id="了解有状态的-pod-初始化">了解有状态的 Pod 初始化</h2>
<p>StatefulSet 控制器按序数索引顺序地每次启动一个 Pod。
它一直等到每个 Pod 报告就绪才再启动下一个 Pod。</p>
<!--
In addition, the controller assigns each Pod a unique, stable name of the form
`<statefulset-name>-<ordinal-index>`, which results in Pods named `mysql-0`,
`mysql-1`, and `mysql-2`. 
-->
<p>此外，控制器为每个 Pod 分配一个唯一、稳定的名称，形如 <code>&lt;statefulset 名称&gt;-&lt;序数索引&gt;</code>，
其结果是 Pods 名为 <code>mysql-0</code>、<code>mysql-1</code> 和 <code>mysql-2</code>。</p>
<!--
The Pod template in the above StatefulSet manifest takes advantage of these
properties to perform orderly startup of MySQL replication. 
-->
<p>上述 StatefulSet 清单中的 Pod 模板利用这些属性来执行 MySQL 副本的有序启动。</p>
<!--
### Generating configuration 

Before starting any of the containers in the Pod spec, the Pod first runs any
[Init Containers](/docs/concepts/workloads/pods/init-containers/)
in the order defined. 
-->
<h3 id="生成配置">生成配置</h3>
<p>在启动 Pod 规约中的任何容器之前，Pod 首先按顺序运行所有的
<a href="/zh/docs/concepts/workloads/pods/init-containers/">Init 容器</a>。</p>
<!--
The first Init Container, named `init-mysql`, generates special MySQL config
files based on the ordinal index. 
-->
<p>第一个名为 <code>init-mysql</code> 的 Init 容器根据序号索引生成特殊的 MySQL 配置文件。</p>
<!--
The script determines its own ordinal index by extracting it from the end of
the Pod name, which is returned by the `hostname` command.
Then it saves the ordinal (with a numeric offset to avoid reserved values)
into a file called `server-id.cnf` in the MySQL `conf.d` directory.
This translates the unique, stable identity provided by the StatefulSet
controller into the domain of MySQL server IDs, which require the same
properties. 
-->
<p>该脚本通过从 Pod 名称的末尾提取索引来确定自己的序号索引，而 Pod 名称由 <code>hostname</code> 命令返回。
然后将序数（带有数字偏移量以避免保留值）保存到 MySQL <code>conf.d</code> 目录中的文件 <code>server-id.cnf</code>。
这一操作将 StatefulSet 所提供的唯一、稳定的标识转换为 MySQL 服务器的 ID，
而这些 ID 也是需要唯一性、稳定性保证的。</p>
<!--
The script in the `init-mysql` container also applies either `primary.cnf` or
`replica.cnf` from the ConfigMap by copying the contents into `conf.d`.
Because the example topology consists of a single primary MySQL server and any number of
replicas, the script assigns ordinal `0` to be the primary server, and everyone
else to be replicas. 

Combined with the StatefulSet controller's
[deployment order guarantee](/docs/concepts/workloads/controllers/statefulset/#deployment-and-scaling-guarantees),
this ensures the primary MySQL server is Ready before creating replicas, so they can begin
replicating.
-->
<p>通过将内容复制到 <code>conf.d</code> 中，<code>init-mysql</code> 容器中的脚本也可以应用 ConfigMap 中的
<code>primary.cnf</code> 或 <code>replica.cnf</code>。
由于示例部署结构由单个 MySQL 主节点和任意数量的副本节点组成，
因此脚本仅将序数 <code>0</code> 指定为主节点，而将其他所有节点指定为副本节点。</p>
<p>与 StatefulSet 控制器的
<a href="/zh/docs/concepts/workloads/controllers/statefulset/#deployment-and-scaling-guarantees">部署顺序保证</a>
相结合，
可以确保 MySQL 主服务器在创建副本服务器之前已准备就绪，以便它们可以开始复制。</p>
<!--
### Cloning existing data 

In general, when a new Pod joins the set as a replica, it must assume the primary MySQL
server might already have data on it. It also must assume that the replication
logs might not go all the way back to the beginning of time. 
-->
<h3 id="克隆现有数据">克隆现有数据</h3>
<p>通常，当新 Pod 作为副本节点加入集合时，必须假定 MySQL 主节点可能已经有数据。
还必须假设复制日志可能不会一直追溯到时间的开始。</p>
<!--
These conservative assumptions are the key to allow a running StatefulSet
to scale up and down over time, rather than being fixed at its initial size. 
-->
<p>这些保守的假设是允许正在运行的 StatefulSet 随时间扩大和缩小而不是固定在其初始大小的关键。</p>
<!--
The second Init Container, named `clone-mysql`, performs a clone operation on
a replica Pod the first time it starts up on an empty PersistentVolume.
That means it copies all existing data from another running Pod,
so its local state is consistent enough to begin replicating from the primary server.
-->
<p>第二个名为 <code>clone-mysql</code> 的 Init 容器，第一次在带有空 PersistentVolume 的副本 Pod
上启动时，会在从属 Pod 上执行克隆操作。
这意味着它将从另一个运行中的 Pod 复制所有现有数据，使此其本地状态足够一致，
从而可以开始从主服务器复制。</p>
<!--
MySQL itself does not provide a mechanism to do this, so the example uses a
popular open-source tool called Percona XtraBackup.
During the clone, the source MySQL server might suffer reduced performance.
To minimize impact on the primary MySQL server, the script instructs each Pod to clone
from the Pod whose ordinal index is one lower.
This works because the StatefulSet controller always ensures Pod `N` is
Ready before starting Pod `N+1`. 
-->
<p>MySQL 本身不提供执行此操作的机制，因此本示例使用了一种流行的开源工具 Percona XtraBackup。
在克隆期间，源 MySQL 服务器性能可能会受到影响。
为了最大程度地减少对 MySQL 主服务器的影响，该脚本指示每个 Pod 从序号较低的 Pod 中克隆。
可以这样做的原因是 StatefulSet 控制器始终确保在启动 Pod <code>N + 1</code> 之前 Pod <code>N</code> 已准备就绪。</p>
<!--
### Starting replication 

After the Init Containers complete successfully, the regular containers run.
The MySQL Pods consist of a `mysql` container that runs the actual `mysqld`
server, and an `xtrabackup` container that acts as a
[sidecar](https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns). 
-->
<h3 id="开始复制">开始复制</h3>
<p>Init 容器成功完成后，应用容器将运行。
MySQL Pod 由运行实际 <code>mysqld</code> 服务的 <code>mysql</code> 容器和充当
<a href="https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns">辅助工具</a>
的 xtrabackup 容器组成。</p>
<!--
The `xtrabackup` sidecar looks at the cloned data files and determines if
it's necessary to initialize MySQL replication on the replica.
If so, it waits for `mysqld` to be ready and then executes the
`CHANGE MASTER TO` and `START SLAVE` commands with replication parameters
extracted from the XtraBackup clone files. 
-->
<p><code>xtrabackup</code> sidecar 容器查看克隆的数据文件，并确定是否有必要在副本服务器上初始化 MySQL 复制。
如果是这样，它将等待 <code>mysqld</code> 准备就绪，然后使用从 XtraBackup 克隆文件中提取的复制参数
执行  <code>CHANGE MASTER TO</code> 和 <code>START SLAVE</code> 命令。</p>
<!--
Once a replica begins replication, it remembers its primary MySQL server and
reconnects automatically if the server restarts or the connection dies.
Also, because replicas look for the primary server at its stable DNS name
(`mysql-0.mysql`), they automatically find the primary server even if it gets a new
Pod IP due to being rescheduled. 
-->
<p>一旦副本服务器开始复制后，它会记住其 MySQL 主服务器，并且如果服务器重新启动或
连接中断也会自动重新连接。
另外，因为副本服务器会以其稳定的 DNS 名称查找主服务器（<code>mysql-0.mysql</code>），
即使由于重新调度而获得新的 Pod IP，它们也会自动找到主服务器。</p>
<!--
Lastly, after starting replication, the `xtrabackup` container listens for
connections from other Pods requesting a data clone.
This server remains up indefinitely in case the StatefulSet scales up, or in
case the next Pod loses its PersistentVolumeClaim and needs to redo the clone. 
-->
<p>最后，开始复制后，<code>xtrabackup</code> 容器监听来自其他 Pod 的连接，处理其数据克隆请求。
如果 StatefulSet 扩大规模，或者下一个 Pod 失去其 PersistentVolumeClaim 并需要重新克隆，
则此服务器将无限期保持运行。</p>
<!--
## Sending client traffic 

You can send test queries to the primary MySQL server (hostname `mysql-0.mysql`)
by running a temporary container with the `mysql:5.7` image and running the
`mysql` client binary. 
-->
<h2 id="发送客户端请求">发送客户端请求</h2>
<p>你可以通过运行带有 <code>mysql:5.7</code> 镜像的临时容器并运行 <code>mysql</code> 客户端二进制文件，
将测试查询发送到 MySQL 主服务器（主机名 <code>mysql-0.mysql</code>）。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl run mysql-client --image<span style="color:#666">=</span>mysql:5.7 -i --rm --restart<span style="color:#666">=</span>Never --<span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>  mysql -h mysql-0.mysql <span style="color:#b44">&lt;&lt;EOF
</span><span style="color:#b44">CREATE DATABASE test;
</span><span style="color:#b44">CREATE TABLE test.messages (message VARCHAR(250));
</span><span style="color:#b44">INSERT INTO test.messages VALUES (&#39;hello&#39;);
</span><span style="color:#b44">EOF</span>
</code></pre></div><!--
Use the hostname `mysql-read` to send test queries to any server that reports
being Ready: 
-->
<p>使用主机名 <code>mysql-read</code> 将测试查询发送到任何报告为就绪的服务器：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl run mysql-client --image<span style="color:#666">=</span>mysql:5.7 -i -t --rm --restart<span style="color:#666">=</span>Never --<span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>  mysql -h mysql-read -e <span style="color:#b44">&#34;SELECT * FROM test.messages&#34;</span>
</code></pre></div><!--
You should get output like this: 
-->
<p>你应该获得如下输出：</p>
<pre><code>Waiting for pod default/mysql-client to be running, status is Pending, pod ready: false
+---------+
| message |
+---------+
| hello   |
+---------+
pod &quot;mysql-client&quot; deleted
</code></pre><!--
To demonstrate that the `mysql-read` Service distributes connections across
servers, you can run `SELECT @@server_id` in a loop: 
-->
<p>为了演示 <code>mysql-read</code> 服务在服务器之间分配连接，你可以在循环中运行 <code>SELECT @@server_id</code>：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl run mysql-client-loop --image<span style="color:#666">=</span>mysql:5.7 -i -t --rm --restart<span style="color:#666">=</span>Never --<span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>  bash -ic <span style="color:#b44">&#34;while sleep 1; do mysql -h mysql-read -e &#39;SELECT @@server_id,NOW()&#39;; done&#34;</span>
</code></pre></div><!--
You should see the reported `@@server_id` change randomly, because a different
endpoint might be selected upon each connection attempt: 
-->
<p>你应该看到报告的 <code>@@server_id</code> 发生随机变化，因为每次尝试连接时都可能选择了不同的端点：</p>
<pre><code>+-------------+---------------------+
| @@server_id | NOW()               |
+-------------+---------------------+
|         100 | 2006-01-02 15:04:05 |
+-------------+---------------------+
+-------------+---------------------+
| @@server_id | NOW()               |
+-------------+---------------------+
|         102 | 2006-01-02 15:04:06 |
+-------------+---------------------+
+-------------+---------------------+
| @@server_id | NOW()               |
+-------------+---------------------+
|         101 | 2006-01-02 15:04:07 |
+-------------+---------------------+
</code></pre><!--
You can press **Ctrl+C** when you want to stop the loop, but it's useful to keep
it running in another window so you can see the effects of the following steps. 
-->
<p>要停止循环时可以按 <strong>Ctrl+C</strong> ，但是让它在另一个窗口中运行非常有用，
这样你就可以看到以下步骤的效果。</p>
<!--
## Simulating Pod and Node downtime 

To demonstrate the increased availability of reading from the pool of replicas
instead of a single server, keep the `SELECT @@server_id` loop from above
running while you force a Pod out of the Ready state. 
-->
<h2 id="模拟-pod-和-node-的宕机时间">模拟 Pod 和 Node 的宕机时间</h2>
<p>为了证明从副本节点缓存而不是单个服务器读取数据的可用性提高，请在使 Pod 退出 Ready
状态时，保持上述 <code>SELECT @@server_id</code> 循环一直运行。</p>
<!--
### Break the Readiness Probe 

The [readiness probe](/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-readiness-probes)
for the `mysql` container runs the command `mysql -h 127.0.0.1 -e 'SELECT 1'`
to make sure the server is up and able to execute queries. 
-->
<h3 id="破坏就绪态探测">破坏就绪态探测</h3>
<p><code>mysql</code> 容器的
<a href="/zh/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-readiness-probes">就绪态探测</a>
运行命令 <code>mysql -h 127.0.0.1 -e 'SELECT 1'</code>，以确保服务器已启动并能够执行查询。</p>
<!--
One way to force this readiness probe to fail is to break that command: 
-->
<p>迫使就绪态探测失败的一种方法就是中止该命令：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl <span style="color:#a2f">exec</span> mysql-2 -c mysql -- mv /usr/bin/mysql /usr/bin/mysql.off
</code></pre></div><!--
This reaches into the actual container's filesystem for Pod `mysql-2` and
renames the `mysql` command so the readiness probe can't find it.
After a few seconds, the Pod should report one of its containers as not Ready,
which you can check by running: 
-->
<p>此命令会进入 Pod <code>mysql-2</code> 的实际容器文件系统，重命名 <code>mysql</code> 命令，导致就绪态探测无法找到它。
几秒钟后， Pod 会报告其中一个容器未就绪。你可以通过运行以下命令进行检查：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pod mysql-2
</code></pre></div><!--
Look for `1/2` in the `READY` column: 
-->
<p>在 <code>READY</code> 列中查找 <code>1/2</code>：</p>
<pre><code>NAME      READY     STATUS    RESTARTS   AGE
mysql-2   1/2       Running   0          3m
</code></pre><!--
At this point, you should see your `SELECT @@server_id` loop continue to run,
although it never reports `102` anymore.
Recall that the `init-mysql` script defined `server-id` as `100 + $ordinal`,
so server ID `102` corresponds to Pod `mysql-2`. 
-->
<p>此时，你应该会看到 <code>SELECT @@server_id</code> 循环继续运行，尽管它不再报告 <code>102</code>。
回想一下，<code>init-mysql</code> 脚本将 <code>server-id</code> 定义为 <code>100 + $ordinal</code>，
因此服务器 ID <code>102</code> 对应于 Pod <code>mysql-2</code>。</p>
<!--
Now repair the Pod and it should reappear in the loop output
after a few seconds: 
-->
<p>现在修复 Pod，几秒钟后它应该重新出现在循环输出中：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl <span style="color:#a2f">exec</span> mysql-2 -c mysql -- mv /usr/bin/mysql.off /usr/bin/mysql
</code></pre></div><!--
### Delete Pods 

The StatefulSet also recreates Pods if they're deleted, similar to what a
ReplicaSet does for stateless Pods. 
-->
<h3 id="删除-pods">删除 Pods</h3>
<p>如果删除了 Pod，则 StatefulSet 还会重新创建 Pod，类似于 ReplicaSet 对无状态 Pod 所做的操作。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl delete pod mysql-2
</code></pre></div><!--
The StatefulSet controller notices that no `mysql-2` Pod exists anymore,
and creates a new one with the same name and linked to the same
PersistentVolumeClaim.
You should see server ID `102` disappear from the loop output for a while
and then return on its own. 
-->
<p>StatefulSet 控制器注意到不再存在 <code>mysql-2</code> Pod，于是创建一个具有相同名称并链接到相同
PersistentVolumeClaim 的新 Pod。
你应该看到服务器 ID <code>102</code> 从循环输出中消失了一段时间，然后又自行出现。</p>
<!--
### Drain a Node 

If your Kubernetes cluster has multiple Nodes, you can simulate Node downtime
(such as when Nodes are upgraded) by issuing a
[drain](/docs/reference/generated/kubectl/kubectl-commands/#drain). 
-->
<h3 id="drain-a-node">腾空节点  </h3>
<p>如果你的 Kubernetes 集群具有多个节点，则可以通过发出以下
<a href="/docs/reference/generated/kubectl/kubectl-commands/#drain">drain</a>
命令来模拟节点停机（就好像节点在被升级）。</p>
<!--
First determine which Node one of the MySQL Pods is on: 
-->
<p>首先确定 MySQL Pod 之一在哪个节点上：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pod mysql-2 -o wide
</code></pre></div><!--
The Node name should show up in the last column: 
-->
<p>节点名称应显示在最后一列中：</p>
<pre><code>NAME      READY     STATUS    RESTARTS   AGE       IP            NODE
mysql-2   2/2       Running   0          15m       10.244.5.27   kubernetes-node-9l2t
</code></pre><!--
Then drain the Node by running the following command, which cordons it so
no new Pods may schedule there, and then evicts any existing Pods.
Replace `<node-name>` with the name of the Node you found in the last step. 
-->
<p>然后通过运行以下命令腾空节点，该命令将其保护起来，以使新的 Pod 不能调度到该节点，
然后逐出所有现有的 Pod。将 <code>&lt;节点名称&gt;</code> 替换为在上一步中找到的节点名称。</p>
<!--
This might impact other applications on the Node, so it's best to
**only do this in a test cluster**. 

```shell
kubectl drain <node-name> --force --delete-local-data --ignore-daemonsets
```
-->
<p>这可能会影响节点上的其他应用程序，因此最好 <strong>仅在测试集群中执行此操作</strong>。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl drain &lt;节点名称&gt; --force --delete-local-data --ignore-daemonsets
</code></pre></div><!--
Now you can watch as the Pod reschedules on a different Node: 
-->
<p>现在，你可以看到 Pod 被重新调度到其他节点上：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pod mysql-2 -o wide --watch
</code></pre></div><!--
It should look something like this: 
-->
<p>它看起来应该像这样：</p>
<pre><code>NAME      READY   STATUS          RESTARTS   AGE       IP            NODE
mysql-2   2/2     Terminating     0          15m       10.244.1.56   kubernetes-node-9l2t
[...]
mysql-2   0/2     Pending         0          0s        &lt;none&gt;        kubernetes-node-fjlm
mysql-2   0/2     Init:0/2        0          0s        &lt;none&gt;        kubernetes-node-fjlm
mysql-2   0/2     Init:1/2        0          20s       10.244.5.32   kubernetes-node-fjlm
mysql-2   0/2     PodInitializing 0          21s       10.244.5.32   kubernetes-node-fjlm
mysql-2   1/2     Running         0          22s       10.244.5.32   kubernetes-node-fjlm
mysql-2   2/2     Running         0          30s       10.244.5.32   kubernetes-node-fjlm
</code></pre><!--
And again, you should see server ID `102` disappear from the
`SELECT @@server_id` loop output for a while and then return. 
-->
<p>再次，你应该看到服务器 ID <code>102</code> 从 <code>SELECT @@server_id</code> 循环输出
中消失一段时间，然后自行出现。</p>
<!--
Now uncordon the Node to return it to a normal state: 

```shell
kubectl uncordon <node-name>
```
-->
<p>现在去掉节点保护（Uncordon），使其恢复为正常模式:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl uncordon &lt;节点名称&gt;
</code></pre></div><!--
## Scaling the number of replicas

With MySQL replication, you can scale your read query capacity by adding replicas.
With StatefulSet, you can do this with a single command: 
-->
<h2 id="扩展副本节点数量">扩展副本节点数量</h2>
<p>使用 MySQL 复制，你可以通过添加副本节点来扩展读取查询的能力。
使用 StatefulSet，你可以使用单个命令执行此操作：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl scale statefulset mysql --replicas<span style="color:#666">=</span><span style="color:#666">5</span>
</code></pre></div><!--
Watch the new Pods come up by running: 
-->
<p>查看新的 Pod 的运行情况：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pods -l <span style="color:#b8860b">app</span><span style="color:#666">=</span>mysql --watch
</code></pre></div><!--
Once they're up, you should see server IDs `103` and `104` start appearing in
the `SELECT @@server_id` loop output.

You can also verify that these new servers have the data you added before they
existed: 
-->
<p>一旦 Pod 启动，你应该看到服务器 IDs <code>103</code> 和 <code>104</code> 开始出现在 <code>SELECT @@server_id</code> 循环输出中。</p>
<p>你还可以验证这些新服务器在存在之前已添加了数据：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl run mysql-client --image<span style="color:#666">=</span>mysql:5.7 -i -t --rm --restart<span style="color:#666">=</span>Never --<span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>  mysql -h mysql-3.mysql -e <span style="color:#b44">&#34;SELECT * FROM test.messages&#34;</span>
</code></pre></div><pre><code>Waiting for pod default/mysql-client to be running, status is Pending, pod ready: false
+---------+
| message |
+---------+
| hello   |
+---------+
pod &quot;mysql-client&quot; deleted
</code></pre><!--
Scaling back down is also seamless: 
-->
<p>向下缩容操作也是很平滑的：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl scale statefulset mysql --replicas<span style="color:#666">=</span><span style="color:#666">3</span>
</code></pre></div><!--
Note, however, that while scaling up creates new PersistentVolumeClaims
automatically, scaling down does not automatically delete these PVCs.
This gives you the choice to keep those initialized PVCs around to make
scaling back up quicker, or to extract data before deleting them. 
-->
<p>但是请注意，按比例扩大会自动创建新的 PersistentVolumeClaims，而按比例缩小不会自动删除这些 PVC。
这使你可以选择保留那些初始化的 PVC，以更快地进行缩放，或者在删除它们之前提取数据。</p>
<!--
You can see this by running: 
-->
<p>你可以通过运行以下命令查看此信息：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pvc -l <span style="color:#b8860b">app</span><span style="color:#666">=</span>mysql
</code></pre></div><!--
Which shows that all 5 PVCs still exist, despite having scaled the
StatefulSet down to 3: 
-->
<p>这表明，尽管将 StatefulSet 缩小为3，所有5个 PVC 仍然存在：</p>
<pre><code>NAME           STATUS    VOLUME                                     CAPACITY   ACCESSMODES   AGE
data-mysql-0   Bound     pvc-8acbf5dc-b103-11e6-93fa-42010a800002   10Gi       RWO           20m
data-mysql-1   Bound     pvc-8ad39820-b103-11e6-93fa-42010a800002   10Gi       RWO           20m
data-mysql-2   Bound     pvc-8ad69a6d-b103-11e6-93fa-42010a800002   10Gi       RWO           20m
data-mysql-3   Bound     pvc-50043c45-b1c5-11e6-93fa-42010a800002   10Gi       RWO           2m
data-mysql-4   Bound     pvc-500a9957-b1c5-11e6-93fa-42010a800002   10Gi       RWO           2m
</code></pre><!--
If you don't intend to reuse the extra PVCs, you can delete them: 
-->
<p>如果你不打算重复使用多余的 PVC，则可以删除它们：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl delete pvc data-mysql-3
kubectl delete pvc data-mysql-4
</code></pre></div><h2 id="cleaning-up">Cleaning up</h2>
<!--
1. Cancel the `SELECT @@server_id` loop by pressing **Ctrl+C** in its terminal,
   or running the following from another terminal: 
-->
<ol>
<li>
<p>通过在终端上按 <strong>Ctrl+C</strong> 取消 <code>SELECT @@server_id</code> 循环，或从另一个终端运行以下命令：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl delete pod mysql-client-loop --now
</code></pre></div></li>
</ol>
<!--
1. Delete the StatefulSet. This also begins terminating the Pods. 
-->
<ol start="2">
<li>
<p>删除 StatefulSet。这也会开始终止 Pod。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl delete statefulset mysql
</code></pre></div></li>
</ol>
<!--
1. Verify that the Pods disappear.
   They might take some time to finish terminating. 
-->
<ol start="3">
<li>
<p>验证 Pod 消失。他们可能需要一些时间才能完成终止。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pods -l <span style="color:#b8860b">app</span><span style="color:#666">=</span>mysql
</code></pre></div><!-- You'll know the Pods have terminated when the above returns: -->
<p>当上述命令返回如下内容时，你就知道 Pod 已终止：</p>
<pre><code>No resources found.
</code></pre></li>
</ol>
<!--
1. Delete the ConfigMap, Services, and PersistentVolumeClaims. 
-->
<ol start="4">
<li>
<p>删除 ConfigMap、Services 和 PersistentVolumeClaims。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl delete configmap,service,pvc -l <span style="color:#b8860b">app</span><span style="color:#666">=</span>mysql
</code></pre></div></li>
</ol>
<!--
1. If you manually provisioned PersistentVolumes, you also need to manually
   delete them, as well as release the underlying resources.
   If you used a dynamic provisioner, it automatically deletes the
   PersistentVolumes when it sees that you deleted the PersistentVolumeClaims.
   Some dynamic provisioners (such as those for EBS and PD) also release the
   underlying resources upon deleting the PersistentVolumes. 
-->
<ol start="5">
<li>如果你手动供应 PersistentVolume，则还需要手动删除它们，并释放下层资源。
如果你使用了动态预配器，当得知你删除 PersistentVolumeClaims 时，它将自动删除 PersistentVolumes。
一些动态预配器（例如用于 EBS 和 PD 的预配器）也会在删除 PersistentVolumes 时释放下层资源。</li>
</ol>
<h2 id="what-s-next">What's next</h2>
<!--
* Learn more about [scaling a StatefulSet](/docs/tasks/run-application/scale-stateful-set/).
* Learn more about [debugging a StatefulSet](/docs/tasks/debug-application-cluster/debug-stateful-set/).
* Learn more about [deleting a StatefulSet](/docs/tasks/run-application/delete-stateful-set/).
* Learn more about [force deleting StatefulSet Pods](/docs/tasks/run-application/force-delete-stateful-set-pod/).
* Look in the [Helm Charts repository](https://artifacthub.io/)
  for other stateful application examples.
-->
<ul>
<li>进一步了解<a href="/zh/docs/tasks/run-application/scale-stateful-set/">为 StatefulSet 扩缩容</a>.</li>
<li>进一步了解<a href="/zh/docs/tasks/debug-application-cluster/debug-stateful-set/">调试 StatefulSet</a>.</li>
<li>进一步了解<a href="/zh/docs/tasks/run-application/delete-stateful-set/">删除 StatefulSet</a>.</li>
<li>进一步了解<a href="/zh/docs/tasks/run-application/force-delete-stateful-set-pod/">强制删除 StatefulSet Pods</a>.</li>
<li>在 <a href="https://artifacthub.io/">Helm Charts 仓库</a>中查找其他有状态的应用程序示例。</li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-c43537b0ee1da992ecb7488f87e6c934">4 - 删除 StatefulSet</h1>
    
	<!--
reviewers:
- bprashanth
- erictune
- foxish
- janetkuo
- smarterclayton
title: Delete a StatefulSet
content_type: task
weight: 60
-->
<!-- overview -->
<!--
This task shows you how to delete a StatefulSet.
-->
<p>本任务展示如何删除 StatefulSet。</p>
<h2 id="before-you-begin">Before you begin</h2>
<!--
* This task assumes you have an application running on your cluster represented by a StatefulSet.
-->
<ul>
<li>本任务假设在你的集群上已经运行了由 StatefulSet 创建的应用。</li>
</ul>
<!-- steps -->
<h2 id="deleting-a-statefulset">删除 StatefulSet  </h2>
<!--
You can delete a StatefulSet in the same way you delete other resources in Kubernetes: use the `kubectl delete` command, and specify the StatefulSet either by file or by name.
-->
<p>你可以像删除 Kubernetes 中的其他资源一样删除 StatefulSet：使用 <code>kubectl delete</code> 命令，并按文件或者名字指定 StatefulSet。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl delete -f &lt;file.yaml&gt;
</code></pre></div><!--
```shell
kubectl delete statefulsets <statefulset-name>
```
-->
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl delete statefulsets &lt;statefulset 名称&gt;
</code></pre></div><!--
You may need to delete the associated headless service separately after the StatefulSet itself is deleted.

```shell
kubectl delete service <service-name>
```
-->
<p>删除 StatefulSet 之后，你可能需要单独删除关联的无头服务。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl delete service &lt;服务名称&gt;
</code></pre></div><!--
When deleting a StatefulSet through `kubectl`, the StatefulSet scales down to 0. All Pods that are part of this workload are also deleted. If you want to delete only the StatefulSet and not the Pods, use `--cascade=orphan`.
For example:
--->
<p>当通过 <code>kubectl</code> 删除 StatefulSet 时，StatefulSet 会被缩容为 0。
属于该 StatefulSet 的所有 Pod 也被删除。
如果你只想删除 StatefulSet 而不删除 Pod，使用 <code>--cascade=orphan</code>。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl delete -f &lt;file.yaml&gt; --cascade<span style="color:#666">=</span>orphan
</code></pre></div><!--
By passing `--cascade=orphan` to `kubectl delete`, the Pods managed by the StatefulSet are left behind even after the StatefulSet object itself is deleted. If the pods have a label `app=myapp`, you can then delete them as follows:
--->
<p>通过将 <code>--cascade=orphan</code> 传递给 <code>kubectl delete</code>，在删除 StatefulSet 对象之后，
StatefulSet 管理的 Pod 会被保留下来。如果 Pod 具有标签 <code>app=myapp</code>，则可以按照
如下方式删除它们：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl delete pods -l <span style="color:#b8860b">app</span><span style="color:#666">=</span>myapp
</code></pre></div><!--
### Persistent Volumes

Deleting the Pods in a StatefulSet will not delete the associated volumes. This is to ensure that you have the chance to copy data off the volume before deleting it. Deleting the PVC after the pods have left the [terminating state](/docs/concepts/workloads/pods/pod/#termination-of-pods) might trigger deletion of the backing Persistent Volumes depending on the storage class and reclaim policy. You should never assume ability to access a volume after claim deletion.
-->
<h3 id="persistent-volumes">持久卷 </h3>
<p>删除 StatefulSet 管理的 Pod 并不会删除关联的卷。这是为了确保你有机会在删除卷之前从卷中复制数据。
在 Pod 离开<a href="/zh/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination">终止状态</a>
后删除 PVC 可能会触发删除背后的 PV 持久卷，具体取决于存储类和回收策略。
永远不要假定在 PVC 删除后仍然能够访问卷。</p>
<!--
Use caution when deleting a PVC, as it may lead to data loss.
-->
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> 删除 PVC 时要谨慎，因为这可能会导致数据丢失。
</div>
<!--
### Complete deletion of a StatefulSet

To simply delete everything in a StatefulSet, including the associated pods, you can run a series of commands similar to the following:
-->
<h3 id="complete-deletion-of-a-statefulset">完全删除 StatefulSet </h3>
<p>要删除 StatefulSet 中的所有内容，包括关联的 pods，你可以运行
一系列如下所示的命令：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#b8860b">grace</span><span style="color:#666">=</span><span style="color:#a2f;font-weight:bold">$(</span>kubectl get pods &lt;stateful-set-pod&gt; --template <span style="color:#b44">&#39;{{.spec.terminationGracePeriodSeconds}}&#39;</span><span style="color:#a2f;font-weight:bold">)</span>
kubectl delete statefulset -l <span style="color:#b8860b">app</span><span style="color:#666">=</span>myapp
sleep <span style="color:#b8860b">$grace</span>
kubectl delete pvc -l <span style="color:#b8860b">app</span><span style="color:#666">=</span>myapp
</code></pre></div><!--
In the example above, the Pods have the label `app=myapp`; substitute your own label as appropriate.
-->
<p>在上面的例子中，Pod 的标签为 <code>app=myapp</code>；适当地替换你自己的标签。</p>
<!--
### Force deletion of StatefulSet pods

If you find that some pods in your StatefulSet are stuck in the 'Terminating' or 'Unknown' states for an extended period of time, you may need to manually intervene to forcefully delete the pods from the apiserver. This is a potentially dangerous task. Refer to [Deleting StatefulSet Pods](/docs/tasks/manage-stateful-set/delete-pods/) for details.
-->
<h3 id="强制删除-statefulset-的-pod">强制删除 StatefulSet 的 Pod</h3>
<p>如果你发现 StatefulSet 的某些 Pod 长时间处于 'Terminating' 或者 'Unknown' 状态，
则可能需要手动干预以强制从 API 服务器中删除这些 Pod。
这是一项有点危险的任务。详细信息请阅读
<a href="/zh/docs/tasks/run-application/force-delete-stateful-set-pod/">删除 StatefulSet 类型的 Pods</a>。</p>
<h2 id="what-s-next">What's next</h2>
<!--
Learn more about [force deleting StatefulSet Pods](/docs/tasks/run-application/force-delete-stateful-set-pod/).
-->
<p>进一步了解<a href="/zh/docs/tasks/run-application/force-delete-stateful-set-pod/">强制删除 StatefulSet 的 Pods</a>。</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-f5f2f7a74377a9d45325c5253353fa8f">5 - 强制删除 StatefulSet 中的 Pods</h1>
    
	<!--
reviewers:
- bprashanth
- erictune
- foxish
- smarterclayton
title: Force Delete StatefulSet Pods
content_type: task
weight: 70
-->
<!-- overview -->
<!--
This page shows how to delete Pods which are part of a <a class='glossary-tooltip' title='StatefulSet 用来管理某 Pod 集合的部署和扩缩，并为这些 Pod 提供持久存储和持久标识符。' data-toggle='tooltip' data-placement='top' href='/zh/docs/concepts/workloads/controllers/statefulset/' target='_blank' aria-label='stateful set'>stateful set</a>, and explains the considerations to keep in mind when doing so.
-->
<p>本文介绍如何删除 <a class='glossary-tooltip' title='StatefulSet 用来管理某 Pod 集合的部署和扩缩，并为这些 Pod 提供持久存储和持久标识符。' data-toggle='tooltip' data-placement='top' href='/zh/docs/concepts/workloads/controllers/statefulset/' target='_blank' aria-label='StatefulSet'>StatefulSet</a>
管理的 Pods，并解释这样操作时需要记住的注意事项。</p>
<h2 id="before-you-begin">Before you begin</h2>
<!--
* This is a fairly advanced task and has the potential to violate some of the properties inherent to StatefulSet.
* Before proceeding, make yourself familiar with the considerations enumerated below.
-->
<ul>
<li>这是一项相当高级的任务，并且可能会违反 StatefulSet 固有的某些属性。</li>
<li>继续任务之前，请熟悉下面列举的注意事项。</li>
</ul>
<!-- steps -->
<!--
## StatefulSet considerations

In normal operation of a StatefulSet, there is **never** a need to force delete a StatefulSet Pod. The [StatefulSet controller](/docs/concepts/workloads/controllers/statefulset/) is responsible for creating, scaling and deleting members of the StatefulSet. It tries to ensure that the specified number of Pods from ordinal 0 through N-1 are alive and ready. StatefulSet ensures that, at any time, there is at most one Pod with a given identity running in a cluster. This is referred to as *at most one* semantics provided by a StatefulSet.
-->
<h2 id="statefulset-注意事项">StatefulSet 注意事项</h2>
<p>在 StatefulSet 的正常操作中，<strong>永远不</strong>需要强制删除 StatefulSet 管理的 Pod。
<a href="/zh/docs/concepts/workloads/controllers/statefulset/">StatefulSet 控制器</a>负责创建、
扩缩和删除 StatefulSet 管理的 Pods。它尝试确保指定数量的从序数 0 到 N-1 的 Pod
处于活跃状态并准备就绪。StatefulSet 确保在任何时候，集群中最多只有一个具有给定标识的 Pod。
这就是所谓的由 StatefulSet 提供的*最多一个（At Most One）*的语义。</p>
<!--
Manual force deletion should be undertaken with caution, as it has the potential to violate the at most one semantics inherent to StatefulSet. StatefulSets may be used to run distributed and clustered applications which have a need for a stable network identity and stable storage. These applications often have configuration which relies on an ensemble of a fixed number of members with fixed identities. Having multiple members with the same identity can be disastrous and may lead to data loss (e.g. split brain scenario in quorum-based systems).
-->
<p>应谨慎进行手动强制删除操作，因为它可能会违反 StatefulSet 固有的至多一个的语义。
StatefulSets 可用于运行分布式和集群级的应用，这些应用需要稳定的网络标识和可靠的存储。
这些应用通常配置为具有固定标识固定数量的成员集合。
具有相同身份的多个成员可能是灾难性的，并且可能导致数据丢失 (例如：票选系统中的脑裂场景)。</p>
<!--
## Delete Pods

You can perform a graceful pod deletion with the following command:
-->
<h2 id="delete-pods">删除 Pods  </h2>
<p>你可以使用下面的命令执行体面地删除 Pod:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl delete pods &lt;pod&gt;
</code></pre></div><!--
For the above to lead to graceful termination, the Pod **must not** specify a `pod.Spec.TerminationGracePeriodSeconds` of 0. The practice of setting a `pod.Spec.TerminationGracePeriodSeconds` of 0 seconds is unsafe and strongly discouraged for StatefulSet Pods. Graceful deletion is safe and will ensure that the [Pod shuts down gracefully](/docs/user-guide/pods/#termination-of-pods) before the kubelet deletes the name from the apiserver.
-->
<p>为了让上面操作能够体面地终止 Pod，Pod <strong>一定不能</strong> 设置 <code>pod.Spec.TerminationGracePeriodSeconds</code> 为 0。
将 <code>pod.Spec.TerminationGracePeriodSeconds</code> 设置为 0s 的做法是不安全的，强烈建议 StatefulSet 类型的
Pod 不要使用。体面删除是安全的，并且会在 kubelet 从 API 服务器中删除资源名称之前确保
<a href="/zh/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination">体面地结束 pod </a>。</p>
<!--
A Pod is not deleted automatically when a Node is unreachable.
The Pods running on an unreachable Node enter the 'Terminating' or 'Unknown' state after a
[timeout](/docs/concepts/architecture/nodes/#condition).
Pods may also enter these states when the user attempts graceful deletion of a Pod
on an unreachable Node.
The only ways in which a Pod in such a state can be removed from the apiserver are as follows:
-->
<p>当某个节点不可达时，不会引发自动删除 Pod。
在无法访问的节点上运行的 Pod 在
<a href="/zh/docs/concepts/architecture/nodes/#condition">超时</a>
后会进入'Terminating' 或者 'Unknown' 状态。
当用户尝试体面地删除无法访问的节点上的 Pod 时 Pod 也可能会进入这些状态。
从 API 服务器上删除处于这些状态 Pod 的仅有可行方法如下：</p>
<!--
   * The Node object is deleted (either by you, or by the [Node Controller](/docs/admin/node)).<br/>
   * The kubelet on the unresponsive Node starts responding, kills the Pod and removes the entry from the apiserver.<br/>
   * Force deletion of the Pod by the user.
-->
<ul>
<li>删除 Node 对象（要么你来删除, 要么<a href="/zh/docs/concepts/architecture/nodes/#node-controller">节点控制器</a>
来删除）</li>
<li>无响应节点上的 kubelet 开始响应，杀死 Pod 并从 API 服务器上移除 Pod 对象</li>
<li>用户强制删除 pod</li>
</ul>
<!--
The recommended best practice is to use the first or second approach. If a Node is confirmed to be dead (e.g. permanently disconnected from the network, powered down, etc), then delete the Node object. If the Node is suffering from a network partition, then try to resolve this or wait for it to resolve. When the partition heals, the kubelet will complete the deletion of the Pod and free up its name in the apiserver.
-->
<p>推荐使用第一种或者第二种方法。如果确认节点已经不可用了 (比如，永久断开网络、断电等)，
则应删除 Node 对象。
如果节点遇到网裂问题，请尝试解决该问题或者等待其解决。
当网裂愈合时，kubelet 将完成 Pod 的删除并从 API 服务器上释放其名字。</p>
<!--
Normally, the system completes the deletion once the Pod is no longer running on a Node, or the Node is deleted by an administrator. You may override this by force deleting the Pod.
-->
<p>通常，Pod 一旦不在节点上运行，或者管理员删除了节点，系统就会完成其删除动作。
你也可以通过强制删除 Pod 来绕过这一机制。</p>
<!--
### Force Deletion

Force deletions **do not** wait for confirmation from the kubelet that the Pod has been terminated. Irrespective of whether a force deletion is successful in killing a Pod, it will immediately free up the name from the apiserver. This would let the StatefulSet controller create a replacement Pod with that same identity; this can lead to the duplication of a still-running Pod, and if said Pod can still communicate with the other members of the StatefulSet, will violate the at most one semantics that StatefulSet is designed to guarantee.
-->
<h3 id="force-deletion">强制删除   </h3>
<p>强制删除<strong>不会</strong>等待来自 kubelet 对 Pod 已终止的确认消息。
无论强制删除是否成功杀死了 Pod，它都会立即从 API 服务器中释放该名字。
这将让 StatefulSet 控制器创建一个具有相同标识的替身 Pod；因而可能导致正在运行 Pod 的重复，
并且如果所述 Pod 仍然可以与 StatefulSet 的成员通信，则将违反 StatefulSet 所要保证的
最多一个的语义。</p>
<!--
When you force delete a StatefulSet pod, you are asserting that the Pod in question will never again make contact with other Pods in the StatefulSet and its name can be safely freed up for a replacement to be created.
-->
<p>当你强制删除 StatefulSet 类型的 Pod 时，你要确保有问题的 Pod 不会再和 StatefulSet 管理的其他
Pod 通信并且可以安全地释放其名字以便创建替代 Pod。</p>
<!--
If you want to delete a Pod forcibly using kubectl version >= 1.5, do the following:
-->
<p>如果要使用 kubectl 1.5 以上版本强制删除 Pod，请执行下面命令：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl delete pods &lt;pod&gt; --grace-period<span style="color:#666">=</span><span style="color:#666">0</span> --force
</code></pre></div><!--
If you're using any version of kubectl <= 1.4, you should omit the `--force` option and use:
-->
<p>如果你使用 kubectl 的 1.4 以下版本，则应省略 <code>--force</code> 选项：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl delete pods &lt;pod&gt; --grace-period<span style="color:#666">=</span><span style="color:#666">0</span>
</code></pre></div><!--
If even after these commands the pod is stuck on `Unknown` state, use the following command to remove the pod from the cluster:
-->
<p>如果在这些命令后 Pod 仍处于 <code>Unknown</code> 状态，请使用以下命令从集群中删除 Pod:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl patch pod &lt;pod&gt; -p <span style="color:#b44">&#39;{&#34;metadata&#34;:{&#34;finalizers&#34;:null}}&#39;</span>
</code></pre></div><!--
Always perform force deletion of StatefulSet Pods carefully and with complete knowledge of the risks involved.
-->
<p>请始终谨慎地执行强制删除 StatefulSet 类型的 pods，并完全了解所涉及地风险。</p>
<h2 id="what-s-next">What's next</h2>
<!--
Learn more about [debugging a StatefulSet](/docs/tasks/debug-application-cluster/debug-stateful-set/).
-->
<p>进一步了解<a href="/zh/docs/tasks/debug-application-cluster/debug-stateful-set/">调试 StatefulSet</a>。</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-0c0bb1bd76d2a9069e50e2cec6d20c2a">6 - Pod 水平自动扩缩</h1>
    
	<!-- overview -->
<!--
In Kubernetes, a _HorizontalPodAutoscaler_ automatically updates a workload resource (such as
a <a class='glossary-tooltip' title='Deployment 是管理应用副本的 API 对象。' data-toggle='tooltip' data-placement='top' href='/zh/docs/concepts/workloads/controllers/deployment/' target='_blank' aria-label='Deployment'>Deployment</a> or
<a class='glossary-tooltip' title='StatefulSet 用来管理某 Pod 集合的部署和扩缩，并为这些 Pod 提供持久存储和持久标识符。' data-toggle='tooltip' data-placement='top' href='/zh/docs/concepts/workloads/controllers/statefulset/' target='_blank' aria-label='StatefulSet'>StatefulSet</a>), with the
aim of automatically scaling the workload to match demand.
-->
<p>在 Kubernetes 中，<em>HorizontalPodAutoscaler</em> 自动更新工作负载资源
（例如 <a class='glossary-tooltip' title='Deployment 是管理应用副本的 API 对象。' data-toggle='tooltip' data-placement='top' href='/zh/docs/concepts/workloads/controllers/deployment/' target='_blank' aria-label='Deployment'>Deployment</a> 或者
<a class='glossary-tooltip' title='StatefulSet 用来管理某 Pod 集合的部署和扩缩，并为这些 Pod 提供持久存储和持久标识符。' data-toggle='tooltip' data-placement='top' href='/zh/docs/concepts/workloads/controllers/statefulset/' target='_blank' aria-label='StatefulSet'>StatefulSet</a>），
目的是自动扩缩工作负载以满足需求。</p>
<!--
Horizontal scaling means that the response to increased load is to deploy more
<a class='glossary-tooltip' title='Pod 表示您的集群上一组正在运行的容器。' data-toggle='tooltip' data-placement='top' href='/docs/concepts/workloads/pods/pod-overview/' target='_blank' aria-label='Pods'>Pods</a>.
This is different from _vertical_ scaling, which for Kubernetes would mean
assigning more resources (for example: memory or CPU) to the Pods that are already
running for the workload.

If the load decreases, and the number of Pods is above the configured minimum,
the HorizontalPodAutoscaler instructs the workload resource (the Deployment, StatefulSet,
or other similar resource) to scale back down.
-->
<p>水平扩缩意味着对增加的负载的响应是部署更多的 <a class='glossary-tooltip' title='Pod 表示您的集群上一组正在运行的容器。' data-toggle='tooltip' data-placement='top' href='/docs/concepts/workloads/pods/pod-overview/' target='_blank' aria-label='Pods'>Pods</a>。
这与 “垂直（Vertical）” 扩缩不同，对于 Kubernetes，
垂直扩缩意味着将更多资源（例如：内存或 CPU）分配给已经为工作负载运行的 Pod。</p>
<p>如果负载减少，并且 Pod 的数量高于配置的最小值，
HorizontalPodAutoscaler 会指示工作负载资源（ Deployment、StatefulSet 或其他类似资源）缩减。</p>
<!--
Horizontal pod autoscaling does not apply to objects that can't be scaled (for example:
a <a class='glossary-tooltip' title='确保 Pod 的副本在集群中的一组节点上运行。' data-toggle='tooltip' data-placement='top' href='/zh/docs/concepts/workloads/controllers/daemonset/' target='_blank' aria-label='DaemonSet'>DaemonSet</a>.)
-->
<p>水平 Pod 自动扩缩不适用于无法扩缩的对象（例如：<a class='glossary-tooltip' title='确保 Pod 的副本在集群中的一组节点上运行。' data-toggle='tooltip' data-placement='top' href='/zh/docs/concepts/workloads/controllers/daemonset/' target='_blank' aria-label='DaemonSet'>DaemonSet</a>。）</p>
<!--
The HorizontalPodAutoscaler is implemented as a Kubernetes API resource and a
<a class='glossary-tooltip' title='控制器通过 apiserver 监控集群的公共状态，并致力于将当前状态转变为期望的状态。' data-toggle='tooltip' data-placement='top' href='/zh/docs/concepts/architecture/controller/' target='_blank' aria-label='controller'>controller</a>.
The resource determines the behavior of the controller.
The horizontal pod autoscaling controller, running within the Kubernetes
<a class='glossary-tooltip' title='控制平面是指容器编排层，它暴露 API 和接口来定义、部署容器和管理容器的生命周期。' data-toggle='tooltip' data-placement='top' href='/zh/docs/reference/glossary/?all=true#term-control-plane' target='_blank' aria-label='control plane'>control plane</a>, periodically adjusts the
desired scale of its target (for example, a Deployment) to match observed metrics such as average
CPU utilization, average memory utilization, or any other custom metric you specify.
 -->
<p>HorizontalPodAutoscaler 被实现为 Kubernetes API 资源和<a class='glossary-tooltip' title='控制器通过 apiserver 监控集群的公共状态，并致力于将当前状态转变为期望的状态。' data-toggle='tooltip' data-placement='top' href='/zh/docs/concepts/architecture/controller/' target='_blank' aria-label='控制器'>控制器</a>。</p>
<p>资源决定了控制器的行为。在 Kubernetes <a class='glossary-tooltip' title='控制平面是指容器编排层，它暴露 API 和接口来定义、部署容器和管理容器的生命周期。' data-toggle='tooltip' data-placement='top' href='/zh/docs/reference/glossary/?all=true#term-control-plane' target='_blank' aria-label='控制平面'>控制平面</a>内运行的水平
Pod 自动扩缩控制器会定期调整其目标（例如：Deployment）的所需规模，以匹配观察到的指标，
例如，平均 CPU 利用率、平均内存利用率或你指定的任何其他自定义指标。</p>
<!--
There is [walkthrough example](/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/) of using
horizontal pod autoscaling.
-->
<p>使用水平 Pod 自动扩缩<a href="/zh/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/">演练示例</a>。</p>
<!-- body -->
<!--
## How does a HorizontalPodAutoscaler work?
-->
<h2 id="how-does-a-horizontalpodautoscaler-work">HorizontalPodAutoscaler 是如何工作的？</h2>

<figure class="diagram-medium">
    <img src="/images/docs/horizontal-pod-autoscaler.svg"
         alt="HorizontalPodAutoscaler 控制 Deployment 及其 ReplicaSet 的规模"/> <figcaption>
            <p>HorizontalPodAutoscaler 控制 Deployment 及其 ReplicaSet 的规模</p>
        </figcaption>
</figure>

<!--
Kubernetes implements horizontal pod autoscaling as a control loop that runs intermittently
(it is not a continuous process). The interval is set by the
`--horizontal-pod-autoscaler-sync-period` parameter to the
[`kube-controller-manager`](/docs/reference/command-line-tools-reference/kube-controller-manager/)
(and the default interval is 15 seconds).
-->
<p>Kubernetes 将水平 Pod 自动扩缩实现为一个间歇运行的控制回路（它不是一个连续的过程）。间隔由
<a href="/zh/docs/reference/command-line-tools-reference/kube-controller-manager/"><code>kube-controller-manager</code></a>
的 <code>--horizontal-pod-autoscaler-sync-period</code> 参数设置（默认间隔为 15 秒）。</p>
<!--
Once during each period, the controller manager queries the resource utilization against the
metrics specified in each HorizontalPodAutoscaler definition.  The controller manager 
finds the target resource defined by the `scaleTargetRef`,
then selects the pods based on the target resource's `.spec.selector` labels, and obtains the metrics from either the resource metrics API (for per-pod resource metrics),
or the custom metrics API (for all other metrics).
-->
<p>在每个时间段内，控制器管理器都会根据每个 HorizontalPodAutoscaler 定义中指定的指标查询资源利用率。
控制器管理器找到由 <code>scaleTargetRef</code> 定义的目标资源，然后根据目标资源的 <code>.spec.selector</code> 标签选择 Pod，
并从资源指标 API（针对每个 Pod 的资源指标）或自定义指标获取指标 API（适用于所有其他指标）。</p>
<!--
* For per-pod resource metrics (like CPU), the controller fetches the metrics
  from the resource metrics API for each Pod targeted by the HorizontalPodAutoscaler.
  Then, if a target utilization value is set, the controller calculates the utilization
  value as a percentage of the equivalent [resource request](/docs/concepts/configuration/manage-resources-containers/#requests-and-limits) on the containers in
  each Pod.  If a target raw value is set, the raw metric values are used directly.
  The controller then takes the mean of the utilization or the raw value (depending on the type
  of target specified) across all targeted Pods, and produces a ratio used to scale
  the number of desired replicas.
-->
<ul>
<li>
<p>对于按 Pod 统计的资源指标（如 CPU），控制器从资源指标 API 中获取每一个
HorizontalPodAutoscaler 指定的 Pod 的度量值，如果设置了目标使用率，
控制器获取每个 Pod 中的容器<a href="/zh/docs/concepts/configuration/manage-resources-containers/#requests-and-limits">资源使用</a> 情况，
并计算资源使用率。如果设置了 target 值，将直接使用原始数据（不再计算百分比）。
接下来，控制器根据平均的资源使用率或原始值计算出扩缩的比例，进而计算出目标副本数。</p>
<!--
Please note that if some of the Pod's containers do not have the relevant resource request set,
CPU utilization for the Pod will not be defined and the autoscaler will
not take any action for that metric. See the [algorithm
details](#algorithm-details) section below for more information about
how the autoscaling algorithm works.
-->
<p>需要注意的是，如果 Pod 某些容器不支持资源采集，那么控制器将不会使用该 Pod 的 CPU 使用率。
下面的<a href="#algorithm-details">算法细节</a>章节将会介绍详细的算法。</p>
</li>
</ul>
<!--
* For per-pod custom metrics, the controller functions similarly to per-pod resource metrics,
  except that it works with raw values, not utilization values.
-->
<ul>
<li>如果 Pod 使用自定义指示，控制器机制与资源指标类似，区别在于自定义指标只使用
原始值，而不是使用率。</li>
</ul>
<!--
* For object metrics and external metrics, a single metric is fetched, which describes
  the object in question. This metric is compared to the target
  value, to produce a ratio as above. In the `autoscaling/v2beta2` API
  version, this value can optionally be divided by the number of Pods before the
  comparison is made.
-->
<ul>
<li>如果 Pod 使用对象指标和外部指标（每个指标描述一个对象信息）。
这个指标将直接根据目标设定值相比较，并生成一个上面提到的扩缩比例。
在 <code>autoscaling/v2beta2</code> 版本 API 中，这个指标也可以根据 Pod 数量平分后再计算。</li>
</ul>
<!--
The common use for HorizontalPodAutoscaler is to configure it to fetch metrics from
<a class='glossary-tooltip' title='聚合层允许您在自己的集群上安装额外的 Kubernetes 风格的 API。' data-toggle='tooltip' data-placement='top' href='/zh/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/' target='_blank' aria-label='aggregated APIs'>aggregated APIs</a>
(`metrics.k8s.io`, `custom.metrics.k8s.io`, or `external.metrics.k8s.io`).  The `metrics.k8s.io` API is
usually provided by an add-on named Metrics Server, which needs to be launched separately.
For more information about resource metrics, see
[Metrics Server](/docs/tasks/debug/debug-cluster/resource-metrics-pipeline/#metrics-server).
-->
<p>HorizontalPodAutoscaler 的常见用途是将其配置为从<a class='glossary-tooltip' title='聚合层允许您在自己的集群上安装额外的 Kubernetes 风格的 API。' data-toggle='tooltip' data-placement='top' href='/zh/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/' target='_blank' aria-label='聚合 API'>聚合 API</a>
（<code>metrics.k8s.io</code>、<code>custom.metrics.k8s.io</code> 或 <code>external.metrics.k8s.io</code>）获取指标。
<code>metrics.k8s.io</code> API 通常由名为 Metrics Server 的插件提供，需要单独启动。有关资源指标的更多信息，
请参阅 <a href="/zh/docs/tasks/debug/debug-cluster/resource-metrics-pipeline/#metrics-server">Metrics Server</a>。</p>
<!--
[Support for metrics APIs](#support-for-metrics-apis) explains the stability guarantees and support status for these
different APIs.

The HorizontalPodAutoscaler controller accesses corresponding workload resources that support scaling (such as Deployments
and StatefulSet). These resources each have a subresource named `scale`, an interface that allows you to dynamically set the
number of replicas and examine each of their current states.
For general information about subresources in the Kubernetes API, see
[Kubernetes API Concepts](/docs/reference/using-api/api-concepts/).
-->
<p>对 <a href="#support-for-metrics-apis">Metrics API 的支持</a>解释了这些不同 API 的稳定性保证和支持状态</p>
<p>HorizontalPodAutoscaler 控制器访问支持扩缩的相应工作负载资源（例如：Deployments 和 StatefulSet）。
这些资源每个都有一个名为 <code>scale</code> 的子资源，该接口允许你动态设置副本的数量并检查它们的每个当前状态。
有关 Kubernetes API 子资源的一般信息，
请参阅 <a href="/zh/docs/reference/using-api/api-concepts/">Kubernetes API 概念</a>。</p>
<!--
### Algorithm Details

From the most basic perspective, the Horizontal Pod Autoscaler controller
operates on the ratio between desired metric value and current metric
value:
-->
<h3 id="algorithm-details">算法细节  </h3>
<p>从最基本的角度来看，Pod 水平自动扩缩控制器根据当前指标和期望指标来计算扩缩比例。</p>
<!--
```
desiredReplicas = ceil[currentReplicas * ( currentMetricValue / desiredMetricValue )]
```
-->
<pre><code>期望副本数 = ceil[当前副本数 * (当前指标 / 期望指标)]
</code></pre><!--
For example, if the current metric value is `200m`, and the desired value
is `100m`, the number of replicas will be doubled, since `200.0 / 100.0 ==
2.0` If the current value is instead `50m`, you'll halve the number of
replicas, since `50.0 / 100.0 == 0.5`.  The control plane skips any scaling
action if the ratio is sufficiently close to 1.0 (within a globally-configurable
tolerance, 0.1 by default).
-->
<p>例如，如果当前指标值为 <code>200m</code>，而期望值为 <code>100m</code>，则副本数将加倍，
因为 <code>200.0 / 100.0 == 2.0</code> 如果当前值为 <code>50m</code>，则副本数将减半，
因为 <code>50.0 / 100.0 == 0.5</code>。如果比率足够接近 1.0（在全局可配置的容差范围内，默认为 0.1），
则控制平面会跳过扩缩操作。</p>
<!--
When a `targetAverageValue` or `targetAverageUtilization` is specified,
the `currentMetricValue` is computed by taking the average of the given
metric across all Pods in the HorizontalPodAutoscaler's scale target.

Before checking the tolerance and deciding on the final values, the control
plane also considers whether any metrics are missing, and how many Pods
are [`Ready`](/docs/concepts/workloads/pods/pod-lifecycle/#pod-conditions).
-->
<p>如果 HorizontalPodAutoscaler 指定的是 <code>targetAverageValue</code> 或 <code>targetAverageUtilization</code>，
那么将会把指定 Pod 度量值的平均值做为 <code>currentMetricValue</code>。</p>
<p>在检查容差并决定最终值之前，控制平面还会考虑是否缺少任何指标，
以及有多少 Pod <a href="/zh/docs/concepts/workloads/pods/pod-lifecycle/#pod-conditions"><code>已就绪</code></a>。</p>
<!--
All Pods with a deletion timestamp set (objects with a deletion timestamp are
in the process of being shut down / removed) are ignored, and all failed Pods
are discarded.

If a particular Pod is missing metrics, it is set aside for later; Pods
with missing metrics will be used to adjust the final scaling amount.
-->
<p>所有设置了删除时间戳的 Pod（带有删除时间戳的对象正在关闭/移除的过程中）都会被忽略，
所有失败的 Pod 都会被丢弃。</p>
<p>如果某个 Pod 缺失度量值，它将会被搁置，只在最终确定扩缩数量时再考虑。</p>
<!--
When scaling on CPU, if any pod has yet to become ready (it's still
initializing, or possibly is unhealthy) *or* the most recent metric point for the pod was before it
became ready, that pod is set aside as well.
-->
<p>当使用 CPU 指标来扩缩时，任何还未就绪（还在初始化，或者可能是不健康的）状态的 Pod <strong>或</strong>
最近的指标度量值采集于就绪状态前的 Pod，该 Pod 也会被搁置。</p>
<!--
Due to technical constraints, the HorizontalPodAutoscaler controller
cannot exactly determine the first time a pod becomes ready when
determining whether to set aside certain CPU metrics. Instead, it
considers a Pod "not yet ready" if it's unready and transitioned to
unready within a short, configurable window of time since it started.
This value is configured with the `--horizontal-pod-autoscaler-initial-readiness-delay` flag, and its default is 30
seconds.  Once a pod has become ready, it considers any transition to
ready to be the first if it occurred within a longer, configurable time
since it started. This value is configured with the `--horizontal-pod-autoscaler-cpu-initialization-period` flag, and its
default is 5 minutes.
-->
<p>由于技术限制，HorizontalPodAutoscaler 控制器在确定是否保留某些 CPU 指标时无法准确确定 Pod 首次就绪的时间。
相反，如果 Pod 未准备好并在其启动后的一个可配置的短时间窗口内转换为未准备好，它会认为 Pod “尚未准备好”。
该值使用 <code>--horizontal-pod-autoscaler-initial-readiness-delay</code> 标志配置，默认值为 30 秒。
一旦 Pod 准备就绪，如果它发生在自启动后较长的、可配置的时间内，它就会认为任何向准备就绪的转换都是第一个。
该值由 <code>-horizontal-pod-autoscaler-cpu-initialization-period</code> 标志配置，默认为 5 分钟。</p>
<!--
The `currentMetricValue / desiredMetricValue` base scale ratio is then
calculated using the remaining pods not set aside or discarded from above.
-->
<p>在排除掉被搁置的 Pod 后，扩缩比例就会根据 <code>currentMetricValue/desiredMetricValue</code>
计算出来。</p>
<!--
If there were any missing metrics, the control plane recomputes the average more
conservatively, assuming those pods were consuming 100% of the desired
value in case of a scale down, and 0% in case of a scale up.  This dampens
the magnitude of any potential scale.
-->
<p>如果缺失某些度量值，控制平面会更保守地重新计算平均值，在需要缩小时假设这些 Pod 消耗了目标值的 100%，
在需要放大时假设这些 Pod 消耗了 0% 目标值。这可以在一定程度上抑制扩缩的幅度。</p>
<!--
Furthermore, if any not-yet-ready pods were present, and the workload would have
scaled up without factoring in missing metrics or not-yet-ready pods,
the controller conservatively assumes that the not-yet-ready pods are consuming 0%
of the desired metric, further dampening the magnitude of a scale up.
-->
<p>此外，如果存在任何尚未就绪的 Pod，工作负载会在不考虑遗漏指标或尚未就绪的 Pod 的情况下进行扩缩，
控制器保守地假设尚未就绪的 Pod 消耗了期望指标的 0%，从而进一步降低了扩缩的幅度。</p>
<!--
After factoring in the not-yet-ready pods and missing metrics, the
controller recalculates the usage ratio.  If the new ratio reverses the scale
direction, or is within the tolerance, the controller doesn't take any scaling
action. In other cases, the new ratio is used to decide any change to the
number of Pods.
-->
<p>考虑到尚未准备好的 Pod 和缺失的指标后，控制器会重新计算使用率。
如果新的比率与扩缩方向相反，或者在容差范围内，则控制器不会执行任何扩缩操作。
在其他情况下，新比率用于决定对 Pod 数量的任何更改。</p>
<!--
Note that the *original* value for the average utilization is reported
back via the HorizontalPodAutoscaler status, without factoring in the
not-yet-ready pods or missing metrics, even when the new usage ratio is
used.
-->
<p>注意，平均利用率的 <strong>原始</strong> 值是通过 HorizontalPodAutoscaler 状态体现的，
而不考虑尚未准备好的 Pod 或缺少的指标，即使使用新的使用率也是如此。</p>
<!--
If multiple metrics are specified in a HorizontalPodAutoscaler, this
calculation is done for each metric, and then the largest of the desired
replica counts is chosen. If any of these metrics cannot be converted
into a desired replica count (e.g. due to an error fetching the metrics
from the metrics APIs) and a scale down is suggested by the metrics which
can be fetched, scaling is skipped. This means that the HPA is still capable
of scaling up if one or more metrics give a `desiredReplicas` greater than
the current value.
-->
<p>如果创建 HorizontalPodAutoscaler 时指定了多个指标，
那么会按照每个指标分别计算扩缩副本数，取最大值进行扩缩。
如果任何一个指标无法顺利地计算出扩缩副本数（比如，通过 API 获取指标时出错），
并且可获取的指标建议缩容，那么本次扩缩会被跳过。
这表示，如果一个或多个指标给出的 <code>desiredReplicas</code> 值大于当前值，HPA 仍然能实现扩容。</p>
<!--
Finally, right before HPA scales the target, the scale recommendation is recorded.  The
controller considers all recommendations within a configurable window choosing the
highest recommendation from within that window. This value can be configured using the `--horizontal-pod-autoscaler-downscale-stabilization` flag, which defaults to 5 minutes.
This means that scaledowns will occur gradually, smoothing out the impact of rapidly
fluctuating metric values.
-->
<p>最后，在 HPA 控制器执行扩缩操作之前，会记录扩缩建议信息。
控制器会在操作时间窗口中考虑所有的建议信息，并从中选择得分最高的建议。
这个值可通过 <code>kube-controller-manager</code> 服务的启动参数
<code>--horizontal-pod-autoscaler-downscale-stabilization</code> 进行配置，
默认值为 5 分钟。
这个配置可以让系统更为平滑地进行缩容操作，从而消除短时间内指标值快速波动产生的影响。</p>
<!--
## API Object

The Horizontal Pod Autoscaler is an API resource in the Kubernetes
`autoscaling` API group.  The current stable version can be found in
the `autoscaling/v2` API version which includes support for scaling on
memory and custom metrics. The new fields introduced in
`autoscaling/v2` are preserved as annotations when working with
`autoscaling/v1`.
-->
<h2 id="api-object">API 对象  </h2>
<p>HorizontalPodAutoscaler 是 Kubernetes <code>autoscaling</code> API 组中的 API 资源。
当前的稳定版本可以在 <code>autoscaling/v2</code> API 版本中找到，其中包括对基于内存和自定义指标执行扩缩的支持。
在使用 <code>autoscaling/v1</code> 时，<code>autoscaling/v2</code> 中引入的新字段作为注释保留。</p>
<!--
When you create a HorizontalPodAutoscaler API object, make sure the name specified is a valid
[DNS subdomain name](/docs/concepts/overview/working-with-objects/names#dns-subdomain-names).
More details about the API object can be found at
[HorizontalPodAutoscaler Object](/docs/reference/generated/kubernetes-api/v1.23/#horizontalpodautoscaler-v2-autoscaling).
-->
<p>创建 HorizontalPodAutoscaler 对象时，需要确保所给的名称是一个合法的
<a href="/zh/docs/concepts/overview/working-with-objects/names#dns-subdomain-names">DNS 子域名</a>。
有关 API 对象的更多信息，请查阅
<a href="/docs/reference/generated/kubernetes-api/v1.23/#horizontalpodautoscaler-v2-autoscaling">HorizontalPodAutoscaler 对象设计文档</a>。</p>
<!--
## Stability of workload scale {#flapping}

When managing the scale of a group of replicas using the HorizontalPodAutoscaler,
it is possible that the number of replicas keeps fluctuating frequently due to the
dynamic nature of the metrics evaluated. This is sometimes referred to as *thrashing*,
or *flapping*. It's similar to the concept of *hysteresis* in cybernetics.
-->
<h2 id="flapping">工作量规模的稳定性</h2>
<p>在使用 HorizontalPodAutoscaler 管理一组副本的规模时，由于评估的指标的动态特性，
副本的数量可能会经常波动。这有时被称为 <strong>抖动（thrashing）</strong> 或 <strong>波动（flapping）</strong>。它类似于控制论中的 <strong>滞后（hysteresis）</strong> 概念。</p>
<!--
## Autoscaling during rolling update

Kubernetes lets you perform a rolling update on a Deployment. In that
case, the Deployment manages the underlying ReplicaSets for you.
When you configure autoscaling for a Deployment, you bind a
HorizontalPodAutoscaler to a single Deployment. The HorizontalPodAutoscaler
manages the `replicas` field of the Deployment. The deployment controller is responsible
for setting the `replicas` of the underlying ReplicaSets so that they add up to a suitable
number during the rollout and also afterwards.
-->
<h2 id="autoscaling-during-rolling-update">滚动升级时扩缩  </h2>
<p>Kubernetes 允许你在 Deployment 上执行滚动更新。在这种情况下，Deployment 为你管理下层的 ReplicaSet。
当你为一个 Deployment 配置自动扩缩时，你要为每个 Deployment 绑定一个 HorizontalPodAutoscaler。
HorizontalPodAutoscaler 管理 Deployment 的 <code>replicas</code> 字段。
Deployment Controller 负责设置下层 ReplicaSet 的 <code>replicas</code> 字段，
以便确保在上线及后续过程副本个数合适。</p>
<!--
If you perform a rolling update of a StatefulSet that has an autoscaled number of
replicas, the StatefulSet directly manages its set of Pods (there is no intermediate resource
similar to ReplicaSet).
-->
<p>如果你对一个副本个数被自动扩缩的 StatefulSet 执行滚动更新， 该 StatefulSet
会直接管理它的 Pod 集合 （不存在类似 ReplicaSet 这样的中间资源）。</p>
<!--
## Support for resource metrics

Any HPA target can be scaled based on the resource usage of the pods in the scaling target.
When defining the pod specification the resource requests like `cpu` and `memory` should
be specified. This is used to determine the resource utilization and used by the HPA controller
to scale the target up or down. To use resource utilization based scaling specify a metric source
like this:
-->
<h2 id="support-for-resource-metrics">对资源指标的支持  </h2>
<p>HPA 的任何目标资源都可以基于其中的 Pods 的资源用量来实现扩缩。
在定义 Pod 规约时，类似 <code>cpu</code> 和 <code>memory</code> 这类资源请求必须被设定。
这些设定值被用来确定资源利用量并被 HPA 控制器用来对目标资源完成扩缩操作。
要使用基于资源利用率的扩缩，可以像下面这样指定一个指标源：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Resource<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">resource</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>cpu<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">target</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Utilization<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">averageUtilization</span>:<span style="color:#bbb"> </span><span style="color:#666">60</span><span style="color:#bbb">
</span></code></pre></div><!--
With this metric the HPA controller will keep the average utilization of the pods in the scaling
target at 60%. Utilization is the ratio between the current usage of resource to the requested
resources of the pod. See [Algorithm](#algorithm-details) for more details about how the utilization
is calculated and averaged.
-->
<p>基于这一指标设定，HPA 控制器会维持扩缩目标中的 Pods 的平均资源利用率在 60%。
利用率是 Pod 的当前资源用量与其请求值之间的比值。关于如何计算利用率以及如何计算平均值
的细节可参考<a href="#algorithm-details">算法</a>小节。</p>
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> <!--
Since the resource usages of all the containers are summed up the total pod utilization may not
accurately represent the individual container resource usage. This could lead to situations where
a single container might be running with high usage and the HPA will not scale out because the overall
pod usage is still within acceptable limits.
-->
<p>由于所有的容器的资源用量都会被累加起来，Pod 的总体资源用量值可能不会精确体现
各个容器的资源用量。这一现象也会导致一些问题，例如某个容器运行时的资源用量非常
高，但因为 Pod 层面的资源用量总值让人在可接受的约束范围内，HPA 不会执行扩大
目标对象规模的操作。
</div>
<!--
### Container Resource Metrics
-->
<h3 id="container-resource-metrics">容器资源指标  </h3>





<div style="margin-top: 10px; margin-bottom: 10px;">
  <b>FEATURE STATE:</b> <code>Kubernetes v1.20 [alpha]</code>
</div>


<!--
The HorizontalPodAutoscaler API also supports a container metric source where the HPA can track the
resource usage of individual containers across a set of Pods, in order to scale the target resource.
This lets you configure scaling thresholds for the containers that matter most in a particular Pod.
For example, if you have a web application and a logging sidecar, you can scale based on the resource
use of the web application, ignoring the sidecar container and its resource use.
-->
<p>HorizontalPodAutoscaler API 也支持容器指标源，这时 HPA 可以跟踪记录一组 Pods 中各个容器的
资源用量，进而触发扩缩目标对象的操作。
容器资源指标的支持使得你可以为特定 Pod 中最重要的容器配置规模扩缩阈值。
例如，如果你有一个 Web 应用和一个执行日志操作的边车容器，你可以基于 Web 应用的
资源用量来执行扩缩，忽略边车容器的存在及其资源用量。</p>
<!--
If you revise the target resource to have a new Pod specification with a different set of containers,
you should revise the HPA spec if that newly added container should also be used for
scaling. If the specified container in the metric source is not present or only present in a subset
of the pods then those pods are ignored and the recommendation is recalculated. See [Algorithm](#algorithm-details)
for more details about the calculation. To use container resources for autoscaling define a metric
source as follows:
-->
<p>如果你更改扩缩目标对象，令其使用新的、包含一组不同的容器的 Pod 规约，你就需要
修改 HPA 的规约才能基于新添加的容器来执行规模扩缩操作。
如果指标源中指定的容器不存在或者仅存在于部分 Pods 中，那么这些 Pods 会被忽略，
HPA 会重新计算资源用量值。参阅<a href="#algorithm-details">算法</a>小节进一步了解计算细节。
要使用容器资源用量来完成自动扩缩，可以像下面这样定义指标源：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>ContainerResource<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">containerResource</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>cpu<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">container</span>:<span style="color:#bbb"> </span>application<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">target</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Utilization<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">averageUtilization</span>:<span style="color:#bbb"> </span><span style="color:#666">60</span><span style="color:#bbb">
</span></code></pre></div><!--
In the above example the HPA controller scales the target such that the average utilization of the cpu
in the `application` container of all the pods is 60%.
-->
<p>在上面的例子中，HPA 控制器会对目标对象执行扩缩操作以确保所有 Pods 中
<code>application</code> 容器的平均 CPU 用量为 60%。</p>
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> <!--
If you change the name of a container that a HorizontalPodAutoscaler is tracking, you can
make that change in a specific order to ensure scaling remains available and effective
whilst the change is being applied. Before you update the resource that defines the container
(such as a Deployment), you should update the associated HPA to track both the new and
old container names. This way, the HPA is able to calculate a scaling recommendation
throughout the update process.
-->
<p>如果你要更改 HorizontalPodAutoscaler 所跟踪记录的容器的名称，你可以按一定顺序
来执行这一更改，确保在应用更改的过程中用来判定扩缩行为的容器可用。
在更新定义容器的资源（如 Deployment）之前，你需要更新相关的 HPA，使之能够同时
跟踪记录新的和老的容器名称。这样，HPA 就能够在整个更新过程中继续计算并提供扩缩操作建议。</p>
<!--
Once you have rolled out the container name change to the workload resource, tidy up by removing
the old container name from the HPA specification.
-->
<p>一旦你已经将容器名称变更这一操作应用到整个负载对象至上，就可以从 HPA
的规约中去掉老的容器名称，完成清理操作。</p>

</div>
<!--
## Scaling on custom metrics

(the `autoscaling/v2beta2` API version previously provided this ability as a beta feature)

Provided that you use the `autoscaling/v2` API version, you can configure a HorizontalPodAutoscaler
to scale based on a custom metric (that is not built in to Kubernetes or any Kubernetes component).
The HorizontalPodAutoscaler controller then queries for these custom metrics from the Kubernetes
API.

See [Support for metrics APIs](#support-for-metrics-apis) for the requirements.
-->
<h2 id="scaling-on-custom-metrics">扩展自定义指标</h2>





<div style="margin-top: 10px; margin-bottom: 10px;">
  <b>FEATURE STATE:</b> <code>Kubernetes v1.23 [stable]</code>
</div>


<p>（之前的 <code>autoscaling/v2beta2</code> API 版本将此功能作为 beta 功能提供）</p>
<p>如果你使用 <code>autoscaling/v2</code> API 版本，则可以将 HorizontalPodAutoscaler
配置为基于自定义指标（未内置于 Kubernetes 或任何 Kubernetes 组件）进行扩缩。
HorizontalPodAutoscaler 控制器能够从 Kubernetes API 查询这些自定义指标。</p>
<p>有关要求，请参阅对 <a href="#support-for-metrics-apis">Metrics APIs 的支持</a>。</p>
<!--
## Scaling on multiple metrics

(the `autoscaling/v2beta2` API version previously provided this ability as a beta feature)

Provided that you use the `autoscaling/v2` API version, you can specify multiple metrics for a
HorizontalPodAutoscaler to scale on. Then, the HorizontalPodAutoscaler controller evaluates each metric,
and proposes a new scale based on that metric. The HorizontalPodAutoscaler takes the maximum scale
recommended for each metric and sets the workload to that size (provided that this isn't larger than the
overall maximum that you configured).
-->
<h2 id="scaling-on-multiple-metrics">基于多个指标来执行扩缩</h2>





<div style="margin-top: 10px; margin-bottom: 10px;">
  <b>FEATURE STATE:</b> <code>Kubernetes v1.23 [stable]</code>
</div>


<p>（之前的 <code>autoscaling/v2beta2</code> API 版本将此功能作为 beta 功能提供）</p>
<p>如果你使用 <code>autoscaling/v2</code> API 版本，你可以为 HorizontalPodAutoscaler 指定多个指标以进行扩缩。
HorizontalPodAutoscaler 控制器评估每个指标，并根据该指标提出一个新的比例。
HorizontalPodAutoscaler 采用为每个指标推荐的最大比例，
并将工作负载设置为该大小（前提是这不大于你配置的总体最大值）。</p>
<!--
## Support for metrics APIs

By default, the HorizontalPodAutoscaler controller retrieves metrics from a series of APIs.  In order for it to access these
APIs, cluster administrators must ensure that:
-->
<h2 id="support-for-metrics-apis">对 Metrics API 的支持  </h2>
<p>默认情况下，HorizontalPodAutoscaler 控制器会从一系列的 API 中检索度量值。
集群管理员需要确保下述条件，以保证 HPA 控制器能够访问这些 API：</p>
<!--
* The [API aggregation layer](/docs/tasks/extend-kubernetes/configure-aggregation-layer/) is enabled.

* The corresponding APIs are registered:

   * For resource metrics, this is the `metrics.k8s.io` API, generally provided by [metrics-server](https://github.com/kubernetes-sigs/metrics-server).
     It can be launched as a cluster addon.

   * For custom metrics, this is the `custom.metrics.k8s.io` API.  It's provided by "adapter" API servers provided by metrics solution vendors.
     Check with your metrics pipeline to see if there is a Kubernetes metrics adapter available.

   * For external metrics, this is the `external.metrics.k8s.io` API.  It may be provided by the custom metrics adapters provided above.
-->
<ul>
<li>
<p>启用了 <a href="/zh/docs/tasks/extend-kubernetes/configure-aggregation-layer/">API 聚合层</a></p>
</li>
<li>
<p>相应的 API 已注册：</p>
<ul>
<li>
<p>对于资源指标，将使用 <code>metrics.k8s.io</code> API，一般由 <a href="https://github.com/kubernetes-incubator/metrics-server">metrics-server</a> 提供。
它可以作为集群插件启动。</p>
</li>
<li>
<p>对于自定义指标，将使用 <code>custom.metrics.k8s.io</code> API。
它由其他度量指标方案厂商的“适配器（Adapter）” API 服务器提供。
检查你的指标管道以查看是否有可用的 Kubernetes 指标适配器。</p>
</li>
<li>
<p>对于外部指标，将使用 <code>external.metrics.k8s.io</code> API。可能由上面的自定义指标适配器提供。</p>
</li>
</ul>
</li>
</ul>
<!--  
For more information on these different metrics paths and how they differ please see the relevant design proposals for
[the HPA V2](https://github.com/kubernetes/design-proposals-archive/blob/main/autoscaling/hpa-v2.md),
[custom.metrics.k8s.io](https://github.com/kubernetes/design-proposals-archive/blob/main/instrumentation/custom-metrics-api.md)
and [external.metrics.k8s.io](https://github.com/kubernetes/design-proposals-archive/blob/main/instrumentation/external-metrics-api.md).
-->
<p>关于指标来源以及其区别的更多信息，请参阅相关的设计文档，
<a href="https://github.com/kubernetes/design-proposals-archive/blob/main/autoscaling/hpa-v2.md">HPA V2</a>，
<a href="https://github.com/kubernetes/design-proposals-archive/blob/main/instrumentation/custom-metrics-api.md">custom.metrics.k8s.io</a> 和
<a href="https://github.com/kubernetes/design-proposals-archive/blob/main/instrumentation/external-metrics-api.md">external.metrics.k8s.io</a>。</p>
<!--
For examples of how to use them see [the walkthrough for using custom metrics](/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#autoscaling-on-multiple-metrics-and-custom-metrics)
and [the walkthrough for using external metrics](/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#autoscaling-on-metrics-not-related-to-kubernetes-objects).
-->
<p>关于如何使用它们的示例，请参考
<a href="/zh/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#autoscaling-on-multiple-metrics-and-custom-metrics">使用自定义指标的教程</a>
和<a href="/zh/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#autoscaling-on-metrics-not-related-to-kubernetes-objects">使用外部指标的教程</a>。</p>
<!--  
## Configurable scaling behavior

(the `autoscaling/v2beta2` API version previously provided this ability as a beta feature)

If you use the `v2` HorizontalPodAutoscaler API, you can use the `behavior` field
(see the [API reference](/docs/reference/kubernetes-api/workload-resources/horizontal-pod-autoscaler-v2/#HorizontalPodAutoscalerSpec))
to configure separate scale-up and scale-down behaviors.
You specify these behaviours by setting `scaleUp` and / or `scaleDown`
under the `behavior` field.
-->
<h2 id="configurable-scaling-behavior">可配置的扩缩行为</h2>





<div style="margin-top: 10px; margin-bottom: 10px;">
  <b>FEATURE STATE:</b> <code>Kubernetes v1.23 [stable]</code>
</div>


<p>（之前的 <code>autoscaling/v2beta2</code> API 版本将此功能作为 beta 功能提供）</p>
<p>如果你使用 <code>v2</code> HorizontalPodAutoscaler API，你可以使用 <code>behavior</code> 字段
（请参阅 <a href="/zh/docs/reference/kubernetes-api/workload-resources/horizontal-pod-autoscaler-v2/#HorizontalPodAutoscalerSpec">API 参考</a>）
来配置单独的放大和缩小行为。你可以通过在行为字段下设置 <code>scaleUp</code> 和/或 <code>scaleDown</code> 来指定这些行为。</p>
<!--
You can specify a _stabilization window_ that prevents [flapping](#flapping)
the replica count for a scaling target. Scaling policies also let you controls the
rate of change of replicas while scaling.
-->
<p>你可以指定一个 “稳定窗口” ，以防止扩缩目标的副本计数发生<a href="#flapping">波动</a>。
扩缩策略还允许你在扩缩时控制副本的变化率。</p>
<!--  
### Scaling Policies

One or more scaling policies can be specified in the `behavior` section of the spec.
When multiple policies are specified the policy which allows the highest amount of
change is the policy which is selected by default. The following example shows this behavior
while scaling down:
-->
<h3 id="scaling-policies">扩缩策略</h3>
<p>可以在规约的 <code>behavior</code> 部分中指定一个或多个扩缩策略。当指定多个策略时，
允许最大更改量的策略是默认选择的策略。以下示例显示了缩小时的这种行为：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">behavior</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">scaleDown</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">policies</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span>- <span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Pods<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">value</span>:<span style="color:#bbb"> </span><span style="color:#666">4</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">periodSeconds</span>:<span style="color:#bbb"> </span><span style="color:#666">60</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span>- <span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Percent<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">value</span>:<span style="color:#bbb"> </span><span style="color:#666">10</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">periodSeconds</span>:<span style="color:#bbb"> </span><span style="color:#666">60</span><span style="color:#bbb">
</span></code></pre></div><!--  
`periodSeconds` indicates the length of time in the past for which the policy must hold true.
The first policy _(Pods)_ allows at most 4 replicas to be scaled down in one minute. The second policy
_(Percent)_ allows at most 10% of the current replicas to be scaled down in one minute.

Since by default the policy which allows the highest amount of change is selected, the second policy will
only be used when the number of pod replicas is more than 40. With 40 or less replicas, the first policy will be applied.
For instance if there are 80 replicas and the target has to be scaled down to 10 replicas
then during the first step 8 replicas will be reduced. In the next iteration when the number
of replicas is 72, 10% of the pods is 7.2 but the number is rounded up to 8. On each loop of
the autoscaler controller the number of pods to be change is re-calculated based on the number
of current replicas. When the number of replicas falls below 40 the first policy _(Pods)_ is applied
and 4 replicas will be reduced at a time.
-->
<p><code>periodSeconds</code> 表示在过去的多长时间内要求策略值为真。
第一个策略（Pods）允许在一分钟内最多缩容 4 个副本。第二个策略（Percent）
允许在一分钟内最多缩容当前副本个数的百分之十。</p>
<p>由于默认情况下会选择容许更大程度作出变更的策略，只有 Pod 副本数大于 40 时，
第二个策略才会被采用。如果副本数为 40 或者更少，则应用第一个策略。
例如，如果有 80 个副本，并且目标必须缩小到 10 个副本，那么在第一步中将减少 8 个副本。
在下一轮迭代中，当副本的数量为 72 时，10% 的 Pod 数为 7.2，但是这个数字向上取整为 8。
在 autoscaler 控制器的每个循环中，将根据当前副本的数量重新计算要更改的 Pod 数量。
当副本数量低于 40 时，应用第一个策略（Pods），一次减少 4 个副本。</p>
<!--  
The policy selection can be changed by specifying the `selectPolicy` field for a scaling
direction. By setting the value to `Min` which would select the policy which allows the
smallest change in the replica count. Setting the value to `Disabled` completely disables
scaling in that direction.
-->
<p>可以指定扩缩方向的 <code>selectPolicy</code> 字段来更改策略选择。
通过设置 <code>Min</code> 的值，它将选择副本数变化最小的策略。
将该值设置为 <code>Disabled</code> 将完全禁用该方向的扩缩。</p>
<!--  
### Stabilization Window

The stabilization window is used to restrict the [flapping](#flapping) of
replicas count when the metrics used for scaling keep fluctuating. The autoscaling algorithm
uses this window to infer a previous desired state and avoid unwanted changes to workload
scale.

For example, in the following example snippet, a stabilization window is specified for `scaleDown`.
-->
<h3 id="stabilization-window">稳定窗口</h3>
<p>当用于扩缩的指标不断波动时，稳定窗口用于限制副本计数的<a href="#flapping">波动</a>。
自动扩缩算法使用此窗口来推断先前的期望状态并避免对工作负载规模进行不必要的更改。</p>
<p>例如，在以下示例代码段中，为 <code>scaleDown</code> 指定了稳定窗口。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">behavior</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">scaleDown</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">stabilizationWindowSeconds</span>:<span style="color:#bbb"> </span><span style="color:#666">300</span><span style="color:#bbb">
</span></code></pre></div><!--  
When the metrics indicate that the target should be scaled down the algorithm looks
into previously computed desired states, and uses the highest value from the specified
interval. In the above example, all desired states from the past 5 minutes will be considered.
-->
<p>当指标显示目标应该缩容时，自动扩缩算法查看之前计算的期望状态，并使用指定时间间隔内的最大值。
在上面的例子中，过去 5 分钟的所有期望状态都会被考虑。</p>
<!--
This approximates a rolling maximum, and avoids having the scaling algorithm frequently
remove Pods only to trigger recreating an equivalent Pod just moments later.
-->
<p>这近似于滚动最大值，并避免了扩缩算法频繁删除 Pod 而又触发重新创建等效 Pod。</p>
<!--  
### Default Behavior

To use the custom scaling not all fields have to be specified. Only values which need to be
customized can be specified. These custom values are merged with default values. The default values
match the existing behavior in the HPA algorithm.
-->
<h3 id="default-behavior">默认行为</h3>
<p>要使用自定义扩缩，不必指定所有字段。
只有需要自定义的字段才需要指定。
这些自定义值与默认值合并。
默认值与 HPA 算法中的现有行为匹配。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">behavior</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">scaleDown</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">stabilizationWindowSeconds</span>:<span style="color:#bbb"> </span><span style="color:#666">300</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">policies</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span>- <span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Percent<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">value</span>:<span style="color:#bbb"> </span><span style="color:#666">100</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">periodSeconds</span>:<span style="color:#bbb"> </span><span style="color:#666">15</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">scaleUp</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">stabilizationWindowSeconds</span>:<span style="color:#bbb"> </span><span style="color:#666">0</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">policies</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span>- <span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Percent<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">value</span>:<span style="color:#bbb"> </span><span style="color:#666">100</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">periodSeconds</span>:<span style="color:#bbb"> </span><span style="color:#666">15</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span>- <span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Pods<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">value</span>:<span style="color:#bbb"> </span><span style="color:#666">4</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">periodSeconds</span>:<span style="color:#bbb"> </span><span style="color:#666">15</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">selectPolicy</span>:<span style="color:#bbb"> </span>Max<span style="color:#bbb">
</span></code></pre></div><!--  
For scaling down the stabilization window is _300_ seconds (or the value of the
`--horizontal-pod-autoscaler-downscale-stabilization` flag if provided). There is only a single policy
for scaling down which allows a 100% of the currently running replicas to be removed which
means the scaling target can be scaled down to the minimum allowed replicas.
For scaling up there is no stabilization window. When the metrics indicate that the target should be
scaled up the target is scaled up immediately. There are 2 policies where 4 pods or a 100% of the currently
running replicas will be added every 15 seconds till the HPA reaches its steady state.
-->
<p>用于缩小稳定窗口的时间为 <em>300</em>  秒(或是 <code>--horizontal-pod-autoscaler-downscale-stabilization</code>
参数设定值)。
只有一种缩容的策略，允许 100% 删除当前运行的副本，这意味着扩缩目标可以缩小到允许的最小副本数。
对于扩容，没有稳定窗口。当指标显示目标应该扩容时，目标会立即扩容。
这里有两种策略，每 15 秒添加 4 个 Pod 或 100% 当前运行的副本数，直到 HPA 达到稳定状态。</p>
<!--  
### Example: change downscale stabilization window

To provide a custom downscale stabilization window of 1 minute, the following
behavior would be added to the HPA:
--> 
<h3 id="example-change-downscale-stabilization-window">示例：更改缩容稳定窗口</h3>
<p>将下面的 behavior 配置添加到 HPA 中，可提供一个 1 分钟的自定义缩容稳定窗口：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">behavior</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">scaleDown</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">stabilizationWindowSeconds</span>:<span style="color:#bbb"> </span><span style="color:#666">60</span><span style="color:#bbb">
</span></code></pre></div><!--  
### Example: limit scale down rate

To limit the rate at which pods are removed by the HPA to 10% per minute, the
following behavior would be added to the HPA:
-->
<h3 id="example-limit-scale-down-rate">示例：限制缩容速率</h3>
<p>将下面的 behavior 配置添加到 HPA 中，可限制 Pod 被 HPA 删除速率为每分钟 10%：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">behavior</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">scaleDown</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">policies</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span>- <span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Percent<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">value</span>:<span style="color:#bbb"> </span><span style="color:#666">10</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">periodSeconds</span>:<span style="color:#bbb"> </span><span style="color:#666">60</span><span style="color:#bbb">
</span></code></pre></div><!--  
To ensure that no more than 5 Pods are removed per minute, you can add a second scale-down
policy with a fixed size of 5, and set `selectPolicy` to minimum. Setting `selectPolicy` to `Min` means
that the autoscaler chooses the policy that affects the smallest number of Pods:
-->
<p>为了确保每分钟删除的 Pod 数不超过 5 个，可以添加第二个缩容策略，大小固定为 5，并将 <code>selectPolicy</code> 设置为最小值。
将 <code>selectPolicy</code> 设置为 <code>Min</code> 意味着 autoscaler 会选择影响 Pod 数量最小的策略:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">behavior</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">scaleDown</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">policies</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span>- <span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Percent<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">value</span>:<span style="color:#bbb"> </span><span style="color:#666">10</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">periodSeconds</span>:<span style="color:#bbb"> </span><span style="color:#666">60</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span>- <span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Pods<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">value</span>:<span style="color:#bbb"> </span><span style="color:#666">5</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">periodSeconds</span>:<span style="color:#bbb"> </span><span style="color:#666">60</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">selectPolicy</span>:<span style="color:#bbb"> </span>Min<span style="color:#bbb">
</span></code></pre></div><!--  
### Example: disable scale down

The `selectPolicy` value of `Disabled` turns off scaling the given direction.
So to prevent downscaling the following policy would be used:
-->
<h3 id="example-disable-scale-down">示例：禁用缩容</h3>
<p><code>selectPolicy</code> 的值 <code>Disabled</code> 会关闭对给定方向的缩容。
因此使用以下策略，将会阻止缩容：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">behavior</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">scaleDown</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">selectPolicy</span>:<span style="color:#bbb"> </span>Disabled<span style="color:#bbb">
</span></code></pre></div><!--
## Support for HorizontalPodAutoscaler in kubectl

HorizontalPodAutoscaler, like every API resource, is supported in a standard way by `kubectl`.
You can create a new autoscaler using `kubectl create` command.
You can list autoscalers by `kubectl get hpa` or get detailed description by `kubectl describe hpa`.
Finally, you can delete an autoscaler using `kubectl delete hpa`.
-->
<h2 id="support-for-horizontalpodautoscaler-in-kubectl">kubectl 对 HorizontalPodAutoscaler 的支持</h2>
<p>与每个 API 资源一样，HorizontalPodAutoscaler 都被 <code>kubectl</code> 以标准方式支持。
你可以使用 <code>kubectl create</code> 命令创建一个新的自动扩缩器。
你可以通过 <code>kubectl get hpa</code> 列出自动扩缩器或通过 <code>kubectl describe hpa</code> 获取详细描述。
最后，你可以使用 <code>kubectl delete hpa</code> 删除自动扩缩器。</p>
<!--
In addition, there is a special `kubectl autoscale` command for creating a HorizontalPodAutoscaler object.
For instance, executing `kubectl autoscale rs foo --min=2 --max=5 --cpu-percent=80`
will create an autoscaler for ReplicaSet *foo*, with target CPU utilization set to `80%`
and the number of replicas between 2 and 5.
-->
<p>此外，还有一个特殊的 <code>kubectl autoscale</code> 命令用于创建 HorizontalPodAutoscaler 对象。
例如，执行 <code>kubectl autoscale rs foo --min=2 --max=5 --cpu-percent=80</code>
将为 ReplicaSet <em>foo</em> 创建一个自动扩缩器，目标 CPU 利用率设置为 <code>80%</code>，副本数在 2 到 5 之间。</p>
<!--
## Implicit maintenance-mode deactivation

You can implicitly deactivate the HPA for a target without the
need to change the HPA configuration itself. If the target's desired replica count
is set to 0, and the HPA's minimum replica count is greater than 0, the HPA 
stops adjusting the target (and sets the `ScalingActive` Condition on itself
to `false`) until you reactivate it by manually adjusting the target's desired
replica count or HPA's minimum replica count.
-->
<h2 id="implicit-maintenance-mode-deactivation">隐式维护状态禁用</h2>
<p>你可以在不必更改 HPA 配置的情况下隐式地为某个目标禁用 HPA。
如果此目标的期望副本个数被设置为 0，而 HPA 的最小副本个数大于 0，
则 HPA 会停止调整目标（并将其自身的 <code>ScalingActive</code> 状况设置为 <code>false</code>），
直到你通过手动调整目标的期望副本个数或 HPA 的最小副本个数来重新激活。</p>
<!--
### Migrating Deployments and StatefulSets to horizontal autoscaling

When an HPA is enabled, it is recommended that the value of `spec.replicas` of
the Deployment and / or StatefulSet be removed from their
<a class='glossary-tooltip' title='一个或多个 Kubernetes API 对象的序列化规范。' data-toggle='tooltip' data-placement='top' href='/zh/docs/reference/glossary/?all=true#term-manifest' target='_blank' aria-label='manifest(s)'>manifest(s)</a>.  If this isn't done, any time
a change to that object is applied, for example via `kubectl apply -f
deployment.yaml`, this will instruct Kubernetes to scale the current number of Pods
to the value of the `spec.replicas` key. This may not be
desired and could be troublesome when an HPA is active.
-->
<h3 id="migrating-deployments-and-statefulsets-to-horizontal-autoscaling">将 Deployment 和 StatefulSet 迁移到水平自动扩缩</h3>
<p>当启用 HPA 时，建议从它们的<a class='glossary-tooltip' title='一个或多个 Kubernetes API 对象的序列化规范。' data-toggle='tooltip' data-placement='top' href='/zh/docs/reference/glossary/?all=true#term-manifest' target='_blank' aria-label='清单'>清单</a>中
删除 Deployment 和/或 StatefulSet 的 <code>spec.replicas</code> 的值。
如果不这样做，则只要应用对该对象的更改，例如通过 <code>kubectl apply -f deployment.yaml</code>，
这将指示 Kubernetes 将当前 Pod 数量扩缩到 <code>spec.replicas</code> 键的值。这可能不是所希望的，
并且当 HPA 处于活动状态时可能会很麻烦。</p>
<!--
Keep in mind that the removal of `spec.replicas` may incur a one-time
degradation of Pod counts as the default value of this key is 1 (reference
[Deployment Replicas](/docs/concepts/workloads/controllers/deployment#replicas)).
Upon the update, all Pods except 1 will begin their termination procedures.  Any
deployment application afterwards will behave as normal and respect a rolling
update configuration as desired.  You can avoid this degradation by choosing one of the following two
methods based on how you are modifying your deployments:
-->
<p>请记住，删除 <code>spec.replicas</code> 可能会导致 Pod 计数一次性降级，因为此键的默认值为 1
（参考 <a href="/zh/docs/concepts/workloads/controllers/deployment#replicas">Deployment Replicas</a>）。
更新后，除 1 之外的所有 Pod 都将开始其终止程序。之后的任何部署应用程序都将正常运行，
并根据需要遵守滚动更新配置。你可以根据修改部署的方式选择以下两种方法之一来避免这种降级：</p>
<ul class="nav nav-tabs" id="fix-replicas-instructions" role="tablist"><li class="nav-item"><a data-toggle="tab" class="nav-link active" href="#fix-replicas-instructions-0" role="tab" aria-controls="fix-replicas-instructions-0" aria-selected="true">客户端 apply 操作（默认行为）</a></li>
	  
		<li class="nav-item"><a data-toggle="tab" class="nav-link" href="#fix-replicas-instructions-1" role="tab" aria-controls="fix-replicas-instructions-1">服务器端 apply 操作</a></li></ul>
<div class="tab-content" id="fix-replicas-instructions"><div id="fix-replicas-instructions-0" class="tab-pane show active" role="tabpanel" aria-labelledby="fix-replicas-instructions-0">

<p><!--
1. `kubectl apply edit-last-applied deployment/<deployment_name>`
2. In the editor, remove `spec.replicas`. When you save and exit the editor, `kubectl`
    applies the update.  No changes to Pod counts happen at this step.
3. You can now remove `spec.replicas` from the manifest. If you use source code management,
    also commit your changes or take whatever other steps for revising the source code
    are appropriate for how you track updates.
4. From here on out you can run `kubectl apply -f deployment.yaml`
-->
<ol>
<li><code>kubectl apply edit-last-applied deployment/&lt;Deployment 名称&gt;</code></li>
<li>在编辑器中，删除 <code>spec.replicas</code>。当你保存并退出编辑器时，<code>kubectl</code> 会应用更新。
在此步骤中不会更改 Pod 计数。</li>
<li>你现在可以从清单中删除 <code>spec.replicas</code>。如果你使用源代码管理，
还应提交你的更改或采取任何其他步骤来修改源代码，以适应你如何跟踪更新。</li>
<li>从这里开始，你可以运行 <code>kubectl apply -f deployment.yaml</code></li>
</ol>
</div>
  <div id="fix-replicas-instructions-1" class="tab-pane" role="tabpanel" aria-labelledby="fix-replicas-instructions-1">

<p><!--
When using the [Server-Side Apply](/docs/reference/using-api/server-side-apply/)
you can follow the [transferring ownership](/docs/reference/using-api/server-side-apply/#transferring-ownership)
guidelines, which cover this exact use case.
-->
<p>使用<a href="/zh/docs/reference/using-api/server-side-apply/">服务器端 Apply</a> 机制，
你可以遵循<a href="/zh/docs/reference/using-api/server-side-apply/#transferring-ownership">交出所有权</a> 说明，
该指南涵盖了这个确切的用例。</p>
</div></div>

<h2 id="what-s-next">What's next</h2>
<!--
If you configure autoscaling in your cluster, you may also want to consider running a
cluster-level autoscaler such as [Cluster Autoscaler](https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler).

For more information on HorizontalPodAutoscaler:
-->
<p>如果你在集群中配置自动扩缩，你可能还需要考虑运行集群级别的自动扩缩器，
例如 <a href="https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler">Cluster Autoscaler</a>。</p>
<p>有关 HorizontalPodAutoscaler 的更多信息：</p>
<!--
* Read a [walkthrough example](/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/) for horizontal pod autoscaling.
* Read documentation for [`kubectl autoscale`](/docs/reference/generated/kubectl/kubectl-commands/#autoscale).
* If you would like to write your own custom metrics adapter, check out the
  [boilerplate](https://github.com/kubernetes-sigs/custom-metrics-apiserver) to get started.
* Read the [API reference](/docs/reference/kubernetes-api/workload-resources/horizontal-pod-autoscaler-v2/) for HorizontalPodAutoscaler.
-->
<ul>
<li>阅读水平 Pod 自动扩缩的<a href="/zh/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/">演练示例</a>。</li>
<li>阅读 <a href="/zh/docs/reference/generated/kubectl/kubectl-commands/#autoscale"><code>kubectl autoscale</code></a> 的文档。</li>
<li>如果你想编写自己的自定义指标适配器，
请查看 <a href="https://github.com/kubernetes-sigs/custom-metrics-apiserver">boilerplate</a> 以开始使用。</li>
<li>阅读 <a href="/docs/reference/kubernetes-api/workload-resources/horizontal-pod-autoscaler-v2/">API 参考</a>。</li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-8138226ce9660ac8e3e82ff86fff8ad2">7 - Horizontal Pod Autoscaler 演练</h1>
    
	<!--
reviewers:
- fgrzadkowski
- jszczepkowski
- justinsb
- directxman12
title: Horizontal Pod Autoscaler Walkthrough
content_type: task
weight: 100
-->
<!-- overview -->
<!--
Horizontal Pod Autoscaler automatically scales the number of pods
in a replication controller, deployment or replica set or statefulset based on observed CPU utilization
(or, with beta support, on some other, application-provided metrics).
-->
<p>Horizontal Pod Autoscaler 可以根据 CPU 利用率自动扩缩 ReplicationController、
Deployment、ReplicaSet 或 StatefulSet 中的 Pod 数量
（也可以基于其他应用程序提供的度量指标，目前这一功能处于 beta 版本）。</p>
<!--
This document walks you through an example of enabling Horizontal Pod Autoscaler for the php-apache server.
For more information on how Horizontal Pod Autoscaler behaves, see the
[Horizontal Pod Autoscaler user guide](/docs/tasks/run-application/horizontal-pod-autoscale/).
-->
<p>本文将引领你了解如何为 php-apache 服务器配置和使用 Horizontal Pod Autoscaler。
与 Horizontal Pod Autoscaler 相关的更多信息请参阅
<a href="/zh/docs/tasks/run-application/horizontal-pod-autoscale/">Horizontal Pod Autoscaler 用户指南</a>。</p>
<h2 id="before-you-begin">Before you begin</h2>
<!--
This example requires a running Kubernetes cluster and kubectl, version 1.2 or later.
[metrics-server](https://github.com/kubernetes-incubator/metrics-server/) monitoring needs to be deployed
in the cluster to provide metrics through the [Metrics API](https://github.com/kubernetes/metrics).
Horizontal Pod Autoscaler uses this API to collect metrics. To learn how to deploy the metrics-server,
see the [metrics-server documentation](https://github.com/kubernetes-sigs/metrics-server#deployment).
-->
<p>本文示例需要一个运行中的 Kubernetes 集群以及 kubectl，版本为 1.2 或更高。
<a href="https://github.com/kubernetes-incubator/metrics-server/">Metrics 服务器</a>
需要被部署到集群中，以便通过 <a href="https://github.com/kubernetes/metrics">Metrics API</a>
提供度量数据。
Horizontal Pod Autoscaler 根据此 API 来获取度量数据。
要了解如何部署 metrics-server，请参考
<a href="https://github.com/kubernetes-incubator/metrics-server/">metrics-server 文档</a> 。</p>
<!--
To specify multiple resource metrics for a Horizontal Pod Autoscaler, you must have a
Kubernetes cluster and kubectl at version 1.6 or later. To make use of custom metrics, your cluster
must be able to communicate with the API server providing the custom metrics API.
Finally, to use metrics not related to any Kubernetes object you must have a
Kubernetes cluster at version 1.10 or later, and you must be able to communicate with
the API server that provides the external metrics API.
See the [Horizontal Pod Autoscaler user guide](/docs/tasks/run-application/horizontal-pod-autoscale/#support-for-custom-metrics) for more details.
-->
<p>如果需要为 Horizontal Pod Autoscaler 指定多种资源度量指标，你的 Kubernetes
集群以及 kubectl 至少需要达到 1.6 版本。
此外，如果要使用自定义度量指标，你的 Kubernetes 集群还必须能够与提供这些自定义指标
的 API 服务器通信。
最后，如果要使用与 Kubernetes 对象无关的度量指标，则 Kubernetes 集群版本至少需要
达到 1.10 版本，同样，需要保证集群能够与提供这些外部指标的 API 服务器通信。
更多详细信息，请参阅
<a href="/zh/docs/tasks/run-application/horizontal-pod-autoscale/#support-for-custom-metrics">Horizontal Pod Autoscaler 用户指南</a>。</p>
<!-- steps -->
<!--
## Run & expose php-apache server
-->
<h2 id="运行-php-apache-服务器并暴露服务">运行 php-apache 服务器并暴露服务</h2>
<!--
To demonstrate Horizontal Pod Autoscaler we will use a custom docker image based on the php-apache image.
The Dockerfile has the following content:
-->
<p>为了演示 Horizontal Pod Autoscaler，我们将使用一个基于 php-apache 镜像的
定制 Docker 镜像。Dockerfile 内容如下：</p>
<pre><code>FROM php:5-apache
COPY index.php /var/www/html/index.php
RUN chmod a+rx index.php
</code></pre><!--
It defines an index.php page which performs some CPU intensive computations:
-->
<p>该文件定义了一个 index.php 页面来执行一些 CPU 密集型计算：</p>
<pre><code>&lt;?php
  $x = 0.0001;
  for ($i = 0; $i &lt;= 1000000; $i++) {
    $x += sqrt($x);
  }
  echo &quot;OK!&quot;;
?&gt;
</code></pre><!--
First, we will start a deployment running the image and expose it as a service
using the following configuration:
-->
<p>首先，我们使用下面的配置启动一个 Deployment 来运行这个镜像并暴露一个服务：</p>


 













<div class="highlight">
    <div class="copy-code-icon" style="text-align:right">
    <a href="https://raw.githubusercontent.com/kubernetes/website/main/content/zh/examples/application/php-apache.yaml" download="application/php-apache.yaml"><code>application/php-apache.yaml</code>
    </a>
    <img src="/images/copycode.svg" style="max-height:24px; cursor: pointer" onclick="copyCode('application-php-apache-yaml')" title="Copy application/php-apache.yaml to clipboard">
    </img>
    </div>
    <div class="includecode" id="application-php-apache-yaml">
    <div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>apps/v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Deployment<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>php-apache<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">matchLabels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">run</span>:<span style="color:#bbb"> </span>php-apache<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">replicas</span>:<span style="color:#bbb"> </span><span style="color:#666">1</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">template</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">run</span>:<span style="color:#bbb"> </span>php-apache<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">containers</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>php-apache<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">image</span>:<span style="color:#bbb"> </span>k8s.gcr.io/hpa-example<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">ports</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">containerPort</span>:<span style="color:#bbb"> </span><span style="color:#666">80</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">limits</span>:<span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">cpu</span>:<span style="color:#bbb"> </span>500m<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">requests</span>:<span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">cpu</span>:<span style="color:#bbb"> </span>200m<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#00f;font-weight:bold">---</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Service<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>php-apache<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">run</span>:<span style="color:#bbb"> </span>php-apache<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">ports</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">port</span>:<span style="color:#bbb"> </span><span style="color:#666">80</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">run</span>:<span style="color:#bbb"> </span>php-apache<span style="color:#bbb">
</span></code></pre></div>
    </div>
</div>


<!--
Run the following command:
-->
<p>运行下面的命令：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl apply -f https://k8s.io/examples/application/php-apache.yaml
</code></pre></div><pre><code>deployment.apps/php-apache created
service/php-apache created
</code></pre><!--
## Create Horizontal Pod Autoscaler

Now that the server is running, we will create the autoscaler using
[kubectl autoscale](/docs/reference/generated/kubectl/kubectl-commands#autoscale).
The following command will create a Horizontal Pod Autoscaler that maintains between 1 and 10 replicas of the Pods
controlled by the php-apache deployment we created in the first step of these instructions.
Roughly speaking, HPA will increase and decrease the number of replicas
(via the deployment) to maintain an average CPU utilization across all Pods of 50%.
Since each pod requests 200 milli-cores by `kubectl run`, this means an average CPU usage of 100 milli-cores.
See [here](/docs/tasks/run-application/horizontal-pod-autoscale/#algorithm-details) for more details on the algorithm.
-->
<h2 id="create-horizontal-pod-autoscaler">创建 Horizontal Pod Autoscaler </h2>
<p>现在，php-apache 服务器已经运行，我们将通过
<a href="/docs/reference/generated/kubectl/kubectl-commands#autoscale">kubectl autoscale</a>
命令创建 Horizontal Pod Autoscaler。
以下命令将创建一个 Horizontal Pod Autoscaler 用于控制我们上一步骤中创建的
Deployment，使 Pod 的副本数量维持在 1 到 10 之间。
大致来说，HPA 将（通过 Deployment）增加或者减少 Pod 副本的数量以保持所有 Pod
的平均 CPU 利用率在 50% 左右。由于每个 Pod 请求 200 毫核的 CPU，这意味着平均
CPU 用量为 100 毫核。
算法的详情请参阅<a href="/zh/docs/tasks/run-application/horizontal-pod-autoscale/#algorithm-details">相关文档</a>。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl autoscale deployment php-apache --cpu-percent<span style="color:#666">=</span><span style="color:#666">50</span> --min<span style="color:#666">=</span><span style="color:#666">1</span> --max<span style="color:#666">=</span><span style="color:#666">10</span>
</code></pre></div><pre><code>horizontalpodautoscaler.autoscaling/php-apache autoscaled
</code></pre><!--
We may check the current status of autoscaler by running:
-->
<p>我们可以通过以下命令查看 Autoscaler 的状态：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get hpa
</code></pre></div><pre><code>NAME         REFERENCE                     TARGET    MINPODS   MAXPODS   REPLICAS   AGE
php-apache   Deployment/php-apache/scale   0% / 50%  1         10        1          18s

</code></pre><!--
Please note that the current CPU consumption is 0% as we are not sending any requests to the server
(the ``CURRENT`` column shows the average across all the pods controlled by the corresponding deployment).
-->
<p>请注意当前的 CPU 利用率是 0%，这是由于我们尚未发送任何请求到服务器
（<code>CURRENT</code> 列显示了相应 Deployment 所控制的所有 Pod 的平均 CPU 利用率）。</p>
<!--
## Increase load

Now, we will see how the autoscaler reacts to increased load.
We will start a container, and send an infinite loop of queries to the php-apache service (please run it in a different terminal):
-->
<h2 id="increase-load">增加负载 </h2>
<p>现在，我们将看到 Autoscaler 如何对增加负载作出反应。
我们将启动一个容器，并通过一个循环向 php-apache 服务器发送无限的查询请求
（请在另一个终端中运行以下命令）：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl run -i --tty load-generator --rm --image<span style="color:#666">=</span>busybox --restart<span style="color:#666">=</span>Never -- /bin/sh -c <span style="color:#b44">&#34;while sleep 0.01; do wget -q -O- http://php-apache; done&#34;</span>
</code></pre></div><!--
Within a minute or so, we should see the higher CPU load by executing:
-->
<p>一分钟时间左右之后，通过以下命令，我们可以看到 CPU 负载升高了：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get hpa
</code></pre></div><pre><code>NAME         REFERENCE                     TARGET      MINPODS   MAXPODS   REPLICAS   AGE
php-apache   Deployment/php-apache/scale   305% / 50%  1         10        1          3m
</code></pre><!--
Here, CPU consumption has increased to 305% of the request.
As a result, the deployment was resized to 7 replicas:
-->
<p>这时，由于请求增多，CPU 利用率已经升至请求值的 305%。
可以看到，Deployment 的副本数量已经增长到了 7：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get deployment php-apache
</code></pre></div><pre><code>NAME         READY   UP-TO-DATE   AVAILABLE   AGE
php-apache   7/7      7           7           19m
</code></pre><!--
It may take a few minutes to stabilize the number of replicas. Since the amount
of load is not controlled in any way it may happen that the final number of replicas
will differ from this example.
-->
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> 有时最终副本的数量可能需要几分钟才能稳定下来。由于环境的差异，
不同环境中最终的副本数量可能与本示例中的数量不同。
</div>
<!--
## Stop load

We will finish our example by stopping the user load.

In the terminal where we created the container with `busybox` image, terminate
the load generation by typing `<Ctrl> + C`.

Then we will verify the result state (after a minute or so):
-->
<h2 id="停止负载">停止负载</h2>
<p>我们将通过停止负载来结束我们的示例。</p>
<p>在我们创建 busybox 容器的终端中，输入<code>&lt;Ctrl&gt; + C</code> 来终止负载的产生。</p>
<p>然后我们可以再次检查负载状态（等待几分钟时间）：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get hpa
</code></pre></div><pre><code>NAME         REFERENCE                     TARGET       MINPODS   MAXPODS   REPLICAS   AGE
php-apache   Deployment/php-apache/scale   0% / 50%     1         10        1          11m
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get deployment php-apache
</code></pre></div><pre><code>NAME         READY   UP-TO-DATE   AVAILABLE   AGE
php-apache   1/1     1            1           27m
</code></pre><!--
Here CPU utilization dropped to 0, and so HPA autoscaled the number of replicas back down to 1.
-->
<p>这时，CPU 利用率已经降到 0，所以 HPA 将自动缩减副本数量至 1。</p>
<!--
Autoscaling the replicas may take a few minutes.
-->
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> 自动扩缩完成副本数量的改变可能需要几分钟的时间。
</div>
<!-- discussion -->
<!--
## Autoscaling on multiple metrics and custom metrics

You can introduce additional metrics to use when autoscaling the `php-apache` Deployment
by making use of the `autoscaling/v2beta2` API version.
-->
<h2 id="autoscaling-on-multiple-metrics-and-custom-metrics">基于多项度量指标和自定义度量指标自动扩缩</h2>
<p>利用 <code>autoscaling/v2beta2</code> API 版本，你可以在自动扩缩 php-apache 这个
Deployment 时使用其他度量指标。</p>
<!--
First, get the YAML of your HorizontalPodAutoscaler in the `autoscaling/v2beta2` form:
-->
<p>首先，将 HorizontalPodAutoscaler 的 YAML 文件改为 <code>autoscaling/v2beta2</code> 格式：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get hpa php-apache -o yaml &gt; /tmp/hpa-v2.yaml
</code></pre></div><!--
Open the `/tmp/hpa-v2.yaml` file in an editor, and you should see YAML which looks like this:
-->
<p>在编辑器中打开 <code>/tmp/hpa-v2.yaml</code>：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>autoscaling/v2beta2<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>HorizontalPodAutoscaler<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>php-apache<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">scaleTargetRef</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>apps/v1<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Deployment<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>php-apache<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">minReplicas</span>:<span style="color:#bbb"> </span><span style="color:#666">1</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">maxReplicas</span>:<span style="color:#bbb"> </span><span style="color:#666">10</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">metrics</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Resource<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">resource</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>cpu<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">target</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Utilization<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">averageUtilization</span>:<span style="color:#bbb"> </span><span style="color:#666">50</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">status</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">observedGeneration</span>:<span style="color:#bbb"> </span><span style="color:#666">1</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">lastScaleTime</span>:<span style="color:#bbb"> </span>&lt;some-time&gt;<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">currentReplicas</span>:<span style="color:#bbb"> </span><span style="color:#666">1</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">desiredReplicas</span>:<span style="color:#bbb"> </span><span style="color:#666">1</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">currentMetrics</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Resource<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">resource</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>cpu<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">current</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">averageUtilization</span>:<span style="color:#bbb"> </span><span style="color:#666">0</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">averageValue</span>:<span style="color:#bbb"> </span><span style="color:#666">0</span><span style="color:#bbb">
</span></code></pre></div><!--
Notice that the `targetCPUUtilizationPercentage` field has been replaced with an array called `metrics`.
The CPU utilization metric is a *resource metric*, since it is represented as a percentage of a resource
specified on pod containers.  Notice that you can specify other resource metrics besides CPU.  By default,
the only other supported resource metric is memory.  These resources do not change names from cluster
to cluster, and should always be available, as long as the `metrics.k8s.io` API is available.
-->
<p>需要注意的是，<code>targetCPUUtilizationPercentage</code> 字段已经被名为 <code>metrics</code> 的数组所取代。
CPU 利用率这个度量指标是一个 <em>resource metric</em>（资源度量指标），因为它表示容器上指定资源的百分比。
除 CPU 外，你还可以指定其他资源度量指标。默认情况下，目前唯一支持的其他资源度量指标为内存。
只要 <code>metrics.k8s.io</code> API 存在，这些资源度量指标就是可用的，并且他们不会在不同的 Kubernetes 集群中改变名称。</p>
<!--
You can also specify resource metrics in terms of direct values, instead of as percentages of the
requested value, by using a `target.type` of `AverageValue` instead of `Utilization`, and
setting the corresponding `target.averageValue` field instead of the `target.averageUtilization`.
-->
<p>你还可以指定资源度量指标使用绝对数值，而不是百分比，你需要将 <code>target.type</code> 从
<code>Utilization</code> 替换成 <code>AverageValue</code>，同时设置 <code>target.averageValue</code>
而非 <code>target.averageUtilization</code> 的值。</p>
<!--
There are two other types of metrics, both of which are considered *custom metrics*: pod metrics and
object metrics.  These metrics may have names which are cluster specific, and require a more
advanced cluster monitoring setup.
-->
<p>还有两种其他类型的度量指标，他们被认为是 <em>custom metrics</em>（自定义度量指标）：
即 Pod 度量指标和 Object 度量指标。
这些度量指标可能具有特定于集群的名称，并且需要更高级的集群监控设置。</p>
<!--
The first of these alternative metric types is *pod metrics*.  These metrics describe pods, and
are averaged together across pods and compared with a target value to determine the replica count.
They work much like resource metrics, except that they *only* support a `target` type of `AverageValue`.
-->
<p>第一种可选的度量指标类型是 Pod 度量指标。这些指标从某一方面描述了 Pod，
在不同 Pod 之间进行平均，并通过与一个目标值比对来确定副本的数量。
它们的工作方式与资源度量指标非常相像，只是它们仅支持 <code>target</code> 类型为 <code>AverageValue</code>。</p>
<!--
Pod metrics are specified using a metric block like this:
-->
<p>pod 度量指标通过如下代码块定义：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Pods<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">pods</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">metric</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>packets-per-second<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">target</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>AverageValue<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">averageValue</span>:<span style="color:#bbb"> </span>1k<span style="color:#bbb">
</span></code></pre></div><!--
The second alternative metric type is *object metrics*. These metrics describe a different
object in the same namespace, instead of describing pods. The metrics are not necessarily
fetched from the object; they only describe it. Object metrics support `target` types of
both `Value` and `AverageValue`.  With `Value`, the target is compared directly to the returned
metric from the API. With `AverageValue`, the value returned from the custom metrics API is divided
by the number of pods before being compared to the target. The following example is the YAML
representation of the `requests-per-second` metric.
-->
<p>第二种可选的度量指标类型是对象（Object）度量指标。这些度量指标用于描述
在相同名字空间中的别的对象，而非 Pods。
请注意这些度量指标不一定来自某对象，它们仅用于描述这些对象。
对象度量指标支持的 <code>target</code> 类型包括 <code>Value</code> 和 <code>AverageValue</code>。
如果是 <code>Value</code> 类型，<code>target</code> 值将直接与 API 返回的度量指标比较，
而对于 <code>AverageValue</code> 类型，API 返回的度量值将按照 Pod 数量拆分，
然后再与 <code>target</code> 值比较。
下面的 YAML 文件展示了一个表示 <code>requests-per-second</code> 的度量指标。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Object<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">object</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">metric</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>requests-per-second<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">describedObject</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>networking.k8s.io/v1<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Ingress<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>main-route<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">target</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Value<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">value</span>:<span style="color:#bbb"> </span>2k<span style="color:#bbb">
</span></code></pre></div><!--
If you provide multiple such metric blocks, the HorizontalPodAutoscaler will consider each metric in turn.
The HorizontalPodAutoscaler will calculate proposed replica counts for each metric, and then choose the
one with the highest replica count.
-->
<p>如果你指定了多个上述类型的度量指标，HorizontalPodAutoscaler 将会依次考量各个指标。
HorizontalPodAutoscaler 将会计算每一个指标所提议的副本数量，然后最终选择一个最高值。</p>
<!--
For example, if you had your monitoring system collecting metrics about network traffic,
you could update the definition above using `kubectl edit` to look like this:
-->
<p>比如，如果你的监控系统能够提供网络流量数据，你可以通过 <code>kubectl edit</code> 命令
将上述 Horizontal Pod Autoscaler 的定义更改为：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>autoscaling/v2beta1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>HorizontalPodAutoscaler<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>php-apache<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">scaleTargetRef</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>apps/v1<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Deployment<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>php-apache<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">minReplicas</span>:<span style="color:#bbb"> </span><span style="color:#666">1</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">maxReplicas</span>:<span style="color:#bbb"> </span><span style="color:#666">10</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">metrics</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Resource<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">resource</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>cpu<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">target</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>AverageUtilization<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">averageUtilization</span>:<span style="color:#bbb"> </span><span style="color:#666">50</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Pods<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">pods</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">metric</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>packets-per-second<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">target</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>AverageValue<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">averageValue</span>:<span style="color:#bbb"> </span>1k<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Object<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">object</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">metric</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>requests-per-second<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">describedObject</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>networking.k8s.io/v1beta1<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Ingress<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>main-route<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">target</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Value<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">value</span>:<span style="color:#bbb"> </span>10k<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">status</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">observedGeneration</span>:<span style="color:#bbb"> </span><span style="color:#666">1</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">lastScaleTime</span>:<span style="color:#bbb"> </span>&lt;some-time&gt;<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">currentReplicas</span>:<span style="color:#bbb"> </span><span style="color:#666">1</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">desiredReplicas</span>:<span style="color:#bbb"> </span><span style="color:#666">1</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">currentMetrics</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Resource<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">resource</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>cpu<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">current</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">averageUtilization</span>:<span style="color:#bbb"> </span><span style="color:#666">0</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">averageValue</span>:<span style="color:#bbb"> </span><span style="color:#666">0</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Object<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">object</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">metric</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>requests-per-second<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">describedObject</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>networking.k8s.io/v1beta1<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Ingress<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>main-route<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">current</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">value</span>:<span style="color:#bbb"> </span>10k<span style="color:#bbb">
</span></code></pre></div><!--
Then, your HorizontalPodAutoscaler would attempt to ensure that each pod was consuming roughly
50% of its requested CPU, serving 1000 packets per second, and that all pods behind the main-route
Ingress were serving a total of 10000 requests per second.
-->
<p>这样，你的 HorizontalPodAutoscaler 将会尝试确保每个 Pod 的 CPU 利用率在 50% 以内，
每秒能够服务 1000 个数据包请求，
并确保所有在 Ingress 后的 Pod 每秒能够服务的请求总数达到 10000 个。</p>
<!--
### Autoscaling on more specific metrics

Many metrics pipelines allow you to describe metrics either by name or by a set of additional
descriptors called _labels_. For all non-resource metric types (pod, object, and external,
described below), you can specify an additional label selector which is passed to your metric
pipeline. For instance, if you collect a metric `http_requests` with the `verb`
label, you can specify the following metric block to scale only on GET requests:
-->
<h3 id="autoscaing-on-more-specific-metrics">基于更特别的度量值来扩缩  </h3>
<p>许多度量流水线允许你通过名称或附加的 <em>标签</em> 来描述度量指标。
对于所有非资源类型度量指标（Pod、Object 和后面将介绍的 External），
可以额外指定一个标签选择算符。例如，如果你希望收集包含 <code>verb</code> 标签的
<code>http_requests</code> 度量指标，可以按如下所示设置度量指标块，使得扩缩操作仅针对
GET 请求执行：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Object<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">object</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">metric</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>`http_requests`<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb"> </span>`verb=GET`<span style="color:#bbb">
</span></code></pre></div><!--
This selector uses the same syntax as the full Kubernetes label selectors. The monitoring pipeline
determines how to collapse multiple series into a single value, if the name and selector
match multiple series. The selector is additive, and cannot select metrics
that describe objects that are **not** the target object (the target pods in the case of the `Pods`
type, and the described object in the case of the `Object` type).
-->
<p>这个选择算符使用与 Kubernetes 标签选择算符相同的语法。
如果名称和标签选择算符匹配到多个系列，监测管道会决定如何将多个系列合并成单个值。
选择算符是可以累加的，它不会选择目标以外的对象（类型为 <code>Pods</code> 的目标 Pods 或者
类型为 <code>Object</code> 的目标对象）。</p>
<!--
### Autoscaling on metrics not related to Kubernetes objects

Applications running on Kubernetes may need to autoscale based on metrics that don't have an obvious
relationship to any object in the Kubernetes cluster, such as metrics describing a hosted service with
no direct correlation to Kubernetes namespaces. In Kubernetes 1.10 and later, you can address this use case
with *external metrics*.
-->
<h3 id="基于与-kubernetes-对象无关的度量指标执行扩缩">基于与 Kubernetes 对象无关的度量指标执行扩缩</h3>
<p>运行在 Kubernetes 上的应用程序可能需要基于与 Kubernetes 集群中的任何对象
没有明显关系的度量指标进行自动扩缩，
例如那些描述与任何 Kubernetes 名字空间中的服务都无直接关联的度量指标。
在 Kubernetes 1.10 及之后版本中，你可以使用外部度量指标（external metrics）。</p>
<!--
Using external metrics requires knowledge of your monitoring system; the setup is
similar to that required when using custom metrics. External metrics allow you to autoscale your cluster
based on any metric available in your monitoring system. Provide a `metric` block with a
`name` and `selector`, as above, and use the `External` metric type instead of `Object`.
If multiple time series are matched by the `metricSelector`,
the sum of their values is used by the HorizontalPodAutoscaler.
External metrics support both the `Value` and `AverageValue` target types, which function exactly the same
as when you use the `Object` type.
-->
<p>使用外部度量指标时，需要了解你所使用的监控系统，相关的设置与使用自定义指标时类似。
外部度量指标使得你可以使用你的监控系统的任何指标来自动扩缩你的集群。
你需要在 <code>metric</code> 块中提供 <code>name</code> 和 <code>selector</code>，同时将类型由 <code>Object</code> 改为 <code>External</code>。
如果 <code>metricSelector</code> 匹配到多个度量指标，HorizontalPodAutoscaler 将会把它们加和。
外部度量指标同时支持 <code>Value</code> 和 <code>AverageValue</code> 类型，这与 <code>Object</code> 类型的度量指标相同。</p>
<!--
For example if your application processes tasks from a hosted queue service, you could add the following
section to your HorizontalPodAutoscaler manifest to specify that you need one worker per 30 outstanding tasks.
-->
<p>例如，如果你的应用程序处理来自主机上消息队列的任务，
为了让每 30 个任务有 1 个工作者实例，你可以将下面的内容添加到
HorizontalPodAutoscaler 的配置中。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">- <span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>External<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">external</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">metric</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>queue_messages_ready<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">matchLabels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">queue</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;worker_tasks&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">target</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>AverageValue<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">averageValue</span>:<span style="color:#bbb"> </span><span style="color:#666">30</span><span style="color:#bbb">
</span></code></pre></div><!--
When possible, it's preferable to use the custom metric target types instead of external metrics, since it's
easier for cluster administrators to secure the custom metrics API.  The external metrics API potentially allows
access to any metric, so cluster administrators should take care when exposing it.
-->
<p>如果可能，还是推荐定制度量指标而不是外部度量指标，因为这便于让系统管理员加固定制度量指标 API。
而外部度量指标 API 可以允许访问所有的度量指标。
当暴露这些服务时，系统管理员需要仔细考虑这个问题。</p>
<!--
## Appendix: Horizontal Pod Autoscaler Status Conditions

When using the `autoscaling/v2beta2` form of the HorizontalPodAutoscaler, you will be able to see
*status conditions* set by Kubernetes on the HorizontalPodAutoscaler.  These status conditions indicate
whether or not the HorizontalPodAutoscaler is able to scale, and whether or not it is currently restricted
in any way.
-->
<h2 id="附录-horizontal-pod-autoscaler-状态条件">附录：Horizontal Pod Autoscaler 状态条件</h2>
<p>使用 <code>autoscaling/v2beta2</code> 格式的 HorizontalPodAutoscaler 时，你将可以看到
Kubernetes 为 HorizongtalPodAutoscaler 设置的状态条件（Status Conditions）。
这些状态条件可以显示当前 HorizontalPodAutoscaler 是否能够执行扩缩以及是否受到一定的限制。</p>
<!--
The conditions appear in the `status.conditions` field.  To see the conditions affecting a HorizontalPodAutoscaler,
we can use `kubectl describe hpa`:
-->
<p><code>status.conditions</code> 字段展示了这些状态条件。
可以通过 <code>kubectl describe hpa</code> 命令查看当前影响 HorizontalPodAutoscaler
的各种状态条件信息：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl describe hpa cm-test
</code></pre></div><pre><code>Name:                           cm-test
Namespace:                      prom
Labels:                         &lt;none&gt;
Annotations:                    &lt;none&gt;
CreationTimestamp:              Fri, 16 Jun 2017 18:09:22 +0000
Reference:                      ReplicationController/cm-test
Metrics:                        ( current / target )
  &quot;http_requests&quot; on pods:      66m / 500m
Min replicas:                   1
Max replicas:                   4
ReplicationController pods:     1 current / 1 desired
Conditions:
  Type                  Status  Reason                  Message
  ----                  ------  ------                  -------
  AbleToScale           True    ReadyForNewScale        the last scale time was sufficiently old as to warrant a new scale
  ScalingActive         True    ValidMetricFound        the HPA was able to successfully calculate a replica count from pods metric http_requests
  ScalingLimited        False   DesiredWithinRange      the desired replica count is within the acceptable range
Events:
</code></pre><!--
For this HorizontalPodAutoscaler, we can see several conditions in a healthy state.  The first,
`AbleToScale`, indicates whether or not the HPA is able to fetch and update scales, as well as
whether or not any backoff-related conditions would prevent scaling.  The second, `ScalingActive`,
indicates whether or not the HPA is enabled (i.e. the replica count of the target is not zero) and
is able to calculate desired scales. When it is `False`, it generally indicates problems with
fetching metrics.  Finally, the last condition, `ScalingLimited`, indicates that the desired scale
was capped by the maximum or minimum of the HorizontalPodAutoscaler.  This is an indication that
you may wish to raise or lower the minimum or maximum replica count constraints on your
HorizontalPodAutoscaler.
-->
<p>对于上面展示的这个 HorizontalPodAutoscaler，我们可以看出有若干状态条件处于健康状态。
首先，<code>AbleToScale</code> 表明 HPA 是否可以获取和更新扩缩信息，以及是否存在阻止扩缩的各种回退条件。
其次，<code>ScalingActive</code> 表明 HPA 是否被启用（即目标的副本数量不为零） 以及是否能够完成扩缩计算。
当这一状态为 <code>False</code> 时，通常表明获取度量指标存在问题。
最后一个条件 <code>ScalingLimitted</code> 表明所需扩缩的值被 HorizontalPodAutoscaler
所定义的最大或者最小值所限制（即已经达到最大或者最小扩缩值）。
这通常表明你可能需要调整 HorizontalPodAutoscaler 所定义的最大或者最小副本数量的限制了。</p>
<!--
## Appendix: Quantities

All metrics in the HorizontalPodAutoscaler and metrics APIs are specified using
a special whole-number notation known in Kubernetes as a
<a class='glossary-tooltip' title='使用全数字来表示较小数值或使用 SI 后缀表示较大数值的表示法。' data-toggle='tooltip' data-placement='top' href='/zh/docs/reference/glossary/?all=true#term-quantity' target='_blank' aria-label='quantity'>quantity</a>.  For example,
the quantity `10500m` would be written as `10.5` in decimal notation.  The metrics APIs
will return whole numbers without a suffix when possible, and will generally return
quantities in milli-units otherwise.  This means you might see your metric value fluctuate
between `1` and `1500m`, or `1` and `1.5` when written in decimal notation.
-->
<h2 id="appendix-quantities">附录：量纲   </h2>
<p>HorizontalPodAutoscaler 和 度量指标 API 中的所有的度量指标使用 Kubernetes 中称为
<a class='glossary-tooltip' title='使用全数字来表示较小数值或使用 SI 后缀表示较大数值的表示法。' data-toggle='tooltip' data-placement='top' href='/zh/docs/reference/glossary/?all=true#term-quantity' target='_blank' aria-label='量纲（Quantity）'>量纲（Quantity）</a>
的特殊整数表示。
例如，数量 <code>10500m</code> 用十进制表示为 <code>10.5</code>。
如果可能的话，度量指标 API 将返回没有后缀的整数，否则返回以千分单位的数量。
这意味着你可能会看到你的度量指标在 <code>1</code> 和 <code>1500m</code> （也就是在十进制记数法中的 <code>1</code> 和 <code>1.5</code>）之间波动。</p>
<!--
## Appendix: Other possible scenarios

### Creating the autoscaler declaratively
-->
<h2 id="appendix-other-possible-scenarios">附录：其他可能的情况  </h2>
<h3 id="creating-the-autoscaler-declaratively">以声明式方式创建 Autoscaler    </h3>
<!--
Instead of using `kubectl autoscale` command to create a HorizontalPodAutoscaler imperatively we
can use the following file to create it declaratively:
-->
<p>除了使用 <code>kubectl autoscale</code> 命令，也可以文件创建 HorizontalPodAutoscaler：</p>


 













<div class="highlight">
    <div class="copy-code-icon" style="text-align:right">
    <a href="https://raw.githubusercontent.com/kubernetes/website/main/content/zh/examples/application/hpa/php-apache.yaml" download="application/hpa/php-apache.yaml"><code>application/hpa/php-apache.yaml</code>
    </a>
    <img src="/images/copycode.svg" style="max-height:24px; cursor: pointer" onclick="copyCode('application-hpa-php-apache-yaml')" title="Copy application/hpa/php-apache.yaml to clipboard">
    </img>
    </div>
    <div class="includecode" id="application-hpa-php-apache-yaml">
    <div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>autoscaling/v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>HorizontalPodAutoscaler<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>php-apache<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">scaleTargetRef</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>apps/v1<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Deployment<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>php-apache<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">minReplicas</span>:<span style="color:#bbb"> </span><span style="color:#666">1</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">maxReplicas</span>:<span style="color:#bbb"> </span><span style="color:#666">10</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">targetCPUUtilizationPercentage</span>:<span style="color:#bbb"> </span><span style="color:#666">50</span><span style="color:#bbb">
</span></code></pre></div>
    </div>
</div>


<!--
We will create the autoscaler by executing the following command:
-->
<p>使用如下命令创建 autoscaler：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl create -f https://k8s.io/examples/application/hpa/php-apache.yaml
</code></pre></div><pre><code>horizontalpodautoscaler.autoscaling/php-apache created
</code></pre>
</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-fbe2744f00d1aa4df4cdf4eea6a082d4">8 - 为应用程序设置干扰预算（Disruption Budget）</h1>
    
	<!--
title: Specifying a Disruption Budget for your Application
content_type: task
weight: 110
-->
<!-- overview -->





<div style="margin-top: 10px; margin-bottom: 10px;">
  <b>FEATURE STATE:</b> <code>Kubernetes v1.21 [stable]</code>
</div>


<!--
This page shows how to limit the number of concurrent disruptions
that your application experiences, allowing for higher availability
while permitting the cluster administrator to manage the clusters
nodes.
-->
<p>本文展示如何限制应用程序的并发干扰数量，在允许集群管理员管理集群节点的同时保证高可用。</p>
<h2 id="before-you-begin">Before you begin</h2>


Your Kubernetes server must be at or later than version v1.21.
 To check the version, enter <code>kubectl version</code>.

<!--
* You are the owner of an application running on a Kubernetes cluster that requires
  high availability.
* You should know how to deploy [Replicated Stateless Applications](/docs/tasks/run-application/run-stateless-application-deployment/)
  and/or [Replicated Stateful Applications](/docs/tasks/run-application/run-replicated-stateful-application/).
* You should have read about [Pod Disruptions](/docs/concepts/workloads/pods/disruptions/).
* You should confirm with your cluster owner or service provider that they respect
  Pod Disruption Budgets.
-->
<ul>
<li>你是 Kubernetes 集群中某应用的所有者，该应用有高可用要求。</li>
<li>你应了解如何部署<a href="/zh/docs/tasks/run-application/run-stateless-application-deployment/">无状态应用</a>
和/或<a href="/zh/docs/tasks/run-application/run-replicated-stateful-application/">有状态应用</a>。</li>
<li>你应当已经阅读过关于 <a href="/zh/docs/concepts/workloads/pods/disruptions/">Pod 干扰</a> 的文档。</li>
<li>用户应当与集群所有者或服务提供者确认其遵从 Pod 干扰预算（Pod Disruption Budgets）的规则。</li>
</ul>
<!-- steps -->
<!--
## Protecting an Application with a PodDisruptionBudget

1. Identify what application you want to protect with a PodDisruptionBudget (PDB).
1. Think about how your application reacts to disruptions.
1. Create a PDB definition as a YAML file.
1. Create the PDB object from the YAML file.
-->
<h2 id="用-poddisruptionbudget-来保护应用">用 PodDisruptionBudget 来保护应用</h2>
<ol>
<li>确定想要使用 PodDisruptionBudget (PDB) 来保护的应用。</li>
<li>考虑应用对干扰的反应。</li>
<li>以 YAML 文件形式定义 PDB 。</li>
<li>通过 YAML 文件创建 PDB 对象。</li>
</ol>
<!-- discussion -->
<!--
## Identify an Application to Protect

The most common use case when you want to protect an application
specified by one of the built-in Kubernetes controllers:
-->
<h2 id="确定要保护的应用">确定要保护的应用</h2>
<p>用户想要保护通过内置的 Kubernetes 控制器指定的应用，这是最常见的使用场景：</p>
<ul>
<li>Deployment</li>
<li>ReplicationController</li>
<li>ReplicaSet</li>
<li>StatefulSet</li>
</ul>
<!--
In this case, make a note of the controller's `.spec.selector`; the same
selector goes into the PDBs `.spec.selector`.
-->
<p>在这种情况下，在控制器的 <code>.spec.selector</code> 字段中做记录，并在 PDB 的
<code>.spec.selector</code> 字段中加入同样的选择算符。</p>
<!--
From version 1.15 PDBs support custom controllers where the [scale subresource](/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#scale-subresource) is enabled.
-->
<p>从 1.15 版本开始，PDB 支持启用
<a href="/zh/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#scale-subresource">scale 子资源</a>
的自定义控制器。</p>
<!--
You can also use PDBs with pods which are not controlled by one of the above
controllers, or arbitrary groups of pods, but there are some restrictions,
described in [Arbitrary Controllers and Selectors](#arbitrary-controllers-and-selectors).
-->
<p>用户也可以用 PDB 来保护不受上述控制器控制的 Pod，或任意的 Pod 集合，但是正如
<a href="#arbitrary-controllers-and-selectors">任意控制器和选择算符</a>中描述的，这里存在一些限制。</p>
<!--
## Think about how your application reacts to disruptions

Decide how many instances can be down at the same time for a short period
due to a voluntary disruption.
-->
<h2 id="考虑应用对干扰的反应">考虑应用对干扰的反应</h2>
<p>确定在自发干扰时，多少实例可以在短时间内同时关闭。</p>
<!--
- Stateless frontends:
  - Concern: don't reduce serving capacity by more than 10%.
    - Solution: use PDB with minAvailable 90% for example.
- Single-instance Stateful Application:
  - Concern: do not terminate this application without talking to me.
    - Possible Solution 1: Do not use a PDB and tolerate occasional downtime.
    - Possible Solution 2: Set PDB with maxUnavailable=0.  Have an understanding
      (outside of Kubernetes) that the cluster operator needs to consult you before
      termination.  When the cluster operator contacts you, prepare for downtime,
      and then delete the PDB to indicate readiness for disruption.  Recreate afterwards.
- Multiple-instance Stateful application such as Consul, ZooKeeper, or etcd:
  - Concern: Do not reduce number of instances below quorum, otherwise writes fail.
    - Possible Solution 1: set maxUnavailable to 1 (works with varying scale of application).
    - Possible Solution 2: set minAvailable to quorum-size (e.g. 3 when scale is 5).  (Allows more disruptions at once).
- Restartable Batch Job:
  - Concern: Job needs to complete in case of voluntary disruption.
    - Possible solution: Do not create a PDB.  The Job controller will create a replacement pod.
-->
<ul>
<li>无状态的前端：
<ul>
<li>关注：不能降低服务能力 10% 以上。
<ul>
<li>解决方案：例如，使用 PDB，指定其 minAvailable 值为 90%。</li>
</ul>
</li>
</ul>
</li>
<li>单实例有状态应用：
<ul>
<li>关注：不要在不通知的情况下终止该应用。
<ul>
<li>可能的解决方案 1：不使用 PDB，并忍受偶尔的停机。</li>
<li>可能的解决方案 2：设置 maxUnavailable=0 的 PDB。
意为（Kubernetes 范畴之外的）集群操作人员需要在终止应用前与用户协商，
协商后准备停机，然后删除 PDB 表示准备接受干扰，后续再重新创建。</li>
</ul>
</li>
</ul>
</li>
<li>多实例有状态应用，如 Consul、ZooKeeper 或 etcd：
<ul>
<li>关注：不要将实例数量减少至低于仲裁规模，否则将出现写入失败。
<ul>
<li>可能的解决方案 1：设置 maxUnavailable 值为 1 (适用于不同规模的应用)。</li>
<li>可能的解决方案 2：设置 minAvailable 值为仲裁规模（例如规模为 5 时设置为 3）。
(允许同时出现更多的干扰)。</li>
</ul>
</li>
</ul>
</li>
<li>可重新启动的批处理任务：
<ul>
<li>关注：自发干扰的情况下，需要确保任务完成。
<ul>
<li>可能的解决方案：不创建 PDB。 任务控制器会创建一个替换 Pod。</li>
</ul>
</li>
</ul>
</li>
</ul>
<!--
### Rounding logic when specifying percentages

Values for `minAvailable` or `maxUnavailable` can be expressed as integers or as a percentage.
-->
<h3 id="指定百分比时的舍入逻辑">指定百分比时的舍入逻辑</h3>
<p><code>minAvailable</code> 或 <code>maxUnavailable</code> 的值可以表示为整数或百分比。</p>
<!--
- When you specify an integer, it represents a number of Pods. For instance, if you set `minAvailable` to 10, then 10
  Pods must always be available, even during a disruption.
- When you specify a percentage by setting the value to a string representation of a percentage (eg. `"50%"`), it represents a percentage of
  total Pods. For instance, if you set `minUnavailable` to `"50%"`, then only 50% of the Pods can be unavailable during a
  disruption.
-->
<ul>
<li>指定整数值时，它表示 Pod 个数。例如，如果将 minAvailable 设置为 10，
那么即使在干扰期间，也必须始终有 10 个Pod可用。</li>
<li>通过将值设置为百分比的字符串表示形式（例如 “50％”）来指定百分比时，它表示占总 Pod 数的百分比。
例如，如果将 &quot;minUnavailable&quot; 设置为 “50％”，则干扰期间只允许 50％ 的 Pod 不可用。</li>
</ul>
<!--
When you specify the value as a percentage, it may not map to an exact number
of Pods. For example, if you have 7 Pods and you set `minAvailable` to
`"50%"`, it's not immediately obvious whether that means 3 Pods or 4 Pods must
be available.  Kubernetes rounds up to the nearest integer, so in this case, 4
Pods must be available. You can examine the
[code](https://github.com/kubernetes/kubernetes/blob/23be9587a0f8677eb8091464098881df939c44a9/pkg/controller/disruption/disruption.go#L539)
that controls this behavior.
-->
<p>如果将值指定为百分比，则可能无法映射到确切数量的 Pod。例如，如果你有 7 个 Pod，
并且你将 <code>minAvailable</code> 设置为 <code>&quot;50％&quot;</code>，具体是 3 个 Pod 或 4 个 Pod 必须可用
并非显而易见。
Kubernetes 采用向上取整到最接近的整数的办法，因此在这种情况下，必须有 4 个 Pod。
你可以检查控制此行为的
<a href="https://github.com/kubernetes/kubernetes/blob/23be9587a0f8677eb8091464098881df939c44a9/pkg/controller/disruption/disruption.go#L539">代码</a>。</p>
<!--
## Specifying a PodDisruptionBudget

A `PodDisruptionBudget` has three fields: 
-->
<h2 id="指定-poddisruptionbudget">指定 PodDisruptionBudget</h2>
<p>一个 <code>PodDisruptionBudget</code> 有 3 个字段：</p>
<!--
* A label selector `.spec.selector` to specify the set of
pods to which it applies. This field is required.
* `.spec.minAvailable` which is a description of the number of pods from that
set that must still be available after the eviction, even in the absence
of the evicted pod. `minAvailable` can be either an absolute number or a percentage.
* `.spec.maxUnavailable` (available in Kubernetes 1.7 and higher) which is a description
of the number of pods from that set that can be unavailable after the eviction.
It can be either an absolute number or a percentage.
-->
<ul>
<li>标签选择算符 <code>.spec.selector</code> 用于指定其所作用的 Pod 集合，该字段为必需字段。</li>
<li><code>.spec.minAvailable</code> 表示驱逐后仍须保证可用的 Pod 数量。即使因此影响到 Pod 驱逐
（即该条件在和 Pod 驱逐发生冲突时优先保证）。
<code>minAvailable</code> 值可以是绝对值，也可以是百分比。</li>
<li><code>.spec.maxUnavailable</code> （Kubernetes 1.7 及更高的版本中可用）表示驱逐后允许不可用的
Pod 的最大数量。其值可以是绝对值或是百分比。</li>
</ul>
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> <!--
The behavior for an empty selector differs between the policy/v1beta1 and policy/v1 APIs for
PodDisruptionBudgets. For policy/v1beta1 an empty selector matches zero pods, while
for policy/v1 an empty selector matches every pod in the namespace.
-->
<p><code>policy/v1beta1</code> 和 <code>policy/v1</code> API 中 PodDisruptionBudget 的空选择算符的行为
略有不同。在 <code>policy/v1beta1</code> 中，空的选择算符不会匹配任何 Pods，而
<code>policy/v1</code> 中，空的选择算符会匹配名字空间中所有 Pods。
</div>
<!--
You can specify only one of `maxUnavailable` and `minAvailable` in a single `PodDisruptionBudget`.
`maxUnavailable` can only be used to control the eviction of pods
that have an associated controller managing them. In the examples below, "desired replicas"
is the `scale` of the controller managing the pods being selected by the
`PodDisruptionBudget`.
-->
<p>用户在同一个 <code>PodDisruptionBudget</code> 中只能够指定 <code>maxUnavailable</code> 和 <code>minAvailable</code> 中的一个。
<code>maxUnavailable</code> 只能够用于控制存在相应控制器的 Pod 的驱逐（即不受控制器控制的 Pod 不在
<code>maxUnavailable</code> 控制范围内）。在下面的示例中，
“所需副本” 指的是相应控制器的 <code>scale</code>，控制器对 <code>PodDisruptionBudget</code> 所选择的 Pod 进行管理。</p>
<!--
Example 1: With a `minAvailable` of 5, evictions are allowed as long as they leave behind
5 or more healthy pods among those selected by the PodDisruptionBudget's `selector`.
-->
<p>示例 1：设置 <code>minAvailable</code> 值为 5 的情况下，驱逐时需保证 PodDisruptionBudget 的 <code>selector</code>
选中的 Pod 中 5 个或 5 个以上处于健康状态。</p>
<!--
Example 2: With a `minAvailable` of 30%, evictions are allowed as long as at least 30%
of the number of desired replicas are healthy. 
-->
<p>示例 2：设置 <code>minAvailable</code> 值为 30% 的情况下，驱逐时需保证 Pod 所需副本的至少 30% 处于健康状态。</p>
<!--
Example 3: With a `maxUnavailable` of 5, evictions are allowed as long as there are at most 5
unhealthy replicas among the total number of desired replicas.
-->
<p>示例 3：设置 <code>maxUnavailable</code> 值为 5 的情况下，驱逐时需保证所需副本中最多 5 个处于不可用状态。</p>
<!--
Example 4: With a `maxUnavailable` of 30%, evictions are allowed as long as no more than 30%
of the desired replicas are unhealthy.
-->
<p>示例 4：设置 <code>maxUnavailable</code> 值为 30% 的情况下，驱逐时需保证所需副本中最多 30% 处于不可用状态。</p>
<!--
In typical usage, a single budget would be used for a collection of pods managed by
a controller—for example, the pods in a single ReplicaSet or StatefulSet. 
-->
<p>在典型用法中，干扰预算会被用于一个控制器管理的一组 Pod 中 —— 例如：一个 ReplicaSet 或 StatefulSet
中的 Pod。</p>
<!--
A disruption budget does not truly guarantee that the specified
number/percentage of pods will always be up.  For example, a node that hosts a
pod from the collection may fail when the collection is at the minimum size
specified in the budget, thus bringing the number of available pods from the
collection below the specified size. The budget can only protect against
voluntary evictions, not all causes of unavailability.
-->
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> 干扰预算并不能真正保证指定数量/百分比的 Pod 一直处于运行状态。例如： 当 Pod 集合的
规模处于预算指定的最小值时，承载集合中某个 Pod 的节点发生了故障，这样就导致集合中可用 Pod 的
数量低于预算指定值。预算只能够针对自发的驱逐提供保护，而不能针对所有 Pod 不可用的诱因。
</div>
<!--
A `maxUnavailable` of 0% (or 0) or a `minAvailable` of 100% (or equal to the
number of replicas) may block node drains entirely. This is permitted as per the
semantics of `PodDisruptionBudget`.
-->
<p>设置 <code>maxUnavailable</code> 值为 0%（或 0）或设置 <code>minAvailable</code> 值为 100%（或等于副本数）
可能会阻塞节点，导致资源耗尽。按照 <code>PodDisruptionBudget</code> 的语义，这是允许的。</p>
<!--
You can find examples of pod disruption budgets defined below. They match pods with the label
`app: zookeeper`.
-->
<p>用户可以在下面看到 pod 干扰预算定义的示例，它们与带有 <code>app: zookeeper</code> 标签的 pod 相匹配：</p>
<!--
Example PDB Using minAvailable:
-->
<p>使用 minAvailable 的PDB 示例：</p>


 













<div class="highlight">
    <div class="copy-code-icon" style="text-align:right">
    <a href="https://raw.githubusercontent.com/kubernetes/website/main/content/zh/examples/policy/zookeeper-pod-disruption-budget-minavailable.yaml" download="policy/zookeeper-pod-disruption-budget-minavailable.yaml"><code>policy/zookeeper-pod-disruption-budget-minavailable.yaml</code>
    </a>
    <img src="/images/copycode.svg" style="max-height:24px; cursor: pointer" onclick="copyCode('policy-zookeeper-pod-disruption-budget-minavailable-yaml')" title="Copy policy/zookeeper-pod-disruption-budget-minavailable.yaml to clipboard">
    </img>
    </div>
    <div class="includecode" id="policy-zookeeper-pod-disruption-budget-minavailable-yaml">
    <div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>policy/v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>PodDisruptionBudget<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>zk-pdb<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">minAvailable</span>:<span style="color:#bbb"> </span><span style="color:#666">2</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">matchLabels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>zookeeper<span style="color:#bbb">
</span></code></pre></div>
    </div>
</div>


<!--
Example PDB Using maxUnavailable:
-->
<p>使用 maxUnavailable 的 PDB 示例：</p>


 













<div class="highlight">
    <div class="copy-code-icon" style="text-align:right">
    <a href="https://raw.githubusercontent.com/kubernetes/website/main/content/zh/examples/policy/zookeeper-pod-disruption-budget-maxunavailable.yaml" download="policy/zookeeper-pod-disruption-budget-maxunavailable.yaml"><code>policy/zookeeper-pod-disruption-budget-maxunavailable.yaml</code>
    </a>
    <img src="/images/copycode.svg" style="max-height:24px; cursor: pointer" onclick="copyCode('policy-zookeeper-pod-disruption-budget-maxunavailable-yaml')" title="Copy policy/zookeeper-pod-disruption-budget-maxunavailable.yaml to clipboard">
    </img>
    </div>
    <div class="includecode" id="policy-zookeeper-pod-disruption-budget-maxunavailable-yaml">
    <div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>policy/v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>PodDisruptionBudget<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>zk-pdb<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">maxUnavailable</span>:<span style="color:#bbb"> </span><span style="color:#666">1</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">matchLabels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>zookeeper<span style="color:#bbb">
</span></code></pre></div>
    </div>
</div>


<!--
For example, if the above `zk-pdb` object selects the pods of a StatefulSet of size 3, both
specifications have the exact same meaning. The use of `maxUnavailable` is recommended as it
automatically responds to changes in the number of replicas of the corresponding controller.
-->
<p>例如，如果上述 <code>zk-pdb</code> 选择的是一个规格为 3 的 StatefulSet 对应的 Pod，
那么上面两种规范的含义完全相同。
推荐使用 <code>maxUnavailable</code> ，因为它自动响应控制器副本数量的变化。</p>
<!--
## Create the PDB object

You can create or update the PDB object using kubectl.
```shell
kubectl apply -f mypdb.yaml
```
-->
<h2 id="创建-pdb-对象">创建 PDB 对象</h2>
<p>你可以使用 kubectl 创建或更新 PDB 对象。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl apply -f mypdb.yaml
</code></pre></div><!--
You cannot update PDB objects.  They must be deleted and re-created.
-->
<p>PDB 对象无法更新，必须删除后重新创建。</p>
<!--
## Check the status of the PDB

Use kubectl to check that your PDB is created.
-->
<h2 id="检查-pdb-的状态">检查 PDB 的状态</h2>
<p>使用 kubectl 来确认 PDB 被创建。</p>
<!--
Assuming you don't actually have pods matching `app: zookeeper` in your namespace,
then you'll see something like this:
-->
<p>假设用户的名字空间下没有匹配 <code>app: zookeeper</code> 的 Pod，用户会看到类似下面的信息：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get poddisruptionbudgets
</code></pre></div><pre><code>NAME     MIN AVAILABLE   MAX UNAVAILABLE   ALLOWED DISRUPTIONS   AGE
zk-pdb   2               N/A               0                     7s
</code></pre><!--
If there are matching pods (say, 3), then you would see something like this:
-->
<p>假设有匹配的 Pod (比如说 3 个), 那么用户会看到类似下面的信息：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get poddisruptionbudgets
</code></pre></div><pre><code>NAME     MIN AVAILABLE   MAX UNAVAILABLE   ALLOWED DISRUPTIONS   AGE
zk-pdb   2               N/A               1                     7s

</code></pre><!--
The non-zero value for `ALLOWED-DISRUPTIONS` means that the disruption controller has seen the pods,
counted the matching pods, and updated the status of the PDB.

You can get more information about the status of a PDB with this command:
-->
<p><code>ALLOWED-DISRUPTIONS</code> 值非 0 意味着干扰控制器已经感知到相应的 Pod，对匹配的 Pod 进行统计，
并更新了 PDB 的状态。</p>
<p>用户可以通过以下命令获取更多 PDB 状态相关信息：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get poddisruptionbudgets zk-pdb -o yaml
</code></pre></div><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>policy/v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>PodDisruptionBudget<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">anntation</span>:<span style="color:#bbb"> </span>{}<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">creationTimestamp</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;2020-03-04T04:22:56Z&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">generation</span>:<span style="color:#bbb"> </span><span style="color:#666">1</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>zk-pdb<span style="color:#bbb">
</span><span style="color:#bbb"></span>…<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">status</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">currentHealthy</span>:<span style="color:#bbb"> </span><span style="color:#666">3</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">desiredHealthy</span>:<span style="color:#bbb"> </span><span style="color:#666">2</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">disruptionsAllowed</span>:<span style="color:#bbb"> </span><span style="color:#666">1</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">expectedPods</span>:<span style="color:#bbb"> </span><span style="color:#666">3</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">observedGeneration</span>:<span style="color:#bbb"> </span><span style="color:#666">1</span><span style="color:#bbb">
</span></code></pre></div><!--
## Arbitrary Controllers and Selectors

You can skip this section if you only use PDBs with the built-in
application controllers (Deployment, ReplicationController, ReplicaSet, and StatefulSet),
with the PDB selector matching the controller's selector.
-->
<h2 id="arbitrary-controllers-and-selectors">任意控制器和选择算符  </h2>
<p>如果你只使用与内置的应用控制器（Deployment、ReplicationController、ReplicaSet 和 StatefulSet）
对应的 PDB，也就是 PDB 的选择算符与 控制器的选择算符相匹配，那么可以跳过这一节。</p>
<!--
You can use a PDB with pods controlled by another type of controller, by an
"operator", or bare pods, but with these restrictions:
-->
<p>你可以使用这样的 PDB：它对应的 Pod 可能由其他类型的控制器控制，可能由 &quot;operator&quot; 控制，
也可能为“裸的（不受控制器控制）” Pod，但该类 PDB 存在以下限制：</p>
<!--
- only `.spec.minAvailable` can be used, not `.spec.maxUnavailable`.
- only an integer value can be used with `.spec.minAvailable`, not a percentage.
-->
<ul>
<li>只能够使用 <code>.spec.minAvailable</code> ，而不能够使用 <code>.spec.maxUnavailable。</code></li>
<li>只能够使用整数作为 <code>.spec.minAvailable</code> 的值，而不能使用百分比。</li>
</ul>
<!--
You can use a selector which selects a subset or superset of the pods belonging to a built-in
controller.  However, when there are multiple PDBs in a namespace, you must be careful not
to create PDBs whose selectors overlap.
-->
<p>你可以令选择算符选择一个内置控制器所控制 Pod 的子集或父集。
然而，当名字空间下存在多个 PDB 时，用户必须小心，保证 PDB 的选择算符之间不重叠。</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-52cd10ee3fc7c74a6c31043a2d489878">9 - 从 Pod 中访问 Kubernetes API</h1>
    
	<!--
title: Accessing the Kubernetes API from a Pod
content_type: task
weight: 120
-->
<!-- overview -->
<!--
This guide demonstrates how to access the Kubernetes API from within a pod.
-->
<p>本指南演示了如何从 Pod 中访问 Kubernetes API。</p>
<h2 id="before-you-begin">Before you begin</h2>
<p>你必须拥有一个 Kubernetes 的集群，同时你的 Kubernetes 集群必须带有 kubectl 命令行工具。
建议在至少有两个节点的集群上运行本教程，且这些节点不作为控制平面主机。
如果你还没有集群，你可以通过 <a href="https://minikube.sigs.k8s.io/docs/tutorials/multi_node/">Minikube</a>
构建一个你自己的集群，或者你可以使用下面任意一个 Kubernetes 工具构建：</p>
<!--
You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. It is recommended to run this tutorial on a cluster with at least two nodes that are not acting as control plane hosts. If you do not already have a
cluster, you can create one by using
[minikube](https://minikube.sigs.k8s.io/docs/tutorials/multi_node/)
or you can use one of these Kubernetes playgrounds:
-->
<ul>
<li><a href="https://www.katacoda.com/courses/kubernetes/playground">Katacoda</a></li>
<li><a href="http://labs.play-with-k8s.com/">玩转 Kubernetes</a></li>
</ul>

<!-- steps -->
<!--
## Accessing the API from within a Pod

When accessing the API from within a Pod, locating and authenticating
to the API server are slightly different to the external client case.
-->
<h3 id="accessing-the-api-from-within-a-pod">从 Pod 中访问 API  </h3>
<p>从 Pod 内部访问 API 时，定位 API 服务器和向服务器认证身份的操作
与外部客户端场景不同。</p>
<!--
The easiest way to use the Kubernetes API from a Pod is to use
one of the official [client libraries](/docs/reference/using-api/client-libraries/). These
libraries can automatically discover the API server and authenticate.
-->
<p>从 Pod 使用 Kubernetes API 的最简单的方法就是使用官方的
<a href="/zh/docs/reference/using-api/client-libraries/">客户端库</a>。
这些库可以自动发现 API 服务器并进行身份验证。</p>
<!--
### Using Official Client Libraries

From within a Pod, the recommended ways to connect to the Kubernetes API are:

  - For a Go client, use the official [Go client library](https://github.com/kubernetes/client-go/).
    The `rest.InClusterConfig()` function handles API host discovery and authentication automatically.
    See [an example here](https://git.k8s.io/client-go/examples/in-cluster-client-configuration/main.go).

  - For a Python client, use the official [Python client library](https://github.com/kubernetes-client/python/).
    The `config.load_incluster_config()` function handles API host discovery and authentication automatically.
    See [an example here](https://github.com/kubernetes-client/python/blob/master/examples/in_cluster_config.py).

  - There are a number of other libraries available, please refer to the [Client Libraries](/docs/reference/using-api/client-libraries/) page.

In each case, the service account credentials of the Pod are used to communicate
securely with the API server.
-->
<h4 id="using-official-client-libraries">使用官方客户端库  </h4>
<p>从一个 Pod 内部连接到 Kubernetes API 的推荐方式为：</p>
<ul>
<li>
<p>对于 Go 语言客户端，使用官方的 <a href="https://github.com/kubernetes/client-go/">Go 客户端库</a>。
函数 <code>rest.InClusterConfig()</code> 自动处理 API 主机发现和身份认证。
参见<a href="https://git.k8s.io/client-go/examples/in-cluster-client-configuration/main.go">这里的一个例子</a>。</p>
</li>
<li>
<p>对于 Python 客户端，使用官方的 <a href="https://github.com/kubernetes-client/python/">Python 客户端库</a>。
函数 <code>config.load_incluster_config()</code> 自动处理 API 主机的发现和身份认证。
参见<a href="https://github.com/kubernetes-client/python/blob/master/examples/in_cluster_config.py">这里的一个例子</a>。</p>
</li>
<li>
<p>还有一些其他可用的客户端库，请参阅<a href="/zh/docs/reference/using-api/client-libraries/">客户端库</a>页面。</p>
</li>
</ul>
<p>在以上场景中，客户端库都使用 Pod 的服务账号凭据来与 API 服务器安全地通信。</p>
<!--
### Directly accessing the REST API

While running in a Pod, the Kubernetes apiserver is accessible via a Service named
`kubernetes` in the `default` namespace. Therefore, Pods can use the
`kubernetes.default.svc` hostname to query the API server. Official client libraries
do this automatically.
-->
<h4 id="directly-accessing-the-rest-api">直接访问 REST API  </h4>
<p>在运行在 Pod 中时，可以通过 <code>default</code> 命名空间中的名为 <code>kubernetes</code> 的服务访问
Kubernetes API 服务器。也就是说，Pod 可以使用 <code>kubernetes.default.svc</code> 主机名
来查询 API 服务器。官方客户端库自动完成这个工作。</p>
<!--
The recommended way to authenticate to the API server is with a
[service account](/docs/tasks/configure-pod-container/configure-service-account/)
credential. By default, a Pod
is associated with a service account, and a credential (token) for that
service account is placed into the filesystem tree of each container in that Pod,
at `/var/run/secrets/kubernetes.io/serviceaccount/token`.
-->
<p>向 API 服务器进行身份认证的推荐做法是使用
<a href="/zh/docs/tasks/configure-pod-container/configure-service-account/">服务账号</a>凭据。
默认情况下，每个 Pod 与一个服务账号关联，该服务账户的凭证（令牌）放置在此 Pod 中
每个容器的文件系统树中的 <code>/var/run/secrets/kubernetes.io/serviceaccount/token</code> 处。</p>
<!--
If available, a certificate bundle is placed into the filesystem tree of each
container at `/var/run/secrets/kubernetes.io/serviceaccount/ca.crt`, and should be
used to verify the serving certificate of the API server.
-->
<p>如果证书包可用，则凭证包被放入每个容器的文件系统树中的
<code>/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</code> 处，
且将被用于验证 API 服务器的服务证书。</p>
<!--
Finally, the default namespace to be used for namespaced API operations is placed in a file
at `/var/run/secrets/kubernetes.io/serviceaccount/namespace` in each container.
-->
<p>最后，用于命名空间域 API 操作的默认命名空间放置在每个容器中的
<code>/var/run/secrets/kubernetes.io/serviceaccount/namespace</code> 文件中。</p>
<!--
### Using kubectl proxy

If you would like to query the API without an official client library, you can run `kubectl proxy`
as the [command](/docs/tasks/inject-data-application/define-command-argument-container/)
of a new sidecar container in the Pod. This way, `kubectl proxy` will authenticate
to the API and expose it on the `localhost` interface of the Pod, so that other containers
in the Pod can use it directly.
-->
<h4 id="use-kubectl-proxy">使用 kubectl proxy  </h4>
<p>如果你希望不使用官方客户端库就完成 API 查询，可以将 <code>kubectl proxy</code> 作为
<a href="/zh/docs/tasks/inject-data-application/define-command-argument-container/">command</a>
在 Pod 中启动一个边车（Sidecar）容器。这样，<code>kubectl proxy</code> 自动完成对 API
的身份认证，并将其暴露到 Pod 的 <code>localhost</code> 接口，从而 Pod 中的其他容器可以
直接使用 API。</p>
<!--
### Without using a proxy

It is possible to avoid using the kubectl proxy by passing the authentication token
directly to the API server.  The internal certificate secures the connection.
-->
<h3 id="without-using-a-proxy">不使用代理  </h3>
<p>通过将认证令牌直接发送到 API 服务器，也可以避免运行 kubectl proxy 命令。
内部的证书机制能够为链接提供保护。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#080;font-style:italic"># 指向内部 API 服务器的主机名</span>
<span style="color:#b8860b">APISERVER</span><span style="color:#666">=</span>https://kubernetes.default.svc

<span style="color:#080;font-style:italic"># 服务账号令牌的路径</span>
<span style="color:#b8860b">SERVICEACCOUNT</span><span style="color:#666">=</span>/var/run/secrets/kubernetes.io/serviceaccount

<span style="color:#080;font-style:italic"># 读取 Pod 的名字空间</span>
<span style="color:#b8860b">NAMESPACE</span><span style="color:#666">=</span><span style="color:#a2f;font-weight:bold">$(</span>cat <span style="color:#b68;font-weight:bold">${</span><span style="color:#b8860b">SERVICEACCOUNT</span><span style="color:#b68;font-weight:bold">}</span>/namespace<span style="color:#a2f;font-weight:bold">)</span>

<span style="color:#080;font-style:italic"># 读取服务账号的持有者令牌</span>
<span style="color:#b8860b">TOKEN</span><span style="color:#666">=</span><span style="color:#a2f;font-weight:bold">$(</span>cat <span style="color:#b68;font-weight:bold">${</span><span style="color:#b8860b">SERVICEACCOUNT</span><span style="color:#b68;font-weight:bold">}</span>/token<span style="color:#a2f;font-weight:bold">)</span>

<span style="color:#080;font-style:italic"># 引用内部证书机构（CA）</span>
<span style="color:#b8860b">CACERT</span><span style="color:#666">=</span><span style="color:#b68;font-weight:bold">${</span><span style="color:#b8860b">SERVICEACCOUNT</span><span style="color:#b68;font-weight:bold">}</span>/ca.crt

<span style="color:#080;font-style:italic"># 使用令牌访问 API</span>
curl --cacert <span style="color:#b68;font-weight:bold">${</span><span style="color:#b8860b">CACERT</span><span style="color:#b68;font-weight:bold">}</span> --header <span style="color:#b44">&#34;Authorization: Bearer </span><span style="color:#b68;font-weight:bold">${</span><span style="color:#b8860b">TOKEN</span><span style="color:#b68;font-weight:bold">}</span><span style="color:#b44">&#34;</span> -X GET <span style="color:#b68;font-weight:bold">${</span><span style="color:#b8860b">APISERVER</span><span style="color:#b68;font-weight:bold">}</span>/api
</code></pre></div><!--
The output will be similar to this:
-->
<p>输出类似于：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-json" data-lang="json">{
  <span style="color:#008000;font-weight:bold">&#34;kind&#34;</span>: <span style="color:#b44">&#34;APIVersions&#34;</span>,
  <span style="color:#008000;font-weight:bold">&#34;versions&#34;</span>: [
    <span style="color:#b44">&#34;v1&#34;</span>
  ],
  <span style="color:#008000;font-weight:bold">&#34;serverAddressByClientCIDRs&#34;</span>: [
    {
      <span style="color:#008000;font-weight:bold">&#34;clientCIDR&#34;</span>: <span style="color:#b44">&#34;0.0.0.0/0&#34;</span>,
      <span style="color:#008000;font-weight:bold">&#34;serverAddress&#34;</span>: <span style="color:#b44">&#34;10.0.1.149:443&#34;</span>
    }
  ]
}
</code></pre></div>
</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-7a9b5779e228083ba3fdeaf414fe704e">10 - 扩缩 StatefulSet</h1>
    
	<!-- overview -->
<!--
This task shows how to scale a StatefulSet. Scaling a StatefulSet refers to increasing or decreasing the number of replicas.
-->
<p>本文介绍如何扩缩StatefulSet。StatefulSet 的扩缩指的是增加或者减少副本个数。</p>
<h2 id="before-you-begin">Before you begin</h2>
<!--
* StatefulSets are only available in Kubernetes version 1.5 or later.
  To check your version of Kubernetes, run `kubectl version`.

* Not all stateful applications scale nicely. If you are unsure about whether to scale your StatefulSets, see [StatefulSet concepts](/docs/concepts/workloads/controllers/statefulset/) or [StatefulSet tutorial](/docs/tutorials/stateful-application/basic-stateful-set/) for further information.

* You should perform scaling only when you are confident that your stateful application
  cluster is completely healthy.
-->
<ul>
<li>
<p>StatefulSets 仅适用于 Kubernetes 1.5 及以上版本。</p>
</li>
<li>
<p>不是所有 Stateful 应用都能很好地执行扩缩操作。
如果你不是很确定是否要扩缩你的 StatefulSet，可先参阅
<a href="/zh/docs/concepts/workloads/controllers/statefulset/">StatefulSet 概念</a>
或者 <a href="/zh/docs/tutorials/stateful-application/basic-stateful-set/">StatefulSet 教程</a>。</p>
</li>
<li>
<p>仅当你确定你的有状态应用的集群是完全健康的，才可执行扩缩操作.</p>
</li>
</ul>
<!-- steps -->
<!--
## Scaling StatefulSets

### Use kubectl to scale StatefulSets

First, find the StatefulSet you want to scale.

```shell
kubectl get statefulsets <stateful-set-name>
```
-->
<h2 id="scaling-statefulset">扩缩 StatefulSet  </h2>
<h2 id="使用-kubectl-扩缩-statefulset">使用 <code>kubectl</code> 扩缩 StatefulSet</h2>
<p>首先，找到你要扩缩的 StatefulSet。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get statefulsets &lt;statefulset 名称&gt;
</code></pre></div><!--
Change the number of replicas of your StatefulSet:

```shell
kubectl scale statefulsets <stateful-set-name> --replicas=<new-replicas>
```
-->
<p>更改 StatefulSet 中副本个数：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl scale statefulsets &lt;statefulset 名称&gt; --replicas<span style="color:#666">=</span>&lt;新的副本数&gt;
</code></pre></div><!--
### Make in-place updates on your StatefulSets

Alternatively, you can do [in-place updates](/docs/concepts/cluster-administration/manage-deployment/#in-place-updates-of-resources) on your StatefulSets.

If your StatefulSet was initially created with `kubectl apply`,
update `.spec.replicas` of the StatefulSet manifests, and then do a `kubectl apply`:
-->
<h3 id="对-statefulset-执行就地更新">对 StatefulSet 执行就地更新</h3>
<p>另外, 你可以<a href="/zh/docs/concepts/cluster-administration/manage-deployment/#in-place-updates-of-resources">就地更新</a> StatefulSet。</p>
<p>如果你的 StatefulSet 最初通过 <code>kubectl apply</code> 或 <code>kubectl create --save-config</code> 创建,
你可以更新 StatefulSet 清单中的 <code>.spec.replicas</code>, 然后执行命令 <code>kubectl apply</code>:</p>
<!--
```shell
kubectl apply -f <stateful-set-file-updated>
```

Otherwise, edit that field with `kubectl edit`:

```shell
kubectl edit statefulsets <stateful-set-name>
```

Or use `kubectl patch`:

```shell
kubectl patch statefulsets <stateful-set-name> -p '{"spec":{"replicas":<new-replicas>}}'
```
-->
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl apply -f &lt;更新后的 statefulset 文件&gt;
</code></pre></div><p>否则，可以使用 <code>kubectl edit</code> 编辑副本字段：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl edit statefulsets &lt;statefulset 名称&gt;
</code></pre></div><p>或者使用 <code>kubectl patch</code>：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl patch statefulsets &lt;statefulset 名称&gt; -p <span style="color:#b44">&#39;{&#34;spec&#34;:{&#34;replicas&#34;:&lt;new-replicas&gt;}}&#39;</span>
</code></pre></div><!--
## Troubleshooting

### Scaling down does not work right
-->
<h2 id="troubleshooting">故障排查 </h2>
<h3 id="缩容操作无法正常工作">缩容操作无法正常工作</h3>
<!--
You cannot scale down a StatefulSet when any of the stateful Pods it manages is unhealthy. Scaling down only takes place
after those stateful Pods become running and ready.

If spec.replicas > 1, Kubernetes cannot determine the reason for an unhealthy Pod. It might be the result of a permanent fault or of a transient fault. A transient fault can be caused by a restart required by upgrading or maintenance.
-->
<p>当 Stateful 所管理的任何 Pod 不健康时，你不能对该 StatefulSet 执行缩容操作。
仅当 StatefulSet 的所有 Pod 都处于运行状态和 Ready 状况后才可缩容.</p>
<p>如果 <code>spec.replicas</code> 大于 1，Kubernetes 无法判定 Pod 不健康的原因。
Pod 不健康可能是由于永久性故障造成也可能是瞬态故障。
瞬态故障可能是节点升级或维护而引起的节点重启造成的。</p>
<!--
If the Pod is unhealthy due to a permanent fault, scaling
without correcting the fault may lead to a state where the StatefulSet membership
drops below a certain minimum number of replicas that are needed to function
correctly. This may cause your StatefulSet to become unavailable.
-->
<p>如果该 Pod 不健康是由于永久性故障导致, 则在不纠正该故障的情况下进行缩容可能会导致
StatefulSet 进入一种状态，其成员 Pod 数量低于应正常运行的副本数。
这种状态也许会导致 StatefulSet 不可用。</p>
<!--
If the Pod is unhealthy due to a transient fault and the Pod might become available again,
the transient error may interfere with your scale-up or scale-down operation. Some distributed
databases have issues when nodes join and leave at the same time. It is better
to reason about scaling operations at the application level in these cases, and
perform scaling only when you are sure that your stateful application cluster is
completely healthy.
-->
<p>如果由于瞬态故障而导致 Pod 不健康并且 Pod 可能再次变为可用，那么瞬态错误可能会干扰
你对 StatefulSet 的扩容/缩容操作。 一些分布式数据库在同时有节点加入和离开时
会遇到问题。在这些情况下，最好是在应用级别进行分析扩缩操作的状态, 并且只有在确保
Stateful 应用的集群是完全健康时才执行扩缩操作。</p>
<h2 id="what-s-next">What's next</h2>
<!--
* Learn more about [deleting a StatefulSet](/docs/tasks/run-application/delete-stateful-set/).
-->
<ul>
<li>进一步了解<a href="/zh/docs/tasks/run-application/delete-stateful-set/">删除 StatefulSet</a></li>
</ul>

</div>



    
	
  



          </main>
        </div>
      </div>
      
<footer class="d-print-none">
  <div class="footer__links">
    <nav>
      
      
      
      <a class="text-white" href="/zh/docs/home/">主页</a>
      
      <a class="text-white" href="/zh/blog/">博客</a>
      
      <a class="text-white" href="/zh/training/">培训</a>
      
      <a class="text-white" href="/zh/partners/">合作伙伴</a>
      
      <a class="text-white" href="/zh/community/">社区</a>
      
      <a class="text-white" href="/zh/case-studies/">案例分析</a>
      
    </nav>
  </div>
  <div class="container-fluid">
    <div class="row">
      <div class="col-6 col-sm-2 text-xs-center order-sm-2">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="User mailing list" aria-label="User mailing list">
    <a class="text-white" target="_blank" href="https://discuss.kubernetes.io">
      <i class="fa fa-envelope"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Twitter" aria-label="Twitter">
    <a class="text-white" target="_blank" href="https://twitter.com/kubernetesio">
      <i class="fab fa-twitter"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Calendar" aria-label="Calendar">
    <a class="text-white" target="_blank" href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io">
      <i class="fas fa-calendar-alt"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Youtube" aria-label="Youtube">
    <a class="text-white" target="_blank" href="https://youtube.com/kubernetescommunity">
      <i class="fab fa-youtube"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-6 col-sm-2 text-right text-xs-center order-sm-3">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="GitHub" aria-label="GitHub">
    <a class="text-white" target="_blank" href="https://github.com/kubernetes/kubernetes">
      <i class="fab fa-github"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Slack" aria-label="Slack">
    <a class="text-white" target="_blank" href="https://slack.k8s.io">
      <i class="fab fa-slack"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Contribute" aria-label="Contribute">
    <a class="text-white" target="_blank" href="https://git.k8s.io/community/contributors/guide">
      <i class="fas fa-edit"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Stack Overflow" aria-label="Stack Overflow">
    <a class="text-white" target="_blank" href="https://stackoverflow.com/questions/tagged/kubernetes">
      <i class="fab fa-stack-overflow"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-12 col-sm-8 text-center order-sm-2">
        <small class="text-white">&copy; 2024 The Kubernetes Authors | Documentation Distributed under <a href="https://git.k8s.io/website/LICENSE" class="light-text">CC BY 4.0</a></small>
        <br/>
        <small class="text-white">Copyright &copy; 2024 The Linux Foundation &reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href="https://www.linuxfoundation.org/trademark-usage" class="light-text">Trademark Usage page</a></small>
        <br/>
        <small class="text-white">ICP license: 京ICP备17074266号-3</small>
        
        
          
        
      </div>
    </div>
  </div>
</footer>


    </div>
    
<script src="/js/popper-1.14.3.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="/js/bootstrap-4.3.1.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>










<script src="/js/main.js"></script>






  </body>
</html>
