<!doctype html>
<html lang="zh" class="no-js">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    
<meta name="ROBOTS" content="NOINDEX, NOFOLLOW">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-36037335-10"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-36037335-10');
</script>


<link rel="alternate" hreflang="en" href="http://localhost:1313/docs/tasks/administer-cluster/kubeadm/">
<link rel="alternate" hreflang="ko" href="http://localhost:1313/ko/docs/tasks/administer-cluster/kubeadm/">
<link rel="alternate" hreflang="ja" href="http://localhost:1313/ja/docs/tasks/administer-cluster/kubeadm/">
<link rel="alternate" hreflang="fr" href="http://localhost:1313/fr/docs/tasks/administer-cluster/kubeadm/">
<link rel="alternate" hreflang="de" href="http://localhost:1313/de/docs/tasks/administer-cluster/kubeadm/">
<link rel="alternate" hreflang="es" href="http://localhost:1313/es/docs/tasks/administer-cluster/kubeadm/">

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.87.0" />
<link rel="canonical" type="text/html" href="http://localhost:1313/zh/docs/tasks/administer-cluster/kubeadm/">
<link rel="shortcut icon" type="image/png" href="/images/favicon.png">
<link rel="apple-touch-icon" href="/favicons/apple-touch-icon-180x180.png" sizes="180x180">
<link rel="manifest" href="/manifest.webmanifest">
<link rel="apple-touch-icon" href="/images/kubernetes-192x192.png">
<title>用 kubeadm 进行管理 | Kubernetes</title><meta property="og:title" content="用 kubeadm 进行管理" />
<meta property="og:description" content="生产级别的容器编排系统" />
<meta property="og:type" content="website" />
<meta property="og:url" content="http://localhost:1313/zh/docs/tasks/administer-cluster/kubeadm/" /><meta property="og:site_name" content="Kubernetes" />

<meta itemprop="name" content="用 kubeadm 进行管理">
<meta itemprop="description" content="生产级别的容器编排系统"><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="用 kubeadm 进行管理"/>
<meta name="twitter:description" content="生产级别的容器编排系统"/>






<link href="/scss/main.css" rel="stylesheet">


<script
  src="/js/jquery-3.3.1.min.js"
  integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
  crossorigin="anonymous"></script>





<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "url": "https://kubernetes.io",
    "logo": "https://kubernetes.io/images/favicon.png",
    "potentialAction": {
      "@type": "SearchAction",
      "target": "http://localhost:1313/search/?q={search_term_string}",
      "query-input": "required name=search_term_string"
    }

  }
</script>
<meta name="theme-color" content="#326ce5">




<link rel="stylesheet" href="/css/feature-states.css">



<meta name="description" content="">
<meta property="og:description" content="">
<meta name="twitter:description" content="">
<meta property="og:url" content="http://localhost:1313/zh/docs/tasks/administer-cluster/kubeadm/">
<meta property="og:title" content="用 kubeadm 进行管理">
<meta name="twitter:title" content="用 kubeadm 进行管理">
<meta name="twitter:image" content="https://kubernetes.io/images/favicon.png" />

<meta name="twitter:image:alt" content="Kubernetes">

<meta property="og:image" content="/images/kubernetes-horizontal-color.png">

<meta property="og:type" content="article">

<script src="/js/script.js"></script>


  </head>
  <body class="td-section">
    <header>
      
<nav class="js-navbar-scroll navbar navbar-expand navbar-dark  flex-column flex-md-row td-navbar" data-auto-burger="primary">
        <a class="navbar-brand" href="/zh/"></a>
	<div class="td-navbar-nav-scroll ml-md-auto" id="main_navbar">
		
		<ul class="navbar-nav mt-2 mt-lg-0">
			
			
			
			
			<li class="nav-item mr-2 mb-lg-0">
				
				<a class="nav-link active" href="/zh/docs/" >文档</a>
			</li>
			
			
			
			<li class="nav-item mr-2 mb-lg-0">
				
				<a class="nav-link" href="/zh/blog/" >Kubernetes 博客</a>
			</li>
			
			
			
			<li class="nav-item mr-2 mb-lg-0">
				
				<a class="nav-link" href="/zh/training/" >培训</a>
			</li>
			
			
			
			<li class="nav-item mr-2 mb-lg-0">
				
				<a class="nav-link" href="/zh/partners/" >合作伙伴</a>
			</li>
			
			
			
			<li class="nav-item mr-2 mb-lg-0">
				
				<a class="nav-link" href="/zh/community/" >社区</a>
			</li>
			
			
			
			<li class="nav-item mr-2 mb-lg-0">
				
				<a class="nav-link" href="/zh/case-studies/" >案例分析</a>
			</li>
			
			
			
			<li class="nav-item dropdown">
				<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
	Versions
</a>
<div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdownMenuLink">
	
	<a class="dropdown-item" href="/releases">Release Information</a>
	
	<a class="dropdown-item" href="https://kubernetes.io/zh/docs/tasks/administer-cluster/kubeadm/">v1.23</a>
	
	<a class="dropdown-item" href="https://v1-22.docs.kubernetes.io/zh/docs/tasks/administer-cluster/kubeadm/">v1.22</a>
	
	<a class="dropdown-item" href="https://v1-21.docs.kubernetes.io/zh/docs/tasks/administer-cluster/kubeadm/">v1.21</a>
	
	<a class="dropdown-item" href="https://v1-20.docs.kubernetes.io/zh/docs/tasks/administer-cluster/kubeadm/">v1.20</a>
	
	<a class="dropdown-item" href="https://v1-19.docs.kubernetes.io/zh/docs/tasks/administer-cluster/kubeadm/">v1.19</a>
	
</div>
			</li>
			
			
			<li class="nav-item dropdown">
				

<a class="nav-link dropdown-toggle" href="#" id="navbarDropdownMenuLink" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
	中文 Chinese
</a>
<div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdownMenuLink">
	
	<a class="dropdown-item" href="/docs/tasks/administer-cluster/kubeadm/">English</a>
	
	<a class="dropdown-item" href="/ko/docs/tasks/administer-cluster/kubeadm/">한국어 Korean</a>
	
	<a class="dropdown-item" href="/ja/docs/tasks/administer-cluster/kubeadm/">日本語 Japanese</a>
	
	<a class="dropdown-item" href="/fr/docs/tasks/administer-cluster/kubeadm/">Français</a>
	
	<a class="dropdown-item" href="/de/docs/tasks/administer-cluster/kubeadm/">Deutsch</a>
	
	<a class="dropdown-item" href="/es/docs/tasks/administer-cluster/kubeadm/">Español</a>
	
</div>

			</li>
			
		</ul>
	</div>
	<button id="hamburger" onclick="kub.toggleMenu()" data-auto-burger-exclude><div></div></button>
</nav>
    </header>
    <div class="container-fluid td-outer">
      <div class="td-main">
        <div class="row flex-xl-nowrap">
          <main class="col-12 col-md-9 col-xl-8 pl-md-5" role="main">
            




<div class="td-content">
<div class="pageinfo pageinfo-primary d-print-none">
<p>
这是本节的多页打印视图。
<a href="#" onclick="print();return false;">点击此处打印</a>.
</p><p>
<a href="/zh/docs/tasks/administer-cluster/kubeadm/">返回本页常规视图</a>.
</p>
</div>



<h1 class="title">用 kubeadm 进行管理</h1>





    <ul>
    
  
  
  
  

  
    
    
	
<li>1: <a href="#pg-f62fba1de4084f3be070785757c8079c">使用 kubeadm 进行证书管理</a></li>


    
  
    
    
	
<li>2: <a href="#pg-6134c5061298affa145ddb801b5c29da">配置 cgroup 驱动</a></li>


    
  
    
    
	
<li>3: <a href="#pg-98530eb3653d28fef34bff4543364aa7">重新配置 kubeadm 集群</a></li>


    
  
    
    
	
<li>4: <a href="#pg-2e173356df5179cab9eec90a606f0aa4">升级 kubeadm 集群</a></li>


    
  
    
    
	
<li>5: <a href="#pg-9133578f1e75663bb031e5a377ca896d">添加 Windows 节点</a></li>


    
  
    
    
	
<li>6: <a href="#pg-e805c7d8d4ad6195cb82dbbc843bfc29">升级 Windows 节点</a></li>


    
  

    </ul>


<div class="content">
      
</div>
</div>


  
  
  
  

  
  

  
    
    
	
    

<div class="td-content" style="">
    
	<h1 id="pg-f62fba1de4084f3be070785757c8079c">1 - 使用 kubeadm 进行证书管理</h1>
    
	<!--
reviewers:
- sig-cluster-lifecycle
title: Certificate Management with kubeadm
content_type: task
weight: 10
-->
<!-- overview -->





<div style="margin-top: 10px; margin-bottom: 10px;">
  <b>FEATURE STATE:</b> <code>Kubernetes v1.15 [stable]</code>
</div>


<!-- 
Client certificates generated by [kubeadm](/docs/reference/setup-tools/kubeadm/) expire after 1 year. This page explains how to manage certificate renewals with kubeadm. 
-->
<p>由 <a href="/zh/docs/reference/setup-tools/kubeadm/">kubeadm</a> 生成的客户端证书在 1 年后到期。
本页说明如何使用 kubeadm 管理证书续订。</p>
<h2 id="before-you-begin">Before you begin</h2>
<!--
You should be familiar with [PKI certificates and requirements in Kubernetes](/docs/setup/best-practices/certificates/).
-->
<p>你应该熟悉 <a href="/zh/docs/setup/best-practices/certificates/">Kubernetes 中的 PKI 证书和要求</a>。</p>
<!-- steps -->
<!--
## Using custom certificates {#custom-certificates}

By default, kubeadm generates all the certificates needed for a cluster to run.
You can override this behavior by providing your own certificates.
-->
<h2 id="custom-certificates">使用自定义的证书</h2>
<p>默认情况下, kubeadm 会生成运行一个集群所需的全部证书。
你可以通过提供你自己的证书来改变这个行为策略。</p>
<!--
To do so, you must place them in whatever directory is specified by the
`--cert-dir` flag or the `CertificatesDir`field of kubeadm's `ClusterConfiguration` . By default this
is `/etc/kubernetes/pki`.
-->
<p>如果要这样做, 你必须将证书文件放置在通过 <code>--cert-dir</code> 命令行参数或者 kubeadm 配置中的
<code>CertificatesDir</code> 配置项指明的目录中。默认的值是 <code>/etc/kubernetes/pki</code>。</p>
<!--
If a given certificate and private key pair exists before running `kubeadm init`,
kubeadm does not overwrite them. This means you can, for example, copy an existing
CA into `/etc/kubernetes/pki/ca.crt` and `/etc/kubernetes/pki/ca.key`,
and kubeadm will use this CA for signing the rest of the certificates.
-->
<p>如果在运行 <code>kubeadm init</code> 之前存在给定的证书和私钥对，kubeadm 将不会重写它们。
例如，这意味着您可以将现有的 CA 复制到 <code>/etc/kubernetes/pki/ca.crt</code> 和
<code>/etc/kubernetes/pki/ca.key</code> 中，而 kubeadm 将使用此 CA 对其余证书进行签名。</p>
<!--
## External CA mode {#external-ca-mode}

It is also possible to provide only the `ca.crt` file and not the
`ca.key` file (this is only available for the root CA file, not other cert pairs).
If all other certificates and kubeconfig files are in place, kubeadm recognizes
this condition and activates the "External CA" mode. kubeadm will proceed without the CA key on disk.
-->
<h2 id="external-ca-mode">外部 CA 模式</h2>
<p>只提供了 <code>ca.crt</code> 文件但是不提供 <code>ca.key</code> 文件也是可以的
（这只对 CA 根证书可用，其它证书不可用）。
如果所有的其它证书和 kubeconfig 文件已就绪，kubeadm 检测到满足以上条件就会激活
&quot;外部 CA&quot; 模式。kubeadm 将会在没有 CA 密钥文件的情况下继续执行。</p>
<!--
Instead, run the controller-manager standalone with `--controllers=csrsigner` and
point to the CA certificate and key.
-->
<p>否则, kubeadm 将独立运行 controller-manager，附加一个
<code>--controllers=csrsigner</code> 的参数，并且指明 CA 证书和密钥。</p>
<!--
[PKI certificates and requirements](/docs/setup/best-practices/certificates/) includes guidance on
setting up a cluster to use an external CA.
-->
<p><a href="/zh/docs/setup/best-practices/certificates/">PKI 证书和要求</a>包括集群使用外部 CA 的设置指南。</p>
<!-- 
## Check certificate expiration 

You can use the `check-expiration` subcommand to check when certificates expire:
-->
<h2 id="检查证书是否过期">检查证书是否过期</h2>
<p>你可以使用 <code>check-expiration</code> 子命令来检查证书何时过期</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubeadm certs check-expiration
</code></pre></div><!-- 
The output is similar to this: 
-->
<p>输出类似于以下内容：</p>
<pre><code>CERTIFICATE                EXPIRES                  RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED
admin.conf                 Dec 30, 2020 23:36 UTC   364d                                    no
apiserver                  Dec 30, 2020 23:36 UTC   364d            ca                      no
apiserver-etcd-client      Dec 30, 2020 23:36 UTC   364d            etcd-ca                 no
apiserver-kubelet-client   Dec 30, 2020 23:36 UTC   364d            ca                      no
controller-manager.conf    Dec 30, 2020 23:36 UTC   364d                                    no
etcd-healthcheck-client    Dec 30, 2020 23:36 UTC   364d            etcd-ca                 no
etcd-peer                  Dec 30, 2020 23:36 UTC   364d            etcd-ca                 no
etcd-server                Dec 30, 2020 23:36 UTC   364d            etcd-ca                 no
front-proxy-client         Dec 30, 2020 23:36 UTC   364d            front-proxy-ca          no
scheduler.conf             Dec 30, 2020 23:36 UTC   364d                                    no

CERTIFICATE AUTHORITY   EXPIRES                  RESIDUAL TIME   EXTERNALLY MANAGED
ca                      Dec 28, 2029 23:36 UTC   9y              no
etcd-ca                 Dec 28, 2029 23:36 UTC   9y              no
front-proxy-ca          Dec 28, 2029 23:36 UTC   9y              no
</code></pre><!-- 
The command shows expiration/residual time for the client certificates in the `/etc/kubernetes/pki` folder and for the client certificate embedded in the KUBECONFIG files used by kubeadm (`admin.conf`, `controller-manager.conf` and `scheduler.conf`). 
-->
<p>该命令显示 <code>/etc/kubernetes/pki</code> 文件夹中的客户端证书以及
kubeadm（<code>admin.conf</code>, <code>controller-manager.conf</code> 和 <code>scheduler.conf</code>）
使用的 KUBECONFIG 文件中嵌入的客户端证书的到期时间/剩余时间。</p>
<!-- 
Additionally, kubeadm informs the user if the certificate is externally managed; in this case, the user should take care of managing certificate renewal manually/using other tools. 
-->
<p>另外， kubeadm 会通知用户证书是否由外部管理；
在这种情况下，用户应该小心的手动/使用其他工具来管理证书更新。</p>
<!--
`kubeadm` cannot manage certificates signed by an external CA.
 -->
<div class="alert alert-danger warning callout" role="alert">
  <strong>Warning:</strong> <code>kubeadm</code> 不能管理由外部 CA 签名的证书
</div>


<!-- 
`kubelet.conf` is not included in the list above because kubeadm configures kubelet
for [automatic certificate renewal](/docs/tasks/tls/certificate-rotation/)
with rotatable certificates under `/var/lib/kubelet/pki`.
To repair an expired kubelet client certificate see
[Kubelet client certificate rotation fails](/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/#kubelet-client-cert).
-->
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> 上面的列表中没有包含 <code>kubelet.conf</code>，因为 kubeadm 将 kubelet 配置为
<a href="/docs/tasks/tls/certificate-rotation/">自动更新证书</a>。
轮换的证书位于目录 <code>/var/lib/kubelet/pki</code>。
要修复过期的 kubelet 客户端证书，请参阅
<a href="/zh/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/#kubelet-client-cert">kubelet 客户端证书轮换失败</a>。
</div>
<!--
On nodes created with `kubeadm init`, prior to kubeadm version 1.17, there is a
[bug](https://github.com/kubernetes/kubeadm/issues/1753) where you manually have to modify the contents of `kubelet.conf`. After `kubeadm init` finishes, you should update `kubelet.conf` to point to the
rotated kubelet client certificates, by replacing `client-certificate-data` and `client-key-data` with:
-->
<div class="alert alert-danger warning callout" role="alert">
  <strong>Warning:</strong> <p>在通过 <code>kubeadm init</code> 创建的节点上，在 kubeadm 1.17 版本之前有一个
<a href="https://github.com/kubernetes/kubeadm/issues/1753">缺陷</a>，该缺陷
使得你必须手动修改 <code>kubelet.conf</code> 文件的内容。
<code>kubeadm init</code> 操作结束之后，你必须更新 <code>kubelet.conf</code> 文件
将 <code>client-certificate-data</code> 和 <code>client-key-data</code> 改为如下所示的内容
以便使用轮换后的 kubelet 客户端证书：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">client-certificate</span>:<span style="color:#bbb"> </span>/var/lib/kubelet/pki/kubelet-client-current.pem<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">client-key</span>:<span style="color:#bbb"> </span>/var/lib/kubelet/pki/kubelet-client-current.pem<span style="color:#bbb">
</span></code></pre></div>
</div>


<!-- 
## Automatic certificate renewal

`kubeadm` renews all the certificates during control plane [upgrade](/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade-1-15/). 
-->
<h2 id="自动更新证书">自动更新证书</h2>
<p><code>kubeadm</code> 会在控制面
<a href="/zh/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/">升级</a>
的时候更新所有证书。</p>
<!-- 
This feature is designed for addressing the simplest use cases; 
if you don't have specific requirements on certificate renewal and perform Kubernetes version upgrades regularly (less than 1 year in between each upgrade), kubeadm will take care of keeping your cluster up to date and reasonably secure. 
-->
<p>这个功能旨在解决最简单的用例；如果你对此类证书的更新没有特殊要求，
并且定期执行 Kubernetes 版本升级（每次升级之间的间隔时间少于 1 年），
则 kubeadm 将确保你的集群保持最新状态并保持合理的安全性。</p>
<!-- 
It is a best practice to upgrade your cluster frequently in order to stay secure.
-->
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> 最佳的做法是经常升级集群以确保安全。
</div>
<!-- 
If you have more complex requirements for certificate renewal, you can opt out from the default behavior by passing `--certificate-renewal=false` to `kubeadm upgrade apply` or to `kubeadm upgrade node`. 
-->
<p>如果你对证书更新有更复杂的需求，则可通过将 <code>--certificate-renewal=false</code> 传递给
<code>kubeadm upgrade apply</code> 或者 <code>kubeadm upgrade node</code>，从而选择不采用默认行为。</p>
<!--
Prior to kubeadm version 1.17 there is a [bug](https://github.com/kubernetes/kubeadm/issues/1818)
where the default value for `--certificate-renewal` is `false` for the `kubeadm upgrade node`
command. In that case, you should explicitly set `--certificate-renewal=true`.
-->
<div class="alert alert-danger warning callout" role="alert">
  <strong>Warning:</strong> kubeadm 在 1.17 版本之前有一个<a href="https://github.com/kubernetes/kubeadm/issues/1818">缺陷</a>，
该缺陷导致 <code>kubeadm update node</code> 执行时 <code>--certificate-renewal</code> 的默认值被设置为 <code>false</code>。
在这种情况下，你需要显式地设置 <code>--certificate-renewal=true</code>。
</div>


<!-- 
## Manual certificate renewal 

You can renew your certificates manually at any time with the `kubeadm certs renew` command. 
-->
<h2 id="手动更新证书">手动更新证书</h2>
<p>你能随时通过 <code>kubeadm certs renew</code> 命令手动更新你的证书。</p>
<!-- 
This command performs the renewal using CA (or front-proxy-CA) certificate and key stored in `/etc/kubernetes/pki`.

After running the command you should restart the control plane Pods. This is required since
dynamic certificate reload is currently not supported for all components and certificates.
[Static Pods](/docs/tasks/configure-pod-container/static-pod/) are managed by the local kubelet
and not by the API Server, thus kubectl cannot be used to delete and restart them.
To restart a static Pod you can temporarily remove its manifest file from `/etc/kubernetes/manifests/`
and wait for 20 seconds (see the `fileCheckFrequency` value in [KubeletConfiguration struct](/docs/reference/config-api/kubelet-config.v1beta1/).
The kubelet will terminate the Pod if it's no longer in the manifest directory.
You can then move the file back and after another `fileCheckFrequency` period, the kubelet will recreate
the Pod and the certificate renewal for the component can complete.
-->
<p>此命令用 CA （或者 front-proxy-CA ）证书和存储在 <code>/etc/kubernetes/pki</code> 中的密钥执行更新。</p>
<p>执行完此命令之后你需要重启控制面 Pods。因为动态证书重载目前还不被所有组件和证书支持，所有这项操作是必须的。
<a href="/zh/docs/tasks/configure-pod-container/static-pod/">静态 Pods</a> 是被本地 kubelet 而不是 API Server 管理，
所以 kubectl 不能用来删除或重启他们。
要重启静态 Pod 你可以临时将清单文件从 <code>/etc/kubernetes/manifests/</code> 移除并等待 20 秒
（参考 <a href="/docs/reference/config-api/kubelet-config.v1beta1/">KubeletConfiguration 结构</a> 中的<code>fileCheckFrequency</code> 值）。
如果 Pod 不在清单目录里，kubelet将会终止它。
在另一个 <code>fileCheckFrequency</code> 周期之后你可以将文件移回去，为了组件可以完成 kubelet 将重新创建 Pod 和证书更新。</p>
<!-- 
If you are running an HA cluster, this command needs to be executed on all the control-plane nodes. 
-->
<div class="alert alert-danger warning callout" role="alert">
  <strong>Warning:</strong> 如果你运行了一个 HA 集群，这个命令需要在所有控制面板节点上执行。
</div>


<!-- 
` certs renew` uses the existing certificates as the authoritative source for attributes (Common Name, Organization, SAN, etc.) instead of the kubeadm-config ConfigMap. It is strongly recommended to keep them both in sync.
-->
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> <code>certs renew</code> 使用现有的证书作为属性 (Common Name、Organization、SAN 等) 的权威来源，
而不是 kubeadm-config ConfigMap 。强烈建议使它们保持同步。
</div>
<!--
`kubeadm certs renew` provides the following options:
-->
<p><code>kubeadm certs renew</code>提供以下选项：</p>
<!--
The Kubernetes certificates normally reach their expiration date after one year.
-->
<p>Kubernetes 证书通常在一年后到期。</p>
<!-- 

- `--csr-only` can be used to renew certificats with an external CA by generating certificate signing requests (without actually renewing certificates in place); see next paragraph for more information. 
- It's also possible to renew a single certificate instead of all.
 -->
<ul>
<li><code>--csr-only</code> 可用于经过一个外部 CA 生成的证书签名请求来更新证书（无需实际替换更新证书）；
更多信息请参见下节。</li>
<li>可以更新单个证书而不是全部证书。</li>
</ul>
<!--
## Renew certificates with the Kubernetes certificates API

This section provide more details about how to execute manual certificate renewal using the Kubernetes certificates API.
-->
<h2 id="用-kubernetes-证书-api-更新证书">用 Kubernetes 证书 API 更新证书</h2>
<p>本节提供有关如何使用 Kubernetes 证书 API 执行手动证书更新的更多详细信息。</p>
<!-- 
These are advanced topics for users who need to integrate their organization's certificate infrastructure into a kubeadm-built cluster. If the default kubeadm configuration satisfies your needs, you should let kubeadm manage certificates instead. 
-->
<div class="alert alert-warning caution callout" role="alert">
  <strong>Caution:</strong> 这些是针对需要将其组织的证书基础结构集成到 kubeadm 构建的集群中的用户的高级主题。
如果默认的 kubeadm 配置满足了你的需求，则应让 kubeadm 管理证书。
</div>

<!--
### Set up a signer

The Kubernetes Certificate Authority does not work out of the box.
You can configure an external signer such as [cert-manager](https://cert-manager.io/docs/configuration/ca/), or you can use the build-in signer.
The built-in signer is part of [`kube-controller-manager`](/docs/reference/command-line-tools-reference/kube-controller-manager/).
To activate the build-in signer, you must pass the `--cluster-signing-cert-file` and `--cluster-signing-key-file` flags.
-->
<h3 id="设置一个签名者-signer">设置一个签名者（Signer）</h3>
<p>Kubernetes 证书颁发机构不是开箱即用。
你可以配置外部签名者，例如
<a href="https://cert-manager.io/docs/configuration/ca/">cert-manager</a>，
也可以使用内置签名者。
内置签名者是
<a href="/zh/docs/reference/command-line-tools-reference/kube-controller-manager/"><code>kube-controller-manager</code></a>
的一部分。
要激活内置签名者，请传递 <code>--cluster-signing-cert-file</code> 和 <code>--cluster-signing-key-file</code> 参数。</p>
<!--
If you're creating a new cluster, you can use a kubeadm [configuration file](https://godoc.org/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta3): 
-->
<p>如果你正在创建一个新的集群，你可以使用 kubeadm 的
<a href="/docs/reference/config-api/kubeadm-config.v1beta3/">配置文件</a>。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>kubeadm.k8s.io/v1beta3<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>ClusterConfiguration<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">controllerManager</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">extraArgs</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">cluster-signing-cert-file</span>:<span style="color:#bbb"> </span>/etc/kubernetes/pki/ca.crt<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">cluster-signing-key-file</span>:<span style="color:#bbb"> </span>/etc/kubernetes/pki/ca.key<span style="color:#bbb">
</span></code></pre></div><!-- 
### Create certificate signing requests (CSR)
-->
<h3 id="创建证书签名请求-csr">创建证书签名请求 (CSR)</h3>
<!--
See [Create CertificateSigningRequest](/docs/reference/access-authn-authz/certificate-signing-requests/#create-certificatesigningrequest) for creating CSRs with the Kubernetes API.
-->
<p>有关使用 Kubernetes API 创建 CSR 的信息，
请参见<a href="/zh/docs/reference/access-authn-authz/certificate-signing-requests/#create-certificatesigningrequest">创建 CertificateSigningRequest</a>。</p>
<!--
## Renew certificates with external CA

This section provides more details about how to execute manual certificate renewal using an external CA.
-->
<h2 id="通过外部-ca-更新证书">通过外部 CA 更新证书</h2>
<p>本节提供有关如何使用外部 CA 执行手动更新证书的更多详细信息。</p>
<!--
To better integrate with external CAs, kubeadm can also produce certificate signing requests (CSRs).
A CSR represents a request to a CA for a signed certificate for a client.
In kubeadm terms, any certificate that would normally be signed by an on-disk CA can be produced as a CSR instead. A CA, however, cannot be produced as a CSR.
-->
<p>为了更好的与外部 CA 集成，kubeadm 还可以生成证书签名请求（CSR）。
CSR 表示向 CA 请求客户的签名证书。
在 kubeadm 术语中，通常由磁盘 CA 签名的任何证书都可以作为 CSR 生成。但是，CA 不能作为 CSR 生成。</p>
<!-- 
### Create certificate signing requests (CSR) 

You can create certificate signing requests with `kubeadm certs renew --csr-only`.

Both the CSR and the accompanying private key are given in the output.
You can pass in a directory with `--csr-dir` to output the CSRs to the specified location.
If `--csr-dir` is not specified, the default certificate directory (`/etc/kubernetes/pki`) is used.
-->
<h3 id="创建证书签名请求-csr-1">创建证书签名请求 (CSR)</h3>
<p>你可以通过 <code>kubeadm certs renew --csr-only</code> 命令创建证书签名请求。</p>
<p>CSR 和随附的私钥都在输出中给出。
你可以传入一个带有 <code>--csr-dir</code> 的目录，将 CRS 输出到指定位置。
如果未指定 <code>--csr-dir</code> ，则使用默认证书目录（<code>/etc/kubernetes/pki</code>）。</p>
<!--
Certificates can be renewed with `kubeadm certs renew --csr-only`.
As with `kubeadm init`, an output directory can be specified with the `--csr-dir` flag.
-->
<p>证书可以通过 <code>kubeadm certs renew --csr-only</code> 来续订。
和 <code>kubeadm init</code> 一样，可以使用 <code>--csr-dir</code> 标志指定一个输出目录。</p>
<p>CSR 签署证书后，必须将证书和私钥复制到 PKI 目录（默认情况下为 <code>/etc/kubernetes/pki</code>）。</p>
<!--
A CSR contains a certificate's name, domains, and IPs, but it does not specify usages.
It is the responsibility of the CA to specify [the correct cert usages](/docs/setup/best-practices/certificates/#all-certificates)
when issuing a certificate.
-->
<p>CSR 中包含一个证书的名字，域和 IP，但是未指定用法。
颁发证书时，CA 有责任指定<a href="/zh/docs/setup/best-practices/certificates/#all-certificates">正确的证书用法</a></p>
<!-- 
* In `openssl` this is done with the
  [`openssl ca` command](https://superuser.com/questions/738612/openssl-ca-keyusage-extension).
* In `cfssl` you specify
  [usages in the config file](https://github.com/cloudflare/cfssl/blob/master/doc/cmd/cfssl.txt#L170).
-->
<ul>
<li>在 <code>openssl</code> 中，这是通过
<a href="https://superuser.com/questions/738612/openssl-ca-keyusage-extension"><code>openssl ca</code> 命令</a>
来完成的。</li>
<li>在 <code>cfssl</code> 中，这是通过
<a href="https://github.com/cloudflare/cfssl/blob/master/doc/cmd/cfssl.txt#L170">在配置文件中指定用法</a>
来完成的。</li>
</ul>
<!-- 
After a certificate is signed using your preferred method, the certificate and the private key must be copied to the PKI directory (by default `/etc/kubernetes/pki`). 
-->
<p>使用首选方法对证书签名后，必须将证书和私钥复制到 PKI 目录（默认为 <code>/etc/kubernetes/pki</code> ）。</p>
<!--
## Certificate authority (CA) rotation {#certificate-authority-rotation}

Kubeadm does not support rotation or replacement of CA certificates out of the box.

For more information about manual rotation or replacement of CA, see [manual rotation of CA certificates](/docs/tasks/tls/manual-rotation-of-ca-certificates/).
-->
<h2 id="certificate-authority-rotation">证书机构（CA）轮换    </h2>
<p>kubeadm 并不直接支持对 CA 证书的轮换或者替换。</p>
<p>关于手动轮换或者置换 CA 的更多信息，可参阅
<a href="/zh/docs/tasks/tls/manual-rotation-of-ca-certificates/">手动轮换 CA 证书</a>。</p>
<!--
## Enabling signed kubelet serving certificates {#kubelet-serving-certs}

By default the kubelet serving certificate deployed by kubeadm is self-signed.
This means a connection from external services like the
[metrics-server](https://github.com/kubernetes-sigs/metrics-server) to a
kubelet cannot be secured with TLS.

To configure the kubelets in a new kubeadm cluster to obtain properly signed serving
certificates you must pass the following minimal configuration to `kubeadm init`:
-->
<h2 id="kubelet-serving-certs">启用已签名的 kubelet 服务证书  </h2>
<p>默认情况下，kubeadm 所部署的 kubelet 服务证书是自签名（Self-Signed））。
这意味着从 <a href="https://github.com/kubernetes-sigs/metrics-server">metrics-server</a>
这类外部服务发起向 kubelet 的链接时无法使用 TLS 来完成保护。</p>
<p>要在新的 kubeadm 集群中配置 kubelet 以使用被正确签名的服务证书，
你必须向 <code>kubeadm init</code> 传递如下最小配置数据：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>kubeadm.k8s.io/v1beta3<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>ClusterConfiguration<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#00f;font-weight:bold">---</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>kubelet.config.k8s.io/v1beta1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>KubeletConfiguration<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">serverTLSBootstrap</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:bold">true</span><span style="color:#bbb">
</span></code></pre></div><!--
If you have already created the cluster you must adapt it by doing the following:
 - Find and edit the `kubelet-config-1.23` ConfigMap in the `kube-system` namespace.
In that ConfigMap, the `kubelet` key has a
[KubeletConfiguration](/docs/reference/config-api/kubelet-config.v1beta1/#kubelet-config-k8s-io-v1beta1-KubeletConfiguration)
document as its value. Edit the KubeletConfiguration document to set `serverTLSBootstrap: true`.
- On each node, add the `serverTLSBootstrap: true` field in `/var/lib/kubelet/config.yaml`
and restart the kubelet with `systemctl restart kubelet`
-->
<p>如果你已经创建了集群，你必须通过执行下面的操作来完成适配：</p>
<ul>
<li>找到 <code>kube-system</code> 名字空间中名为 <code>kubelet-config-1.23</code>
的 ConfigMap 并编辑之。
在该 ConfigMap 中，<code>kubelet</code> 键下面有一个
<a href="/zh/docs/reference/config-api/kubelet-config.v1beta1/#kubelet-config-k8s-io-v1beta1-KubeletConfiguration">KubeletConfiguration</a>
文档作为其取值。编辑该 KubeletConfiguration 文档以设置
<code>serverTLSBootstrap: true</code>。</li>
<li>在每个节点上，在 <code>/var/lib/kubelet/config.yaml</code> 文件中添加
<code>serverTLSBootstrap: true</code> 字段，并使用 <code>systemctl restart kubelet</code>
来重启 kubelet。</li>
</ul>
<!--
The field `serverTLSBootstrap: true` will enable the bootstrap of kubelet serving
certificates by requesting them from the `certificates.k8s.io` API. One known limitation
is that the CSRs (Certificate Signing Requests) for these certificates cannot be automatically
approved by the default signer in the kube-controller-manager -
[`kubernetes.io/kubelet-serving`](/docs/reference/access-authn-authz/certificate-signing-requests/#kubernetes-signers).
This will require action from the user or a third party controller.

These CSRs can be viewed using:
-->
<p>字段 <code>serverTLSBootstrap</code> 将允许启动引导 kubelet 的服务证书，方式
是从 <code>certificates.k8s.io</code> API 处读取。这种方式的一种局限在于这些
证书的 CSR（证书签名请求）不能被 kube-controller-manager 中默认的
签名组件
<a href="/zh/docs/reference/access-authn-authz/certificate-signing-requests/#kubernetes-signers"><code>kubernetes.io/kubelet-serving</code></a>
批准。需要用户或者第三方控制器来执行此操作。</p>
<p>可以使用下面的命令来查看 CSR：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get csr
</code></pre></div><pre><code class="language-none" data-lang="none">NAME        AGE     SIGNERNAME                        REQUESTOR                      CONDITION
csr-9wvgt   112s    kubernetes.io/kubelet-serving     system:node:worker-1           Pending
csr-lz97v   1m58s   kubernetes.io/kubelet-serving     system:node:control-plane-1    Pending
</code></pre><!--
To approve them you can do the following:
-->
<p>你可以执行下面的操作来批准这些请求：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl certificate approve &lt;CSR-名称&gt;
</code></pre></div><!--
By default, these serving certificate will expire after one year. Kubeadm sets the
`KubeletConfiguration` field `rotateCertificates` to `true`, which means that close
to expiration a new set of CSRs for the serving certificates will be created and must
be approved to complete the rotation. To understand more see
[Certificate Rotation](/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/#certificate-rotation).
-->
<p>默认情况下，这些服务证书上会在一年后过期。
kubeadm 将 <code>KubeletConfiguration</code> 的 <code>rotateCertificates</code> 字段设置为
<code>true</code>；这意味着证书快要过期时，会生成一组针对服务证书的新的 CSR，而
这些 CSR 也要被批准才能完成证书轮换。
要进一步了解这里的细节，可参阅
<a href="/zh/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/#certificate-rotation">证书轮换</a>
文档。</p>
<!--
If you are looking for a solution for automatic approval of these CSRs it is recommended
that you contact your cloud provider and ask if they have a CSR signer that verifies
the node identity with an out of band mechanism.
-->
<p>如果你在寻找一种能够自动批准这些 CSR 的解决方案，建议你与你的云提供商
联系，询问他们是否有 CSR 签名组件，用来以带外（out-of-band）的方式检查
节点的标识符。</p>
<div class="alert alert-secondary callout third-party-content" role="alert"><strong>Note:</strong>
  This section links to third party projects that provide functionality required by Kubernetes. The Kubernetes project authors aren't responsible for these projects, which are listed alphabetically. To add a project to this list, read the <a href="/docs/contribute/style/content-guide/#third-party-content">content guide</a> before submitting a change. <a href="#third-party-content-disclaimer">More information.</a></div>
<!--
Third party custom controllers can be used:
- [kubelet-rubber-stamp](https://github.com/kontena/kubelet-rubber-stamp)

Such a controller is not a secure mechanism unless it not only verifies the CommonName
in the CSR but also verifies the requested IPs and domain names. This would prevent
a malicious actor that has access to a kubelet client certificate to create
CSRs requesting serving certificates for any IP or domain name.
-->
<p>也可以使用第三方定制的控制器：</p>
<ul>
<li><a href="https://github.com/kontena/kubelet-rubber-stamp">kubelet-rubber-stamp</a></li>
</ul>
<p>除非既能够验证 CSR 中的 CommonName，也能检查请求的 IP 和域名，
这类控制器还算不得安全的机制。
只有完成彻底的检查，才有可能避免有恶意的、能够访问 kubelet 客户端证书的第三方
为任何 IP 或域名请求服务证书。</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-6134c5061298affa145ddb801b5c29da">2 - 配置 cgroup 驱动</h1>
    
	<!-- 
---
title: Configuring a cgroup driver
content_type: task
weight: 10
---
-->
<!-- overview -->
<!-- 
This page explains how to configure the kubelet cgroup driver to match the container
runtime cgroup driver for kubeadm clusters.
-->
<p>本页阐述如何配置 kubelet 的 cgroup 驱动以匹配 kubeadm 集群中的容器运行时的 cgroup 驱动。</p>
<h2 id="before-you-begin">Before you begin</h2>
<!-- 
You should be familiar with the Kubernetes
[container runtime requirements](/docs/setup/production-environment/container-runtimes).
-->
<p>你应该熟悉 Kubernetes 的<a href="/zh/docs/setup/production-environment/container-runtimes">容器运行时需求</a>。</p>
<!-- steps -->
<!-- 
## Configuring the container runtime cgroup driver
-->
<h2 id="configuring-the-container-runtime-cgroup-driver">配置容器运行时 cgroup 驱动</h2>
<!-- 
The [Container runtimes](/docs/setup/production-environment/container-runtimes) page
explains that the `systemd` driver is recommended for kubeadm based setups instead
of the `cgroupfs` driver, because kubeadm manages the kubelet as a systemd service.
-->
<p><a href="/zh/docs/setup/production-environment/container-runtimes">容器运行时</a>页面提到：
由于 kubeadm 把 kubelet 视为一个系统服务来管理，所以对基于 kubeadm 的安装，
我们推荐使用 <code>systemd</code> 驱动，不推荐 <code>cgroupfs</code> 驱动。</p>
<!-- 
The page also provides details on how to setup a number of different container runtimes with the
`systemd` driver by default.
-->
<p>此页还详述了如何安装若干不同的容器运行时，并将 <code>systemd</code> 设为其默认驱动。</p>
<!-- 
## Configuring the kubelet cgroup driver
-->
<h2 id="配置-kubelet-的-cgroup-驱动">配置 kubelet 的 cgroup 驱动</h2>
<!-- 
kubeadm allows you to pass a `KubeletConfiguration` structure during `kubeadm init`.
This `KubeletConfiguration` can include the `cgroupDriver` field which controls the cgroup
driver of the kubelet.
-->
<p>kubeadm 支持在执行 <code>kubeadm init</code> 时，传递一个 <code>KubeletConfiguration</code> 结构体。
<code>KubeletConfiguration</code> 包含 <code>cgroupDriver</code> 字段，可用于控制 kubelet 的 cgroup 驱动。</p>
<!-- 
In v1.22, if the user is not setting the `cgroupDriver` field under `KubeletConfiguration`,
`kubeadm init` will default it to `systemd`.
-->
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> 在版本 1.22 中，如果用户没有在 <code>KubeletConfiguration</code> 中设置 <code>cgroupDriver</code> 字段，
<code>kubeadm init</code> 会将它设置为默认值 <code>systemd</code>。
</div>
<!-- 
A minimal example of configuring the field explicitly:
-->
<p>这是一个最小化的示例，其中显式的配置了此字段：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#080;font-style:italic"># kubeadm-config.yaml</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>ClusterConfiguration<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>kubeadm.k8s.io/v1beta3<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kubernetesVersion</span>:<span style="color:#bbb"> </span>v1.21.0<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#00f;font-weight:bold">---</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>KubeletConfiguration<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>kubelet.config.k8s.io/v1beta1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">cgroupDriver</span>:<span style="color:#bbb"> </span>systemd<span style="color:#bbb">
</span></code></pre></div><!-- 
Such a configuration file can then be passed to the kubeadm command:
-->
<p>这样一个配置文件就可以传递给 kubeadm 命令了：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubeadm init --config kubeadm-config.yaml
</code></pre></div><!-- 
Kubeadm uses the same `KubeletConfiguration` for all nodes in the cluster.
The `KubeletConfiguration` is stored in a [ConfigMap](/docs/concepts/configuration/configmap)
object under the `kube-system` namespace.

Executing the sub commands `init`, `join` and `upgrade` would result in kubeadm
writing the `KubeletConfiguration` as a file under `/var/lib/kubelet/config.yaml`
and passing it to the local node kubelet.
-->
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> <p>Kubeadm 对集群所有的节点，使用相同的 <code>KubeletConfiguration</code>。
<code>KubeletConfiguration</code> 存放于 <code>kube-system</code> 命名空间下的某个
<a href="/zh/docs/concepts/configuration/configmap">ConfigMap</a> 对象中。</p>
<p>执行 <code>init</code>、<code>join</code> 和 <code>upgrade</code> 等子命令会促使 kubeadm
将 <code>KubeletConfiguration</code> 写入到文件 <code>/var/lib/kubelet/config.yaml</code> 中，
继而把它传递给本地节点的 kubelet。</p>

</div>
<!-- 
## Using the `cgroupfs` driver
-->
<h1 id="使用-cgroupfs-驱动">使用 <code>cgroupfs</code> 驱动</h1>
<!-- 
As this guide explains using the `cgroupfs` driver with kubeadm is not recommended.

To continue using `cgroupfs` and to prevent `kubeadm upgrade` from modifying the
`KubeletConfiguration` cgroup driver on existing setups, you must be explicit
about its value. This applies to a case where you do not wish future versions
of kubeadm to apply the `systemd` driver by default.
-->
<p>正如本指南阐述的：不推荐与 kubeadm 一起使用 <code>cgroupfs</code> 驱动。</p>
<p>如仍需使用 <code>cgroupfs</code>，
且要防止 <code>kubeadm upgrade</code> 修改现有系统中 <code>KubeletConfiguration</code> 的 cgroup 驱动，
你必须显式声明它的值。
此方法应对的场景为：在将来某个版本的 kubeadm 中，你不想使用默认的 <code>systemd</code> 驱动。</p>
<!-- 
See the below section on "Modify the kubelet ConfigMap" for details on
how to be explicit about the value.

If you wish to configure a container runtime to use the `cgroupfs` driver,
you must refer to the documentation of the container runtime of your choice.
-->
<p>参阅以下章节“修改 kubelet 的 ConfigMap”，了解显式设置该值的方法。</p>
<p>如果你希望配置容器运行时来使用 <code>cgroupfs</code> 驱动，
则必须参考所选容器运行时的文档。</p>
<!-- 
## Migrating to the `systemd` driver
-->
<h2 id="迁移到-systemd-驱动">迁移到 <code>systemd</code> 驱动</h2>
<!-- 
To change the cgroup driver of an existing kubeadm cluster to `systemd` in-place,
a similar procedure to a kubelet upgrade is required. This must include both
steps outlined below.
-->
<p>要将现有 kubeadm 集群的 cgroup 驱动就地升级为 <code>systemd</code>，
需要执行一个与 kubelet 升级类似的过程。
该过程必须包含下面两个步骤：</p>
<!-- 
Alternatively, it is possible to replace the old nodes in the cluster with new ones
that use the `systemd` driver. This requires executing only the first step below
before joining the new nodes and ensuring the workloads can safely move to the new
nodes before deleting the old nodes.
-->
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> 还有一种方法，可以用已配置了 <code>systemd</code> 的新节点替换掉集群中的老节点。
按这种方法，在加入新节点、确保工作负载可以安全迁移到新节点、及至删除旧节点这一系列操作之前，
只需执行以下第一个步骤。
</div>
<!-- 
### Modify the kubelet ConfigMap
-->
<h3 id="修改-kubelet-的-configmap">修改 kubelet 的 ConfigMap</h3>
<!-- 
- Find the kubelet ConfigMap name using `kubectl get cm -n kube-system | grep kubelet-config`.
- Call `kubectl edit cm kubelet-config-x.yy -n kube-system` (replace `x.yy` with
the Kubernetes version).
- Either modify the existing `cgroupDriver` value or add a new field that looks like this:
-->
<ul>
<li>
<p>用命令 <code>kubectl get cm -n kube-system | grep kubelet-config</code> 找到 kubelet 的 ConfigMap 名称。</p>
</li>
<li>
<p>运行 <code>kubectl edit cm kubelet-config-x.yy -n kube-system</code> （把 <code>x.yy</code> 替换为 Kubernetes 版本）。</p>
</li>
<li>
<p>修改现有 <code>cgroupDriver</code> 的值，或者新增如下式样的字段：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">cgroupDriver</span>:<span style="color:#bbb"> </span>systemd<span style="color:#bbb">
</span></code></pre></div><!-- 
This field must be present under the `kubelet:` section of the ConfigMap.
-->
<p>该字段必须出现在 ConfigMap 的 <code>kubelet:</code> 小节下。</p>
</li>
</ul>
<!-- 
### Update the cgroup driver on all nodes
-->
<h3 id="更新所有节点的-cgroup-驱动">更新所有节点的 cgroup 驱动</h3>
<!-- 
For each node in the cluster:

- [Drain the node](/docs/tasks/administer-cluster/safely-drain-node) using `kubectl drain <node-name> --ignore-daemonsets`
- Stop the kubelet using `systemctl stop kubelet`
- Stop the container runtime
- Modify the container runtime cgroup driver to `systemd`
- Set `cgroupDriver: systemd` in `/var/lib/kubelet/config.yaml`
- Start the container runtime
- Start the kubelet using `systemctl start kubelet`
- [Uncordon the node](/docs/tasks/administer-cluster/safely-drain-node) using `kubectl uncordon <node-name>`
-->
<p>对于集群中的每一个节点：</p>
<ul>
<li>执行命令 <code>kubectl drain &lt;node-name&gt; --ignore-daemonsets</code>，以
<a href="/zh/docs/tasks/administer-cluster/safely-drain-node">腾空节点</a></li>
<li>执行命令 <code>systemctl stop kubelet</code>，以停止 kubelet</li>
<li>停止容器运行时</li>
<li>修改容器运行时 cgroup 驱动为 <code>systemd</code></li>
<li>在文件 <code>/var/lib/kubelet/config.yaml</code> 中添加设置 <code>cgroupDriver: systemd</code></li>
<li>启动容器运行时</li>
<li>执行命令 <code>systemctl start kubelet</code>，以启动 kubelet</li>
<li>执行命令 <code>kubectl uncordon &lt;node-name&gt;</code>，以
<a href="/zh/docs/tasks/administer-cluster/safely-drain-node">取消节点隔离</a></li>
</ul>
<!-- 
Execute these steps on nodes one at a time to ensure workloads
have sufficient time to schedule on different nodes.

Once the process is complete ensure that all nodes and workloads are healthy.
-->
<p>在节点上依次执行上述步骤，确保工作负载有充足的时间被调度到其他节点。</p>
<p>流程完成后，确认所有节点和工作负载均健康如常。</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-98530eb3653d28fef34bff4543364aa7">3 - 重新配置 kubeadm 集群</h1>
    
	<!--
reviewers:
- sig-cluster-lifecycle
title: Reconfiguring a kubeadm cluster
content_type: task
weight: 10
-->
<!-- overview -->
<!--
kubeadm does not support automated ways of reconfiguring components that
were deployed on managed nodes. One way of automating this would be
by using a custom [operator](/docs/concepts/extend-kubernetes/operator/).
-->
<p>kubeadm 不支持自动重新配置部署在托管节点上的组件的方式。
一种自动化的方法是使用自定义的
<a href="/zh/docs/concepts/extend-kubernetes/operator/">operator</a>。</p>
<!--
To modify the components configuration you must manually edit associated cluster
objects and files on disk.

This guide shows the correct sequence of steps that need to be performed
to achieve kubeadm cluster reconfiguration.
-->
<p>要修改组件配置，你必须手动编辑磁盘上关联的集群对象和文件。
本指南展示了实现 kubeadm 集群重新配置所需执行的正确步骤顺序。</p>
<h2 id="before-you-begin">Before you begin</h2>
<!--
- You need a cluster that was deployed using kubeadm
- Have administrator credentials (`/etc/kubernetes/admin.conf`) and network connectivity
to a running kube-apiserver in the cluster from a host that has kubectl installed
- Have a text editor installed on all hosts
-->
<ul>
<li>你需要一个使用 kubeadm 部署的集群</li>
<li>拥有管理员凭据（<code>/etc/kubernetes/admin.conf</code>）
和从安装了 kubectl 的主机到集群中正在运行的 kube-apiserver 的网络连接</li>
<li>在所有主机上安装文本编辑器</li>
</ul>
<!-- steps -->
<!--
## Reconfiguring the cluster
kubeadm writes a set of cluster wide component configuration options in
ConfigMaps and other objects. These objects must be manually edited. The command `kubectl edit`
can be used for that.
-->
<h2 id="重新配置集群">重新配置集群</h2>
<p>kubeadm 在 ConfigMap 和其他对象中写入了一组集群范围的组件配置选项。
这些对象必须手动编辑，可以使用命令 <code>kubectl edit</code>。</p>
<!--
The `kubectl edit` command will open a text editor where you can edit and save the object directly.

You can use the environment variables `KUBECONFIG` and `KUBE_EDITOR` to specify the location of
the kubectl consumed kubeconfig file and preferred text editor.

For example:
-->
<p><code>kubectl edit</code> 命令将打开一个文本编辑器，你可以在其中直接编辑和保存对象。
你可以使用环境变量 <code>KUBECONFIG</code> 和 <code>KUBE_EDITOR</code> 来指定 kubectl
使用的 kubeconfig 文件和首选文本编辑器的位置。</p>
<p>例如：</p>
<pre><code>KUBECONFIG=/etc/kubernetes/admin.conf KUBE_EDITOR=nano kubectl edit &lt;parameters&gt;
</code></pre><div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> <!--
Upon saving any changes to these cluster objects, components running on nodes may not be
automatically updated. The steps below instruct you on how to perform that manually.
-->
<p>保存对这些集群对象的任何更改后，节点上运行的组件可能不会自动更新。
以下步骤将指导你如何手动执行该操作。
</div>
<div class="alert alert-danger warning callout" role="alert">
  <strong>Warning:</strong> <!--
Component configuration in ConfigMaps is stored as unstructured data (YAML string).
This means that validation will not be performed upon updating the contents of a ConfigMap.
You have to be careful to follow the documented API format for a particular
component configuration and avoid introducing typos and YAML indentation mistakes.
-->
<p>ConfigMaps 中的组件配置存储为非结构化数据（YAML 字符串）。 这意味着在更新
ConfigMap 的内容时不会执行验证。 你必须小心遵循特定组件配置的文档化 API 格式，
并避免引入拼写错误和 YAML 缩进错误。
</div>


<!--
### Applying cluster configuration changes

#### Updating the `ClusterConfiguration`

During cluster creation and upgrade, kubeadm writes its
[`ClusterConfiguration`](/docs/reference/config-api/kubeadm-config.v1beta3/)
in a ConfigMap called `kubeadm-config` in the `kube-system` namespace.

To change a particular option in the `ClusterConfiguration` you can edit the ConfigMap with this command:

The configuration is located under the `data.ClusterConfiguration` key.
-->
<h3 id="应用集群配置更改">应用集群配置更改</h3>
<h4 id="更新-clusterconfiguration">更新 <code>ClusterConfiguration</code></h4>
<p>在集群创建和升级期间，kubeadm 将其
<a href="/zh/docs/reference/config-api/kubeadm-config.v1beta3/"><code>ClusterConfiguration</code></a>
写入 <code>kube-system</code> 命名空间中名为 <code>kubeadm-config</code> 的 ConfigMap。</p>
<p>要更改 <code>ClusterConfiguration</code> 中的特定选项，你可以使用以下命令编辑 ConfigMap：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl edit cm -n kube-system kubeadm-config
</code></pre></div><p>配置位于 <code>data.ClusterConfiguration</code> 键下。</p>
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> <!--
The `ClusterConfiguration` includes a variety of options that affect the configuration of individual
components such as kube-apiserver, kube-scheduler, kube-controller-manager, CoreDNS, etcd and kube-proxy.
Changes to the configuration must be reflected on node components manually.
-->
<p><code>ClusterConfiguration</code> 包括各种影响单个组件配置的选项， 例如
kube-apiserver、kube-scheduler、kube-controller-manager、
CoreDNS、etcd 和 kube-proxy。 对配置的更改必须手动反映在节点组件上。
</div>
<!--
#### Reflecting `ClusterConfiguration` changes on control plane nodes

kubeadm manages the control plane components as static Pod manifests located in
the directory `/etc/kubernetes/manifests`.
Any changes to the `ClusterConfiguration` under the `apiServer`, `controllerManager`, `scheduler` or `etcd`
keys must be reflected in the associated files in the manifests directory on a control plane node.
-->
<h4 id="在控制平面节点上反映-clusterconfiguration-更改">在控制平面节点上反映 <code>ClusterConfiguration</code> 更改</h4>
<p>kubeadm 将控制平面组件作为位于 <code>/etc/kubernetes/manifests</code>
目录中的静态 Pod 清单进行管理。
对 <code>apiServer</code>、<code>controllerManager</code>、<code>scheduler</code> 或 <code>etcd</code>键下的
<code>ClusterConfiguration</code> 的任何更改都必须反映在控制平面节点上清单目录中的关联文件中。</p>
<!--
Such changes may include:
- `extraArgs` - requires updating the list of flags passed to a component container
- `extraMounts` - requires updated the volume mounts for a component container
- `*SANs` - requires writing new certificates with updated Subject Alternative Names.

Before proceeding with these changes, make sure you have backed up the directory `/etc/kubernetes/`.
-->
<p>此类更改可能包括:</p>
<ul>
<li><code>extraArgs</code> - 需要更新传递给组件容器的标志列表</li>
<li><code>extraMounts</code> - 需要更新组件容器的卷挂载</li>
<li><code>*SANs</code> - 需要使用更新的主题备用名称编写新证书</li>
</ul>
<p>在继续进行这些更改之前，请确保你已备份目录 <code>/etc/kubernetes/</code>。</p>
<!--
To write new certificates you can use:

To write new manifest files in `/etc/kubernetes/manifests` you can use:
-->
<p>要编写新证书，你可以使用：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubeadm init phase certs &lt;component-name&gt; --config &lt;config-file&gt;
</code></pre></div><p>要在 <code>/etc/kubernetes/manifests</code> 中编写新的清单文件，你可以使用：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubeadm init phase control-plane &lt;component-name&gt; --config &lt;config-file&gt;
</code></pre></div><!--
The `<config-file>` contents must match the updated `ClusterConfiguration`.
The `<component-name>` value must be the name of the component.
-->
<p><code>&lt;config-file&gt;</code> 内容必须与更新后的 <code>ClusterConfiguration</code> 匹配。
<code>&lt;component-name&gt;</code> 值必须是组件的名称。</p>
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> <!--
Updating a file in `/etc/kubernetes/manifests` will tell the kubelet to restart the static Pod for the corresponding component.
Try doing these changes one node at a time to leave the cluster without downtime.
-->
<p>更新 <code>/etc/kubernetes/manifests</code> 中的文件将告诉 kubelet 重新启动相应组件的静态 Pod。
尝试一次对一个节点进行这些更改，以在不停机的情况下离开集群。
</div>
<!--
### Applying kubelet configuration changes

#### Updating the `KubeletConfiguration`

During cluster creation and upgrade, kubeadm writes its
[`KubeletConfiguration`](/docs/reference/config-api/kubelet-config.v1beta1/)
in a ConfigMap called `kubelet-config` in the `kube-system` namespace.

You can edit the ConfigMap with this command:

The configuration is located under the `data.kubelet` key.
-->
<h3 id="应用-kubelet-配置更改">应用 kubelet 配置更改</h3>
<h4 id="更新-kubeletconfiguration">更新 <code>KubeletConfiguration</code></h4>
<p>在集群创建和升级期间，kubeadm 将其
<a href="/zh/docs/reference/config-api/kubelet-config.v1beta1/"><code>KubeletConfiguration</code></a>
写入 <code>kube-system</code> 命名空间中名为 <code>kubelet-config</code> 的 ConfigMap。
你可以使用以下命令编辑 ConfigMap：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl edit cm -n kube-system kubelet-config
</code></pre></div><p>配置位于 <code>data.kubelet</code> 键下。</p>
<!--
#### Reflecting the kubelet changes

To reflect the change on kubeadm nodes you must do the following:
- Log in to a kubeadm node
- Run `kubeadm upgrade node phase kubelet-config` to download the latest `kubelet-config`
ConfigMap contents into the local file `/var/lib/kubelet/config.conf`
- Edit the file `/var/lib/kubelet/kubeadm-flags.env` to apply additional configuration with
flags
- Restart the kubelet service with `systemctl restart kubelet`
-->
<h4 id="反映-kubelet-的更改">反映 kubelet 的更改</h4>
<p>要反映 kubeadm 节点上的更改，你必须执行以下操作：</p>
<ul>
<li>登录到 kubeadm 节点</li>
<li>运行 <code>kubeadm upgrade node phase kubelet-config</code> 下载最新的
<code>kubelet-config</code> ConfigMap 内容到本地文件 <code>/var/lib/kubelet/config.conf</code></li>
<li>编辑文件 <code>/var/lib/kubelet/kubeadm-flags.env</code> 以使用标志来应用额外的配置</li>
<li>使用 <code>systemctl restart kubelet</code> 重启 kubelet 服务</li>
</ul>
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> <!--
Do these changes one node at a time to allow workloads to be rescheduled properly.
-->
<p>一次执行一个节点的这些更改，以允许正确地重新安排工作负载。
</div>
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> <!--
During `kubeadm upgrade`, kubeadm downloads the `KubeletConfiguration` from the
`kubelet-config` ConfigMap and overwrite the contents of `/var/lib/kubelet/config.conf`.
This means that node local configuration must be applied either by flags in
`/var/lib/kubelet/kubeadm-flags.env` or by manually updating the contents of
`/var/lib/kubelet/config.conf` after `kubeadm upgrade`, and then restarting the kubelet.
-->
<p>在 <code>kubeadm upgrade</code> 期间，kubeadm 从 <code>kubelet-config</code> ConfigMap
下载 <code>KubeletConfiguration</code> 并覆盖 <code>/var/lib/kubelet/config.conf</code> 的内容。
这意味着节点本地配置必须通过<code>/var/lib/kubelet/kubeadm-flags.env</code>中的标志或在
kubeadm upgrade<code> 后手动更新</code>/var/lib/kubelet/config.conf`的内容来应用，然后重新启动 kubelet。
</div>
<!--
### Applying kube-proxy configuration changes

#### Updating the `KubeProxyConfiguration`

During cluster creation and upgrade, kubeadm writes its
[`KubeProxyConfiguration`](/docs/reference/config-api/kube-proxy-config.v1alpha1/)
in a ConfigMap in the `kube-system` namespace called `kube-proxy`.

This ConfigMap is used by the `kube-proxy` DaemonSet in the `kube-system` namespace.

To change a particular option in the `KubeProxyConfiguration`, you can edit the ConfigMap with this command:

The configuration is located under the `data.config.conf` key.
-->
<h3 id="应用-kube-proxy-配置更改">应用 kube-proxy 配置更改</h3>
<h4 id="更新-kubeproxyconfiguration">更新 <code>KubeProxyConfiguration</code></h4>
<p>在集群创建和升级期间，kubeadm 将其写入
<a href="/zh/docs/reference/config-api/kube-proxy-config.v1alpha1/"><code>KubeProxyConfiguration</code></a>
在名为 <code>kube-proxy</code> 的 <code>kube-system</code> 命名空间中的 ConfigMap 中。</p>
<p>此 ConfigMap 由 <code>kube-system</code> 命名空间中的 <code>kube-proxy</code> DaemonSet 使用。</p>
<p>要更改 <code>KubeProxyConfiguration</code> 中的特定选项，你可以使用以下命令编辑 ConfigMap：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl edit cm -n kube-system kube-proxy
</code></pre></div><p>配置位于 <code>data.config.conf</code> 键下。</p>
<!--
#### Reflecting the kube-proxy changes

Once the `kube-proxy` ConfigMap is updated, you can restart all kube-proxy Pods:

Obtain the Pod names:

Delete a Pod with:

New Pods that use the updated ConfigMap will be created.
-->
<h4 id="反映-kube-proxy-的更改">反映 kube-proxy 的更改</h4>
<p>更新 <code>kube-proxy</code> ConfigMap 后，你可以重新启动所有 kube-proxy Pod：</p>
<p>获取 Pod 名称：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get po -n kube-system | grep kube-proxy
</code></pre></div><p>使用以下命令删除 Pod：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl delete po -n kube-system &lt;pod-name&gt;
</code></pre></div><p>将创建使用更新的 ConfigMap 的新 Pod。</p>
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> <!--
Because kubeadm deploys kube-proxy as a DaemonSet, node specific configuration is unsupported.
-->
<p>由于 kubeadm 将 kube-proxy 部署为 DaemonSet，因此不支持特定于节点的配置。
</div>
<!--
### Applying CoreDNS configuration changes

#### Updating the CoreDNS Deployment and Service

kubeadm deploys CoreDNS as a Deployment called `coredns` and with a Service `kube-dns`,
both in the `kube-system` namespace.

To update any of the CoreDNS settings, you can edit the Deployment and
Service objects:
-->
<h3 id="应用-coredns-配置更改">应用 CoreDNS 配置更改</h3>
<h4 id="更新-coredns-的-deployment-和-service">更新 CoreDNS 的 Deployment 和 Service</h4>
<p>kubeadm 将 CoreDNS 部署为名为 <code>coredns</code> 的 Deployment，并使用 Service <code>kube-dns</code>，
两者都在 <code>kube-system</code> 命名空间中。</p>
<p>要更新任何 CoreDNS 设置，你可以编辑 Deployment 和 Service：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl edit deployment -n kube-system coredns
kubectl edit service -n kube-system kube-dns
</code></pre></div><!--
#### Reflecting the CoreDNS changes

Once the CoreDNS changes are applied you can delete the CoreDNS Pods:

Obtain the Pod names:

Delete a Pod with:
-->
<h4 id="反映-coredns-的更改">反映 CoreDNS 的更改</h4>
<p>应用 CoreDNS 更改后，你可以删除 CoreDNS Pod。</p>
<p>获取 Pod 名称：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get po -n kube-system | grep coredns
</code></pre></div><p>使用以下命令删除 Pod：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl delete po -n kube-system &lt;pod-name&gt;
</code></pre></div><!--
New Pods with the updated CoreDNS configuration will be created.
-->
<p>将创建具有更新的 CoreDNS 配置的新 Pod。</p>
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> <!--
kubeadm does not allow CoreDNS configuration during cluster creation and upgrade.
This means that if you execute `kubeadm upgrade apply`, your changes to the CoreDNS
-->
<p>kubeadm 不允许在集群创建和升级期间配置 CoreDNS。
这意味着如果执行了 <code>kubeadm upgrade apply</code>，你对
CoreDNS 对象的更改将丢失并且必须重新应用。
</div>
<!--
## Persisting the reconfiguration

During the execution of `kubeadm upgrade` on a managed node, kubeadm might overwrite configuration
that was applied after the cluster was created (reconfiguration).
-->
<h2 id="持久化重新配置">持久化重新配置</h2>
<p>在受管节点上执行 <code>kubeadm upgrade</code> 期间，kubeadm
可能会覆盖在创建集群（重新配置）后应用的配置。</p>
<!--
### Persisting Node object reconfiguration

kubeadm writes Labels, Taints, CRI socket and other information on the Node object for a particular
Kubernetes node. To change any of the contents of this Node object you can use:
-->
<h3 id="持久化-node-对象重新配置">持久化 Node 对象重新配置</h3>
<p>kubeadm 在特定 Kubernetes 节点的 Node 对象上写入标签、污点、CRI
套接字和其他信息。要更改此 Node 对象的任何内容，你可以使用：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl edit no &lt;node-name&gt;
</code></pre></div><!--
During `kubeadm upgrade` the contents of such a Node might get overwritten.
If you would like to persist your modifications to the Node object after upgrade,
you can prepare a [kubectl patch](/docs/tasks/manage-kubernetes-objects/update-api-object-kubectl-patch/)
and apply it to the Node object:
-->
<p>在 <code>kubeadm upgrade</code> 期间，此类节点的内容可能会被覆盖。
如果你想在升级后保留对 Node 对象的修改，你可以准备一个
<a href="/zh/docs/tasks/manage-kubernetes-objects/update-api-object-kubectl-patch/">kubectl patch</a>
并将其应用到 Node 对象：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl patch no &lt;node-name&gt; --patch-file &lt;patch-file&gt;
</code></pre></div><!--
#### Persisting control plane component reconfiguration

The main source of control plane configuration is the `ClusterConfiguration`
object stored in the cluster. To extend the static Pod manifests configuration,
[patches](/docs/setup/production-environment/tools/kubeadm/control-plane-flags/#patches) can be used.

These patch files must remain as files on the control plane nodes to ensure that
they can be used by the `kubeadm upgrade ... --patches <directory>`.

If reconfiguration is done to the `ClusterConfiguration` and static Pod manifests on disk,
the set of node specific patches must be updated accordingly.
-->
<h4 id="持久化控制平面组件重新配置">持久化控制平面组件重新配置</h4>
<p>控制平面配置的主要来源是存储在集群中的 <code>ClusterConfiguration</code> 对象。
要扩展静态 Pod 清单配置，可以使用
<a href="/zh/docs/setup/production-environment/tools/kubeadm/control-plane-flags/#patches">patches</a>。</p>
<p>这些补丁文件必须作为文件保留在控制平面节点上，以确保它们可以被
<code>kubeadm upgrade ... --patches &lt;directory&gt;</code> 使用。</p>
<p>如果对 <code>ClusterConfiguration</code> 和磁盘上的静态 Pod 清单进行了重新配置，则必须相应地更新节点特定补丁集。</p>
<!--
#### Persisting kubelet reconfiguration

Any changes to the `KubeletConfiguration` stored in `/var/lib/kubelet/config.conf` will be overwritten on
`kubeadm upgrade` by downloading the contents of the cluster wide `kubelet-config` ConfigMap.
To persist kubelet node specific configuration either the file `/var/lib/kubelet/config.conf`
has to be updated manually post-upgrade or the file `/var/lib/kubelet/kubeadm-flags.env` can include flags.
The kubelet flags override the associated `KubeletConfiguration` options, but note that
some of the flags are deprecated.

A kubelet restart will be required after changing `/var/lib/kubelet/config.conf` or
`/var/lib/kubelet/kubeadm-flags.env`.
-->
<h4 id="持久化-kubelet-重新配置">持久化 kubelet 重新配置</h4>
<p>对存储在 <code>/var/lib/kubelet/config.conf</code> 中的 <code>KubeletConfiguration</code>
所做的任何更改都将在 <code>kubeadm upgrade</code> 时因为下载集群范围内的 <code>kubelet-config</code>
ConfigMap 的内容而被覆盖。
要持久保存 kubelet 节点特定的配置，文件<code>/var/lib/kubelet/config.conf</code>
必须在升级后手动更新，或者文件<code>/var/lib/kubelet/kubeadm-flags.env</code> 可以包含标志。
kubelet 标志会覆盖相关的 <code>KubeletConfiguration</code> 选项，但请注意，有些标志已被弃用。</p>
<p>更改 <code>/var/lib/kubelet/config.conf</code> 或 <code>/var/lib/kubelet/kubeadm-flags.env</code>
后需要重启 kubelet。</p>
<p>What's next</p>
<!--
- [Upgrading kubeadm clusters](/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade)
- [Customizing components with the kubeadm API](/docs/setup/production-environment/tools/kubeadm/control-plane-flags)
- [Certificate management with kubeadm](/docs/tasks/administer-cluster/kubeadm/kubeadm-certs)
-->
<ul>
<li><a href="/zh/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade">升级 kubeadm 集群</a></li>
<li><a href="/zh/docs/setup/production-environment/tools/kubeadm/control-plane-flags">使用 kubeadm API 自定义组件</a></li>
<li><a href="/zh/docs/tasks/administer-cluster/kubeadm/kubeadm-certs">使用 kubeadm 管理证书</a></li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-2e173356df5179cab9eec90a606f0aa4">4 - 升级 kubeadm 集群</h1>
    
	<!--
reviewers:
- sig-cluster-lifecycle
title: Upgrading kubeadm clusters
content_type: task
weight: 20
min-kubernetes-server-version: 1.18
-->
<!-- overview -->
<!--
This page explains how to upgrade a Kubernetes cluster created with kubeadm from version
1.22.x to version 1.23.x, and from version
1.23.x to 1.23.y (where `y > x`). Skipping MINOR versions
when upgrading is unsupported. For more details, please visit [Version Skew Policy](https://kubernetes.io/releases/version-skew-policy/).
-->
<p>本页介绍如何将 <code>kubeadm</code> 创建的 Kubernetes 集群从 1.22.x 版本
升级到 1.23.x 版本以及从 1.23.x
升级到 1.23.y（其中 <code>y &gt; x</code>）。略过次版本号的升级是
不被支持的。更多详情请访问<a href="https://kubernetes.io/releases/version-skew-policy/">版本倾斜政策</a>。</p>
<!--
To see information about upgrading clusters created using older versions of kubeadm,
please refer to following pages instead:
-->
<p>要查看 kubeadm 创建的有关旧版本集群升级的信息，请参考以下页面：</p>
<!--
- [Upgrading a kubeadm cluster from 1.21 to 1.22](https://v1-22.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/)
- [Upgrading a kubeadm cluster from 1.20 to 1.21](https://v1-21.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/)
- [Upgrading a kubeadm cluster from 1.19 to 1.20](https://v1-20.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/)
- [Upgrading a kubeadm cluster from 1.18 to 1.19](https://v1-19.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/)
-->
<ul>
<li><a href="https://v1-22.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/">将 kubeadm 集群从 1.21 升级到 1.22</a></li>
<li><a href="https://v1-21.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/">将 kubeadm 集群从 1.20 升级到 1.21</a></li>
<li><a href="https://v1-20.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/">将 kubeadm 集群从 1.19 升级到 1.20</a></li>
<li><a href="https://v1-19.docs.kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/">将 kubeadm 集群从 1.18 升级到 1.19</a></li>
</ul>
<!--
The upgrade workflow at high level is the following:

1. Upgrade a primary control plane node.
1. Upgrade additional control plane nodes.
1. Upgrade worker nodes.
-->
<p>升级工作的基本流程如下：</p>
<ol>
<li>升级主控制平面节点</li>
<li>升级其他控制平面节点</li>
<li>升级工作节点</li>
</ol>
<h2 id="before-you-begin">Before you begin</h2>
<!--
- Make sure you read the [release notes](https://git.k8s.io/kubernetes/CHANGELOG/CHANGELOG-1.23.md
) carefully.
- The cluster should use a static control plane and etcd pods or external etcd.
- Make sure to back up any important components, such as app-level state stored in a database.
  `kubeadm upgrade` does not touch your workloads, only components internal to Kubernetes, but backups are always a best practice.
-->
<ul>
<li>务必仔细认真阅读<a href="https://git.k8s.io/kubernetes/CHANGELOG/CHANGELOG-1.23.md
">发行说明</a>。</li>
<li>集群应使用静态的控制平面和 etcd Pod 或者外部 etcd。</li>
<li>务必备份所有重要组件，例如存储在数据库中应用层面的状态。
<code>kubeadm upgrade</code> 不会影响你的工作负载，只会涉及 Kubernetes 内部的组件，但备份终究是好的。</li>
<li><a href="https://serverfault.com/questions/684771/best-way-to-disable-swap-in-linux">必须禁用交换分区</a>。</li>
</ul>
<!--
### Additional information

- The instructions below outline when to drain each node during the upgrade process.
If you are performing a **minor** version upgrade for any kubelet, you **must**
first drain the node (or nodes) that you are upgrading. In the case of control plane nodes,
they could be running CoreDNS Pods or other critical workloads. For more information see
[Draining nodes](/docs/tasks/administer-cluster/safely-drain-node/).
- All containers are restarted after upgrade, because the container spec hash value is changed.
-->
<h3 id="附加信息">附加信息</h3>
<ul>
<li>下述说明了在升级过程中何时腾空每个节点。如果你正在对任何 kubelet 进行小版本升级，
你需要先腾空待升级的节点（或多个节点）。对于控制面节点，其上可能运行着 CoreDNS Pods
或者其它非常重要的负载。更多信息见<a href="/zh/docs/tasks/administer-cluster/safely-drain-node/">腾空节点</a>。</li>
<li>升级后，因为容器规约的哈希值已更改，所有容器都会被重新启动。</li>
</ul>
<!--
- To verify that the kubelet service has successfully restarted after the kubelet has been upgraded,
you can execute `systemctl status kubelet`  or view the service logs with `journalctl -xeu kubelet`.
- Usage of the `--config` flag of `kubeadm upgrade` with
[kubeadm configuration API types](/docs/reference/config-api/kubeadm-config.v1beta3)
with the purpose of reconfiguring the cluster is not recommended and can have unexpected results. Follow the steps in
[Reconfiguring a kubeadm cluster](/docs/tasks/administer-cluster/kubeadm/kubeadm-reconfigure) instead.
-->
<ul>
<li>要验证 kubelet 服务在升级后是否成功重启，可以执行 <code>systemctl status kubelet</code>
或 <code>journalctl -xeu kubelet</code> 查看服务日志。</li>
<li>不建议使用 <code>kubeadm upgrade</code> 的 `--config 参数和 <a href="/zh/docs/reference/config-api/kubeadm-config.v1beta3">kubeadm 配置 API 类型</a>
来重新配置集群，这样会产生意想不到的结果。请按照<a href="/zh/docs/tasks/administer-cluster/kubeadm/kubeadm-reconfigure">重新配置 kubeadm 集群</a>
中的步骤来进行。</li>
</ul>
<!-- steps -->
<!--
## Determine which version to upgrade to

Find the latest patch release for Kubernetes 1.23 using the OS package manager:
-->
<h2 id="确定要升级到哪个版本">确定要升级到哪个版本</h2>
<p>使用操作系统的包管理器找到最新的补丁版本 Kubernetes 1.23：</p>
<ul class="nav nav-tabs" id="k8s-install-versions" role="tablist"><li class="nav-item"><a data-toggle="tab" class="nav-link active" href="#k8s-install-versions-0" role="tab" aria-controls="k8s-install-versions-0" aria-selected="true">Ubuntu、Debian 或 HypriotOS</a></li>
	  
		<li class="nav-item"><a data-toggle="tab" class="nav-link" href="#k8s-install-versions-1" role="tab" aria-controls="k8s-install-versions-1">CentOS、RHEL 或 Fedora</a></li></ul>
<div class="tab-content" id="k8s-install-versions"><div id="k8s-install-versions-0" class="tab-pane show active" role="tabpanel" aria-labelledby="k8s-install-versions-0">

<p><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">apt update
apt-cache madison kubeadm
<span style="color:#080;font-style:italic"># 在列表中查找最新的 1.23 版本</span>
<span style="color:#080;font-style:italic"># 它看起来应该是 1.23.x-00，其中 x 是最新的补丁版本</span>
</code></pre></div></div>
  <div id="k8s-install-versions-1" class="tab-pane" role="tabpanel" aria-labelledby="k8s-install-versions-1">

<p><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">yum list --showduplicates kubeadm --disableexcludes<span style="color:#666">=</span>kubernetes
<span style="color:#080;font-style:italic"># 在列表中查找最新的 1.23 版本</span>
<span style="color:#080;font-style:italic"># 它看起来应该是 1.23.x-0，其中 x 是最新的补丁版本</span>
</code></pre></div></div></div>

<!--
## Upgrade the control plane node

The upgrade procedure on control plane nodes should be executed one node at a time.
Pick a control plane node that you wish to upgrade first. It must have the `/etc/kubernetes/admin.conf` file.

### Call "kubeadm upgrade"
-->
<h2 id="升级控制平面节点">升级控制平面节点</h2>
<p>控制面节点上的升级过程应该每次处理一个节点。
首先选择一个要先行升级的控制面节点。该节点上必须拥有
<code>/etc/kubernetes/admin.conf</code> 文件。</p>
<h3 id="执行-kubeadm-upgrade">执行 &quot;kubeadm upgrade&quot;</h3>
<!--
**Upgrade the first control plane node**
-->
<p><strong>升级第一个控制面节点</strong></p>
<!--
- Upgrade kubeadm:
-->
<ul>
<li>升级 kubeadm：</li>
</ul>
<p><ul class="nav nav-tabs" id="k8s-install-kubeadm-first-cp" role="tablist"><li class="nav-item"><a data-toggle="tab" class="nav-link active" href="#k8s-install-kubeadm-first-cp-0" role="tab" aria-controls="k8s-install-kubeadm-first-cp-0" aria-selected="true">Ubuntu、Debian 或 HypriotOS</a></li>
	  
		<li class="nav-item"><a data-toggle="tab" class="nav-link" href="#k8s-install-kubeadm-first-cp-1" role="tab" aria-controls="k8s-install-kubeadm-first-cp-1">CentOS、RHEL 或 Fedora</a></li></ul>
<div class="tab-content" id="k8s-install-kubeadm-first-cp"><div id="k8s-install-kubeadm-first-cp-0" class="tab-pane show active" role="tabpanel" aria-labelledby="k8s-install-kubeadm-first-cp-0">

<p><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#080;font-style:italic"># 用最新的补丁版本号替换 1.23.x-00 中的 x</span>
apt-mark unhold kubeadm <span style="color:#666">&amp;&amp;</span> <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>apt-get update <span style="color:#666">&amp;&amp;</span> apt-get install -y <span style="color:#b8860b">kubeadm</span><span style="color:#666">=</span>1.23.x-00 <span style="color:#666">&amp;&amp;</span> <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>apt-mark hold kubeadm
-

</code></pre></div></div>
  <div id="k8s-install-kubeadm-first-cp-1" class="tab-pane" role="tabpanel" aria-labelledby="k8s-install-kubeadm-first-cp-1">

<p><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#080;font-style:italic"># 用最新的补丁版本号替换 1.23.x-0 中的 x</span>
yum install -y kubeadm-1.23.x-0 --disableexcludes<span style="color:#666">=</span>kubernetes
</code></pre></div></div></div>

<br /></p>
<!--
- Verify that the download works and has the expected version:
-->
<ul>
<li>
<p>验证下载操作正常，并且 kubeadm 版本正确：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubeadm version
</code></pre></div></li>
</ul>
<!--
- Verify the upgrade plan:
-->
<ul>
<li>
<p>验证升级计划：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubeadm upgrade plan
</code></pre></div><!--
This command checks that your cluster can be upgraded, and fetches the versions you can upgrade to.
It also shows a table with the component config version states.
-->
<p>此命令检查你的集群是否可被升级，并取回你要升级的目标版本。
命令也会显示一个包含组件配置版本状态的表格。</p>
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> <!--
  `kubeadm upgrade` also automatically renews the certificates that it manages on this node.
  To opt-out of certificate renewal the flag `--certificate-renewal=false` can be used.
  For more information see the [certificate management guide](/docs/tasks/administer-cluster/kubeadm/kubeadm-certs).
  -->
<p><code>kubeadm upgrade</code> 也会自动对 kubeadm 在节点上所管理的证书执行续约操作。
如果需要略过证书续约操作，可以使用标志 <code>--certificate-renewal=false</code>。
更多的信息，可参阅<a href="/zh/docs/tasks/administer-cluster/kubeadm/kubeadm-certs">证书管理指南</a>。
</div>
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> <!--
  If `kubeadm upgrade plan` shows any component configs that require manual upgrade, users must provide
  a config file with replacement configs to `kubeadm upgrade apply` via the `--config` command line flag.
  Failing to do so will cause `kubeadm upgrade apply` to exit with an error and not perform an upgrade.
  -->
<p>如果 <code>kubeadm upgrade plan</code> 给出任何需要手动升级的组件配置，用户必须
通过 <code>--config</code> 命令行标志向 <code>kubeadm upgrade apply</code> 命令提供替代的配置文件。
如果不这样做，<code>kubeadm upgrade apply</code> 会出错并退出，不再执行升级操作。
</div>
</li>
</ul>
<!--
- Choose a version to upgrade to, and run the appropriate command. For example:

  ```shell
  # replace x with the patch version you picked for this upgrade
  sudo kubeadm upgrade apply v1.23.x
  ```
-->
<p>选择要升级到的目标版本，运行合适的命令。例如：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#080;font-style:italic"># 将 x 替换为你为此次升级所选择的补丁版本号</span>
sudo kubeadm upgrade apply v1.23.x
</code></pre></div>  <!--
  Once the command finishes you should see:
  -->
<p>一旦该命令结束，你应该会看到：</p>
<pre><code class="language-console" data-lang="console">[upgrade/successful] SUCCESS! Your cluster was upgraded to &quot;v1.23.x&quot;. Enjoy!

[upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven't already done so.
</code></pre><!--
- Manually upgrade your CNI provider plugin.

  Your Container Network Interface (CNI) provider may have its own upgrade instructions to follow.
  Check the [addons](/docs/concepts/cluster-administration/addons/) page to
  find your CNI provider and see whether additional upgrade steps are required.

  This step is not required on additional control plane nodes if the CNI provider runs as a DaemonSet.
-->
<ul>
<li>
<p>手动升级你的 CNI 驱动插件。</p>
<p>你的容器网络接口（CNI）驱动应该提供了程序自身的升级说明。
参阅<a href="/zh/docs/concepts/cluster-administration/addons/">插件</a>页面查找你的 CNI 驱动，
并查看是否需要其他升级步骤。</p>
<p>如果 CNI 驱动作为 DaemonSet 运行，则在其他控制平面节点上不需要此步骤。</p>
</li>
</ul>
<!--
**For the other control plane nodes**
-->
<p><strong>对于其它控制面节点</strong></p>
<!--
Same as the first control plane node but use:
-->
<p>与第一个控制面节点相同，但是使用：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">sudo kubeadm upgrade node
</code></pre></div><!--
instead of:
-->
<p>而不是：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">sudo kubeadm upgrade apply
</code></pre></div><!--
Also calling `kubeadm upgrade plan` and upgrading the CNI provider plugin is no longer needed.
-->
<p>此外，不需要执行 <code>kubeadm upgrade plan</code> 和更新 CNI 驱动插件的操作。</p>
<!--
### Drain the node

-  Prepare the node for maintenance by marking it unschedulable and evicting the workloads:

    ```shell
    # replace <node-to-drain> with the name of your node you are draining
    kubectl drain <node-to-drain> --ignore-daemonsets
    ```
-->
<h3 id="腾空节点">腾空节点</h3>
<ul>
<li>
<p>通过将节点标记为不可调度并腾空节点为节点作升级准备：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#080;font-style:italic"># 将 &lt;node-to-drain&gt; 替换为你要腾空的控制面节点名称</span>
kubectl drain &lt;node-to-drain&gt; --ignore-daemonsets
</code></pre></div></li>
</ul>
<!--
### Upgrade kubelet and kubectl

-  Upgrade the kubelet and kubectl:
-->
<h3 id="升级-kubelet-和-kubectl">升级 kubelet 和 kubectl</h3>
<ul>
<li>
<p>升级 kubelet 和 kubectl：</p>
<p><ul class="nav nav-tabs" id="k8s-install-kubelet" role="tablist"><li class="nav-item"><a data-toggle="tab" class="nav-link active" href="#k8s-install-kubelet-0" role="tab" aria-controls="k8s-install-kubelet-0" aria-selected="true">Ubuntu、Debian 或 HypriotOS</a></li>
	  
		<li class="nav-item"><a data-toggle="tab" class="nav-link" href="#k8s-install-kubelet-1" role="tab" aria-controls="k8s-install-kubelet-1">CentOS、RHEL 或 Fedora</a></li></ul>
<div class="tab-content" id="k8s-install-kubelet"><div id="k8s-install-kubelet-0" class="tab-pane show active" role="tabpanel" aria-labelledby="k8s-install-kubelet-0">

<p><pre><code>```shell
# 用最新的补丁版本替换 1.23.x-00 中的 x
apt-mark unhold kubelet kubectl &amp;&amp; \
apt-get update &amp;&amp; apt-get install -y kubelet=1.23.x-00 kubectl=1.23.x-00 &amp;&amp; \
apt-mark hold kubelet kubectl
```
</code></pre>
</div>
  <div id="k8s-install-kubelet-1" class="tab-pane" role="tabpanel" aria-labelledby="k8s-install-kubelet-1">

<p><pre><code>```shell
# 用最新的补丁版本号替换 1.23.x-00 中的 x
yum install -y kubelet-1.23.x-0 kubectl-1.23.x-0 --disableexcludes=kubernetes
```
</code></pre>
</div></div>

<br /></p>
</li>
</ul>
<!--
- Restart the kubelet
-->
<ul>
<li>
<p>重启 kubelet</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">sudo systemctl daemon-reload
sudo systemctl restart kubelet
</code></pre></div></li>
</ul>
<!--
### Uncordon the node

- Bring the node back online by marking it schedulable:

  ```shell
  # replace <node-to-drain> with the name of your node
  kubectl uncordon <node-to-drain>

-->
<h3 id="解除节点的保护">解除节点的保护</h3>
<ul>
<li>
<p>通过将节点标记为可调度，让其重新上线：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#080;font-style:italic"># 将 &lt;node-to-drain&gt; 替换为你的节点名称</span>
kubectl uncordon &lt;node-to-drain&gt;
</code></pre></div></li>
</ul>
<!--
## Upgrade worker nodes

The upgrade procedure on worker nodes should be executed one node at a time or few nodes at a time,
without compromising the minimum required capacity for running your workloads.
-->
<h2 id="升级工作节点">升级工作节点</h2>
<p>工作节点上的升级过程应该一次执行一个节点，或者一次执行几个节点，
以不影响运行工作负载所需的最小容量。</p>
<!--
### Upgrade kubeadm
-->
<h3 id="升级-kubeadm">升级 kubeadm</h3>
<!--
- Upgrade kubeadm:
-->
<ul>
<li>
<p>升级 kubeadm：</p>
<ul class="nav nav-tabs" id="k8s-install-kubeadm-worker-nodes" role="tablist"><li class="nav-item"><a data-toggle="tab" class="nav-link active" href="#k8s-install-kubeadm-worker-nodes-0" role="tab" aria-controls="k8s-install-kubeadm-worker-nodes-0" aria-selected="true">Ubuntu、Debian 或 HypriotOS</a></li>
	  
		<li class="nav-item"><a data-toggle="tab" class="nav-link" href="#k8s-install-kubeadm-worker-nodes-1" role="tab" aria-controls="k8s-install-kubeadm-worker-nodes-1">CentOS、RHEL 或 Fedora</a></li></ul>
<div class="tab-content" id="k8s-install-kubeadm-worker-nodes"><div id="k8s-install-kubeadm-worker-nodes-0" class="tab-pane show active" role="tabpanel" aria-labelledby="k8s-install-kubeadm-worker-nodes-0">

<p><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#080;font-style:italic"># 将 1.23.x-00 中的 x 替换为最新的补丁版本号</span>
apt-mark unhold kubeadm <span style="color:#666">&amp;&amp;</span> <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>apt-get update <span style="color:#666">&amp;&amp;</span> apt-get install -y <span style="color:#b8860b">kubeadm</span><span style="color:#666">=</span>1.23.x-00 <span style="color:#666">&amp;&amp;</span> <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>apt-mark hold kubeadm
</code></pre></div></div>
  <div id="k8s-install-kubeadm-worker-nodes-1" class="tab-pane" role="tabpanel" aria-labelledby="k8s-install-kubeadm-worker-nodes-1">

<p><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#080;font-style:italic"># 用最新的补丁版本替换 1.23.x-00 中的 x</span>
yum install -y kubeadm-1.23.x-0 --disableexcludes<span style="color:#666">=</span>kubernetes
</code></pre></div></div></div>

</li>
</ul>
<!--
### Call "kubeadm upgrade"

-  For worker nodes this upgrades the local kubelet configuration:
-->
<h3 id="执行-kubeadm-upgrade-1">执行 &quot;kubeadm upgrade&quot;</h3>
<ul>
<li>
<p>对于工作节点，下面的命令会升级本地的 kubelet 配置：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">sudo kubeadm upgrade node
</code></pre></div></li>
</ul>
<!--
### Drain the node

- Prepare the node for maintenance by marking it unschedulable and evicting the workloads:

  ```shell
  # replace <node-to-drain> with the name of your node you are draining
  kubectl drain <node-to-drain> --ignore-daemonsets
  ```
-->
<h3 id="腾空节点-1">腾空节点</h3>
<ul>
<li>
<p>将节点标记为不可调度并驱逐所有负载，准备节点的维护：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#080;font-style:italic"># 将 &lt;node-to-drain&gt; 替换为你正在腾空的节点的名称</span>
kubectl drain &lt;node-to-drain&gt; --ignore-daemonsets
</code></pre></div></li>
</ul>
<!--
### Upgrade kubelet and kubectl
-->
<h3 id="升级-kubelet-和-kubectl-1">升级 kubelet 和 kubectl</h3>
<!--
-  Upgrade the kubelet and kubectl:
-->
<ul>
<li>
<p>升级 kubelet 和 kubectl：</p>
<ul class="nav nav-tabs" id="k8s-kubelet-and-kubectl" role="tablist"><li class="nav-item"><a data-toggle="tab" class="nav-link active" href="#k8s-kubelet-and-kubectl-0" role="tab" aria-controls="k8s-kubelet-and-kubectl-0" aria-selected="true">Ubuntu、Debian 或 HypriotOS</a></li>
	  
		<li class="nav-item"><a data-toggle="tab" class="nav-link" href="#k8s-kubelet-and-kubectl-1" role="tab" aria-controls="k8s-kubelet-and-kubectl-1">CentOS, RHEL or Fedora</a></li></ul>
<div class="tab-content" id="k8s-kubelet-and-kubectl"><div id="k8s-kubelet-and-kubectl-0" class="tab-pane show active" role="tabpanel" aria-labelledby="k8s-kubelet-and-kubectl-0">

<p><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#080;font-style:italic"># 将 1.23.x-00 中的 x 替换为最新的补丁版本</span>
apt-mark unhold kubelet kubectl <span style="color:#666">&amp;&amp;</span> <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>apt-get update <span style="color:#666">&amp;&amp;</span> apt-get install -y <span style="color:#b8860b">kubelet</span><span style="color:#666">=</span>1.23.x-00 <span style="color:#b8860b">kubectl</span><span style="color:#666">=</span>1.23.x-00 <span style="color:#666">&amp;&amp;</span> <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>apt-mark hold kubelet kubectl
</code></pre></div></div>
  <div id="k8s-kubelet-and-kubectl-1" class="tab-pane" role="tabpanel" aria-labelledby="k8s-kubelet-and-kubectl-1">

<p><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#080;font-style:italic"># 将 1.23.x-0 x 替换为最新的补丁版本</span>
yum install -y kubelet-1.23.x-0 kubectl-1.23.x-0 --disableexcludes<span style="color:#666">=</span>kubernetes
</code></pre></div></div></div>

</li>
</ul>
<!--
- Restart the kubelet

    ```shell
    sudo systemctl daemon-reload
    sudo systemctl restart kubelet
    ```
-->
<ul>
<li>
<p>重启 kubelet</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">sudo systemctl daemon-reload
sudo systemctl restart kubelet
</code></pre></div></li>
</ul>
<!--
### Uncordon the node
-->
<h3 id="取消对节点的保护">取消对节点的保护</h3>
<!--
-  Bring the node back online by marking it schedulable:

    ```shell
    # replace <node-to-drain> with the name of your node
    kubectl uncordon <node-to-drain>
    ```
-->
<ul>
<li>
<p>通过将节点标记为可调度，让节点重新上线:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#080;font-style:italic"># 将 &lt;node-to-drain&gt; 替换为当前节点的名称</span>
kubectl uncordon &lt;node-to-drain&gt;
</code></pre></div></li>
</ul>
<!--
## Verify the status of the cluster

After the kubelet is upgraded on all nodes verify that all nodes are available again by running the following command
from anywhere kubectl can access the cluster:

```shell
kubectl get nodes
```
-->
<h2 id="验证集群的状态">验证集群的状态</h2>
<p>在所有节点上升级 kubelet 后，通过从 kubectl 可以访问集群的任何位置运行以下命令，
验证所有节点是否再次可用：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get nodes
</code></pre></div><!--
The `STATUS` column should show `Ready` for all your nodes, and the version number should be updated.
-->
<p><code>STATUS</code> 应显示所有节点为 <code>Ready</code> 状态，并且版本号已经被更新。</p>
<!--
## Recovering from a failure state

If `kubeadm upgrade` fails and does not roll back, for example because of an unexpected shutdown during execution, you can run `kubeadm upgrade` again.
This command is idempotent and eventually makes sure that the actual state is the desired state you declare.

To recover from a bad state, you can also run `kubeadm upgrade--force` without changing the version that your cluster is running.
-->
<h2 id="从故障状态恢复">从故障状态恢复</h2>
<p>如果 <code>kubeadm upgrade</code> 失败并且没有回滚，例如由于执行期间节点意外关闭，
你可以再次运行 <code>kubeadm upgrade</code>。
此命令是幂等的，并最终确保实际状态是你声明的期望状态。
要从故障状态恢复，你还可以运行 <code>kubeadm upgrade --force</code> 而无需更改集群正在运行的版本。</p>
<!--
During upgrade kubeadm writes the following backup folders under `/etc/kubernetes/tmp`:
- `kubeadm-backup-etcd-<date>-<time>`
- `kubeadm-backup-manifests-<date>-<time>`

`kubeadm-backup-etcd` contains a backup of the local etcd member data for this control-plane Node.
In case of an etcd upgrade failure and if the automatic rollback does not work, the contents of this folder
can be manually restored in `/var/lib/etcd`. In case external etcd is used this backup folder will be empty.

`kubeadm-backup-manifests` contains a backup of the static Pod manifest files for this control-plane Node.
In case of a upgrade failure and if the automatic rollback does not work, the contents of this folder can be
manually restored in `/etc/kubernetes/manifests`. If for some reason there is no difference between a pre-upgrade
and post-upgrade manifest file for a certain component, a backup file for it will not be written.
-->
<p>在升级期间，kubeadm 向 <code>/etc/kubernetes/tmp</code> 目录下的如下备份文件夹写入数据：</p>
<ul>
<li><code>kubeadm-backup-etcd-&lt;date&gt;-&lt;time&gt;</code></li>
<li><code>kubeadm-backup-manifests-&lt;date&gt;-&lt;time&gt;</code></li>
</ul>
<p><code>kubeadm-backup-etcd</code> 包含当前控制面节点本地 etcd 成员数据的备份。
如果 etcd 升级失败并且自动回滚也无法修复，则可以将此文件夹中的内容复制到
<code>/var/lib/etcd</code> 进行手工修复。如果使用的是外部的 etcd，则此备份文件夹为空。</p>
<p><code>kubeadm-backup-manifests</code> 包含当前控制面节点的静态 Pod 清单文件的备份版本。
如果升级失败并且无法自动回滚，则此文件夹中的内容可以复制到
<code>/etc/kubernetes/manifests</code> 目录实现手工恢复。
如果由于某些原因，在升级前后某个组件的清单未发生变化，则 kubeadm 也不会为之
生成备份版本。</p>
<!--
## How it works

`kubeadm upgrade apply` does the following:

- Checks that your cluster is in an upgradeable state:
  - The API server is reachable
  - All nodes are in the `Ready` state
  - The control plane is healthy
- Enforces the version skew policies.
- Makes sure the control plane images are available or available to pull to the machine.
- Generates replacements and/or uses user supplied overwrites if component configs require version upgrades.
- Upgrades the control plane components or rollbacks if any of them fails to come up.
- Applies the new `CoreDNS` and `kube-proxy` manifests and makes sure that all necessary RBAC rules are created.
- Creates new certificate and key files of the API server and backs up old files if they're about to expire in 180 days.
-->
<h2 id="how-it-works">工作原理  </h2>
<p><code>kubeadm upgrade apply</code> 做了以下工作：</p>
<ul>
<li>检查你的集群是否处于可升级状态:
<ul>
<li>API 服务器是可访问的</li>
<li>所有节点处于 <code>Ready</code> 状态</li>
<li>控制面是健康的</li>
</ul>
</li>
<li>强制执行版本偏差策略。</li>
<li>确保控制面的镜像是可用的或可拉取到服务器上。</li>
<li>如果组件配置要求版本升级，则生成替代配置与/或使用用户提供的覆盖版本配置。</li>
<li>升级控制面组件或回滚（如果其中任何一个组件无法启动）。</li>
<li>应用新的 <code>CoreDNS</code> 和 <code>kube-proxy</code> 清单，并强制创建所有必需的 RBAC 规则。</li>
<li>如果旧文件在 180 天后过期，将创建 API 服务器的新证书和密钥文件并备份旧文件。</li>
</ul>
<!--
`kubeadm upgrade node` does the following on additional control plane nodes:

- Fetches the kubeadm `ClusterConfiguration` from the cluster.
- Optionally backups the kube-apiserver certificate.
- Upgrades the static Pod manifests for the control plane components.
- Upgrades the kubelet configuration for this node.
-->
<p><code>kubeadm upgrade node</code> 在其他控制平节点上执行以下操作：</p>
<ul>
<li>从集群中获取 kubeadm <code>ClusterConfiguration</code>。</li>
<li>（可选操作）备份 kube-apiserver 证书。</li>
<li>升级控制平面组件的静态 Pod 清单。</li>
<li>为本节点升级 kubelet 配置</li>
</ul>
<!--
`kubeadm upgrade node` does the following on worker nodes:

- Fetches the kubeadm `ClusterConfiguration` from the cluster.
- Upgrades the kubelet configuration for this node.
-->
<p><code>kubeadm upgrade node</code> 在工作节点上完成以下工作：</p>
<ul>
<li>从集群取回 kubeadm <code>ClusterConfiguration</code>。</li>
<li>为本节点升级 kubelet 配置。</li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-9133578f1e75663bb031e5a377ca896d">5 - 添加 Windows 节点</h1>
    
	<!--
reviewers:
- michmike
- patricklang
title: Adding Windows nodes
min-kubernetes-server-version: 1.17
content_type: tutorial
weight: 30
-->
<!-- overview -->





<div style="margin-top: 10px; margin-bottom: 10px;">
  <b>FEATURE STATE:</b> <code>Kubernetes v1.18 [beta]</code>
</div>


<!--
You can use Kubernetes to run a mixture of Linux and Windows nodes, so you can mix Pods that run on Linux on with Pods that run on Windows. This page shows how to register Windows nodes to your cluster.
-->
<p>你可以使用 Kubernetes 来混合运行 Linux 和 Windows 节点，这样你就可以
混合使用运行于 Linux 上的 Pod 和运行于 Windows 上的 Pod。
本页面展示如何将 Windows 节点注册到你的集群。</p>
<h2 id="before-you-begin">Before you begin</h2>


Your Kubernetes server must be at or later than version 1.17.
 To check the version, enter <code>kubectl version</code>.

<!--
* Obtain a [Windows Server 2019 license](https://www.microsoft.com/en-us/cloud-platform/windows-server-pricing)
(or higher) in order to configure the Windows node that hosts Windows containers.
If you are using VXLAN/Overlay networking you must have also have [KB4489899](https://support.microsoft.com/help/4489899) installed.

* A Linux-based Kubernetes kubeadm cluster in which you have access to the control plane (see [Creating a single control-plane cluster with kubeadm](/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/)).
-->
<ul>
<li>
<p>获取 <a href="https://www.microsoft.com/en-us/cloud-platform/windows-server-pricing">Windows Server 2019 或更高版本的授权</a>
以便配置托管 Windows 容器的 Windows 节点。
如果你在使用 VXLAN/覆盖（Overlay）联网设施，则你还必须安装 <a href="https://support.microsoft.com/help/4489899">KB4489899</a>。</p>
</li>
<li>
<p>一个利用 kubeadm 创建的基于 Linux 的 Kubernetes 集群；你能访问该集群的控制面
（参见<a href="/zh/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/">使用 kubeadm 创建一个单控制面的集群</a>)。</p>
</li>
</ul>
<h2 id="objectives">Objectives</h2>
<!--
* Register a Windows node to the cluster
* Configure networking so Pods and Services on Linux and Windows can communicate with each other
-->
<ul>
<li>将一个 Windows 节点注册到集群上</li>
<li>配置网络，以便 Linux 和 Windows 上的 Pod 和 Service 之间能够相互通信。</li>
</ul>
<!-- lessoncontent -->
<!--
## Getting Started: Adding a Windows Node to Your Cluster

### Networking Configuration

Once you have a Linux-based Kubernetes control-plane node you are ready to choose a networking solution. This guide illustrates using Flannel in VXLAN mode for simplicity.
-->
<h2 id="开始行动-向你的集群添加一个-windows-节点">开始行动：向你的集群添加一个 Windows 节点</h2>
<h3 id="networking-configuration">联网配置  </h3>
<p>一旦你有了一个基于 Linux 的 Kubernetes 控制面节点，你就可以为其选择联网方案。
出于简单考虑，本指南展示如何使用 VXLAN 模式的 Flannel。</p>
<!--
#### Configuring Flannel

1. Prepare Kubernetes control plane for Flannel

    Some minor preparation is recommended on the Kubernetes control plane in our cluster. It is recommended to enable bridged IPv4 traffic to iptables chains when using Flannel. The following command must be run on all Linux nodes:

    ```bash
    sudo sysctl net.bridge.bridge-nf-call-iptables=1
    ```
-->
<h4 id="configuring-flannel">配置 Flannel </h4>
<ol>
<li>
<p>为 Flannel 准备 Kubernetes 的控制面</p>
<p>在我们的集群中，建议对 Kubernetes 的控制面进行少许准备处理。
建议在使用 Flannel 时为 iptables 链启用桥接方式的 IPv4 流处理，
必须在所有 Linux 节点上执行如下命令：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">sudo sysctl net.bridge.bridge-nf-call-iptables<span style="color:#666">=</span><span style="color:#666">1</span>
</code></pre></div></li>
</ol>
<!--
1. Download & configure Flannel for Linux

    Download the most recent Flannel manifest:

    ```bash
    wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
    ```

    Modify the `net-conf.json` section of the flannel manifest in order to set the VNI to 4096 and the Port to 4789. It should look as follows:

    ```json
    net-conf.json: |
        {
          "Network": "10.244.0.0/16",
          "Backend": {
            "Type": "vxlan",
            "VNI": 4096,
            "Port": 4789
          }
        }
    ```

    The VNI must be set to 4096 and port 4789 for Flannel on Linux to interoperate with Flannel on Windows. See the [VXLAN documentation](https://github.com/coreos/flannel/blob/master/Documentation/backends.md#vxlan).
    for an explanation of these fields.

    To use L2Bridge/Host-gateway mode instead change the value of `Type` to `"host-gw"` and omit `VNI` and `Port`.
-->
<ol start="2">
<li>
<p>下载并配置 Linux 版本的 Flannel</p>
<p>下载最新的 Flannel 清单文件：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</code></pre></div><p>修改 Flannel 清单中的 <code>net-conf.json</code> 部分，将 VNI 设置为 4096，并将 Port 设置为 4789。
结果看起来像下面这样：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-json" data-lang="json"><span style="">net-conf.json:</span> <span style="">|</span>
    {
      <span style="color:#008000;font-weight:bold">&#34;Network&#34;</span>: <span style="color:#b44">&#34;10.244.0.0/16&#34;</span>,
      <span style="color:#008000;font-weight:bold">&#34;Backend&#34;</span>: {
         <span style="color:#008000;font-weight:bold">&#34;Type&#34;</span>: <span style="color:#b44">&#34;vxlan&#34;</span>,
         <span style="color:#008000;font-weight:bold">&#34;VNI&#34;</span>: <span style="color:#666">4096</span>,
         <span style="color:#008000;font-weight:bold">&#34;Port&#34;</span>: <span style="color:#666">4789</span>
    }
}
</code></pre></div><div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> 在 Linux 节点上 VNI 必须设置为 4096，端口必须设置为 4789，这样才能令其与 Windows 上的
Flannel 互操作。关于这些字段的详细说明，请参见
<a href="https://github.com/coreos/flannel/blob/master/Documentation/backends.md#vxlan">VXLAN 文档</a>。
</div>
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> 如要使用 L2Bridge/Host-gateway 模式，则可将 <code>Type</code> 值设置为
<code>&quot;host-gw&quot;</code>，并忽略 <code>VNI</code> 和 <code>Port</code> 的设置。
</div>
</li>
</ol>
<!--
1. Apply the Flannel manifest and validate

    Let's apply the Flannel configuration:

    ```bash
    kubectl apply -f kube-flannel.yml
    ```

    After a few minutes, you should see all the pods as running if the Flannel pod network was deployed.

    ```bash
    kubectl get pods -n kube-system
    ```

    The output should include the Linux flannel DaemonSet as running:

    ```
    NAMESPACE     NAME                                      READY        STATUS    RESTARTS   AGE
    ...
    kube-system   kube-flannel-ds-54954                     1/1          Running   0          1m
    ```
-->
<ol start="3">
<li>
<p>应用 Flannel 清单并验证</p>
<p>首先应用 Flannel 配置：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">kubectl apply -f kube-flannel.yml
</code></pre></div><p>几分钟之后，如果 Flannel Pod 网络被正确部署，你应该会看到所有 Pods 都处于运行中状态。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">kubectl get pods -n kube-system
</code></pre></div><p>输出中应该包含处于运行中状态的 Linux Flannel DaemonSet：</p>
<pre><code>NAMESPACE     NAME                                      READY        STATUS    RESTARTS   AGE
...
kube-system   kube-flannel-ds-54954                     1/1          Running   0          1m
</code></pre></li>
</ol>
<!--
1. Add Windows Flannel and kube-proxy DaemonSets

    Now you can add Windows-compatible versions of Flannel and kube-proxy. In order
    to ensure that you get a compatible version of kube-proxy, you'll need to substitute
    the tag of the image. The following example shows usage for Kubernetes v1.23.0,
    but you should adjust the version for your own deployment.

    ```bash
    curl -L https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/kube-proxy.yml | sed 's/VERSION/v1.23.0/g' | kubectl apply -f -
    kubectl apply -f https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/flannel-overlay.yml
    ```

    If you're using host-gateway use https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/flannel-host-gw.yml instead

If you're using a different interface rather than Ethernet (i.e. "Ethernet0 2") on the Windows nodes, you have to modify the line:

```powershell
wins cli process run --path /k/flannel/setup.exe --args "--mode=overlay --interface=Ethernet"
```

in the `flannel-host-gw.yml` or `flannel-overlay.yml` file and specify your interface accordingly.

```bash
# Example
curl -L https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/flannel-overlay.yml | sed 's/Ethernet/Ethernet0 2/g' | kubectl apply -f -
```
-->    
<ol start="4">
<li>
<p>添加 Windows Flannel 和 kube-proxy DaemonSet</p>
<p>现在你可以添加 Windows 兼容版本的 Flannel 和 kube-proxy。为了确保你能获得兼容
版本的 kube-proxy，你需要替换镜像中的标签。
下面的例子中展示的是针对 Kubernetes v1.23.0 版本的用法，
不过你应该根据你自己的集群部署调整其中的版本号。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">curl -L https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/kube-proxy.yml | sed <span style="color:#b44">&#39;s/VERSION/v1.23.0/g&#39;</span> | kubectl apply -f -
kubectl apply -f https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/flannel-overlay.yml
</code></pre></div><div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> 如果你在使用 host-gateway 模式，则应该使用
<a href="https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/flannel-host-gw.yml">https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/flannel-host-gw.yml</a>
这一清单。
</div>
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> <p>如果你在 Windows 节点上使用的不是以太网（即，&quot;Ethernet0 2&quot;）接口，你需要
修改 <code>flannel-host-gw.yml</code> 或 <code>flannel-overlay.yml</code> 文件中的下面这行：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-powershell" data-lang="powershell">wins <span style="color:#a2f">cli </span><span style="color:#a2f;font-weight:bold">process</span> run --path /k/flannel/setup.exe --args <span style="color:#b44">&#34;--mode=overlay --interface=Ethernet&#34;</span>
</code></pre></div><p>在其中根据情况设置要使用的网络接口。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#080;font-style:italic"># Example</span>
curl -L https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/flannel-overlay.yml | sed <span style="color:#b44">&#39;s/Ethernet/Ethernet0 2/g&#39;</span> | kubectl apply -f -
</code></pre></div>
</div>
</li>
</ol>
<!--
### Joining a Windows worker node
-->
<h3 id="joining-a-windows-worker-node">加入 Windows 工作节点  </h3>
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> <!--
All code snippets in Windows sections are to be run in a PowerShell environment
with elevated permissions (Administrator) on the Windows worker node.
-->
<p>Windows 节的所有代码片段都需要在 PowerShell 环境中执行，并且要求在
Windows 工作节点上具有提升的权限（Administrator）。
</div>
<ul class="nav nav-tabs" id="tab-windows-kubeadm-runtime-installation" role="tablist"><li class="nav-item"><a data-toggle="tab" class="nav-link active" href="#tab-windows-kubeadm-runtime-installation-0" role="tab" aria-controls="tab-windows-kubeadm-runtime-installation-0" aria-selected="true">Docker EE</a></li>
	  
		<li class="nav-item"><a data-toggle="tab" class="nav-link" href="#tab-windows-kubeadm-runtime-installation-1" role="tab" aria-controls="tab-windows-kubeadm-runtime-installation-1">CRI-containerD</a></li></ul>
<div class="tab-content" id="tab-windows-kubeadm-runtime-installation"><div id="tab-windows-kubeadm-runtime-installation-0" class="tab-pane show active" role="tabpanel" aria-labelledby="tab-windows-kubeadm-runtime-installation-0">

<p><!--
#### Install Docker EE

Install the `Containers` feature
-->
<h4 id="安装-docker-ee">安装 Docker EE</h4>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-powershell" data-lang="powershell"><span style="color:#a2f">Install-WindowsFeature</span> -Name containers
</code></pre></div><!--
Install Docker
Instructions to do so are available at [Install Docker Engine - Enterprise on Windows Servers](https://docs.microsoft.com/en-us/virtualization/windowscontainers/quick-start/set-up-environment?tabs=Windows-Server#install-docker).
-->
<p>安装 Docker
操作指南在 <a href="https://docs.microsoft.com/en-us/virtualization/windowscontainers/quick-start/set-up-environment?tabs=Windows-Server#install-docker">Install Docker Engine - Enterprise on Windows Servers</a>。</p>
<!--
#### Install wins, kubelet, and kubeadm.
-->
<h4 id="安装-wins-kubelet-和-kubeadm">安装 wins、kubelet 和 kubeadm</h4>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-PowerShell" data-lang="PowerShell">curl.exe -LO https<span style="">:</span>//raw.githubusercontent.com/<span style="color:#a2f">kubernetes-sigs</span>/<span style="color:#a2f">sig-windows</span>-tools/master/kubeadm/scripts/PrepareNode.ps1
.\PrepareNode.ps1 -KubernetesVersion v1.23.0
</code></pre></div><!--
#### Run `kubeadm` to join the node

    Use the command that was given to you when you ran `kubeadm init` on a control plane host.
    If you no longer have this command, or the token has expired, you can run `kubeadm token create -print-join-command`
    (on a control plane host) to generate a new token and join command.
-->
<h4 id="运行-kubeadm-添加节点">运行 <code>kubeadm</code> 添加节点</h4>
<p>当你在控制面主机上运行 <code>kubeadm init</code> 时，输出了一个命令。现在运行这个命令。
如果你找不到这个命令，或者命令中对应的令牌已经过期，你可以（在一个控制面主机上）运行
<code>kubeadm token create --print-join-command</code> 来生成新的令牌和 join 命令。</p>
</div>
  <div id="tab-windows-kubeadm-runtime-installation-1" class="tab-pane" role="tabpanel" aria-labelledby="tab-windows-kubeadm-runtime-installation-1">

<p><!--
#### Install containerD
-->
<h4 id="安装-containerd">安装 containerD</h4>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-powershell" data-lang="powershell">curl.exe -LO https<span style="">:</span>//github.com/<span style="color:#a2f">kubernetes-sigs</span>/<span style="color:#a2f">sig-windows</span>-tools/releases/latest/download/<span style="color:#a2f">Install-Containerd</span>.ps1
.\<span style="color:#a2f">Install-Containerd</span>.ps1
</code></pre></div><div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> <!--
To install a specific version of containerD specify the version with -ContainerDVersion.
-->
<p>要安装特定版本的 containerD，使用参数 -ContainerDVersion指定版本。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-powershell" data-lang="powershell"><span style="color:#080;font-style:italic"># Example</span>
.\<span style="color:#a2f">Install-Containerd</span>.ps1 -ContainerDVersion 1.4.1
</code></pre></div>
</div>
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> <!--
If you're using a different interface rather than Ethernet (i.e. "Ethernet0 2") on the Windows nodes, specify the name with `-netAdapterName`.
-->
<p>如果你在 Windows 节点上使用了与 Ethernet 不同的接口（例如 &quot;Ethernet0 2&quot;），使用参数 <code>-netAdapterName</code> 指定名称。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-powershell" data-lang="powershell"><span style="color:#080;font-style:italic"># Example</span>
.\<span style="color:#a2f">Install-Containerd</span>.ps1 -netAdapterName <span style="color:#b44">&#34;Ethernet0 2&#34;</span>
</code></pre></div>
</div>
<!--
#### Install wins, kubelet, and kubeadm
-->
<h4 id="安装-wins-kubelet-和-kubeadm">安装 wins，kubelet 和 kubeadm</h4>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-PowerShell" data-lang="PowerShell">curl.exe -LO https<span style="">:</span>//raw.githubusercontent.com/<span style="color:#a2f">kubernetes-sigs</span>/<span style="color:#a2f">sig-windows</span>-tools/master/kubeadm/scripts/PrepareNode.ps1
.\PrepareNode.ps1 -KubernetesVersion v1.23.0 -ContainerRuntime containerD
</code></pre></div><!--
#### Run `kubeadm` to join the node

Use the command that was given to you when you ran `kubeadm init` on a control plane host.
If you no longer have this command, or the token has expired, you can run `kubeadm token create --print-join-command`
(on a control plane host) to generate a new token and join command.
-->
<h4 id="运行-kubeadm-添加节点">运行 <code>kubeadm</code> 添加节点</h4>
<p>使用当你在控制面主机上运行 <code>kubeadm init</code> 时得到的命令。
如果你找不到这个命令，或者命令中对应的令牌已经过期，你可以（在一个控制面主机上）运行
<code>kubeadm token create --print-join-command</code> 来生成新的令牌和 join 命令。</p>
<div class="alert alert-info note callout" role="alert">
  <strong>Note:</strong> If using <strong>CRI-containerD</strong> add <code>--cri-socket &quot;npipe:////./pipe/containerd-containerd&quot;</code> to the kubeadm call
</div>
</div></div>

<!--
#### Verifying your installation

You should now be able to view the Windows node in your cluster by running:
-->
<h4 id="verifying-your-installation">检查你的安装  </h4>
<p>你现在应该能够通过运行下面的命令来查看集群中的 Windows 节点了：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">kubectl get nodes -o wide
</code></pre></div><!--
If your new node is in the `NotReady` state it is likely because the flannel image is still downloading.
You can check the progress as before by checking on the flannel pods in the `kube-system` namespace:
-->
<p>如果你的新节点处于 <code>NotReady</code> 状态，很可能的原因是系统仍在下载 Flannel 镜像。
你可以像之前一样，通过检查 <code>kube-system</code> 名字空间中的 Flannel Pods 来了解
安装进度。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl -n kube-system get pods -l <span style="color:#b8860b">app</span><span style="color:#666">=</span>flannel
</code></pre></div><!--
Once the flannel Pod is running, your node should enter the `Ready` state and then be available to handle workloads.
-->
<p>一旦 Flannel Pod 运行起来，你的节点就应该能进入 <code>Ready</code> 状态并可
用来处理负载。</p>
<h2 id="what-s-next">What's next</h2>
<!--
- [Upgrading Windows kubeadm nodes](/docs/tasks/administer-cluster/kubeadm/upgrading-windows-nodes)
-->
<ul>
<li><a href="/zh/docs/tasks/administer-cluster/kubeadm/upgrading-windows-nodes">升级 kubeadm 安装的 Windows 节点</a></li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-e805c7d8d4ad6195cb82dbbc843bfc29">6 - 升级 Windows 节点</h1>
    
	<!--
title: Upgrading Windows nodes
min-kubernetes-server-version: 1.17
content_type: task
weight: 40
-->
<!-- overview -->





<div style="margin-top: 10px; margin-bottom: 10px;">
  <b>FEATURE STATE:</b> <code>Kubernetes v1.18 [beta]</code>
</div>


<!--
This page explains how to upgrade a Windows node [created with kubeadm](/docs/tasks/administer-cluster/kubeadm/adding-windows-nodes).
-->
<p>本页解释如何升级<a href="/zh/docs/tasks/administer-cluster/kubeadm/adding-windows-nodes">用 kubeadm 创建的</a>
Windows 节点。</p>
<h2 id="before-you-begin">Before you begin</h2>
<p><p>你必须拥有一个 Kubernetes 的集群，同时你的 Kubernetes 集群必须带有 kubectl 命令行工具。
建议在至少有两个节点的集群上运行本教程，且这些节点不作为控制平面主机。
如果你还没有集群，你可以通过 <a href="https://minikube.sigs.k8s.io/docs/tutorials/multi_node/">Minikube</a>
构建一个你自己的集群，或者你可以使用下面任意一个 Kubernetes 工具构建：</p>
<!--
You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. It is recommended to run this tutorial on a cluster with at least two nodes that are not acting as control plane hosts. If you do not already have a
cluster, you can create one by using
[minikube](https://minikube.sigs.k8s.io/docs/tutorials/multi_node/)
or you can use one of these Kubernetes playgrounds:
-->
<ul>
<li><a href="https://www.katacoda.com/courses/kubernetes/playground">Katacoda</a></li>
<li><a href="http://labs.play-with-k8s.com/">玩转 Kubernetes</a></li>
</ul>
 

Your Kubernetes server must be at or later than version 1.17.
 To check the version, enter <code>kubectl version</code>.
</p>
<!--
* Familiarize yourself with [the process for upgrading the rest of your kubeadm
cluster](/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade). You will want to
upgrade the control plane nodes before upgrading your Windows nodes.
-->
<ul>
<li>熟悉<a href="/zh/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade">更新 kubeadm 集群中的其余组件</a>。
在升级你的 Windows 节点之前你会想要升级控制面节点。</li>
</ul>
<!-- steps -->
<!--
## Upgrading worker nodes

### Upgrade kubeadm
-->
<h2 id="upgrading-worker-nodes">升级工作节点  </h2>
<h3 id="upgrade-kubeadm">升级 kubeadm   </h3>
<!--
1.  From the Windows node, upgrade kubeadm:

    ```powershell
    # replace v1.23.0 with your desired version
    curl.exe -Lo C:\k\kubeadm.exe https://dl.k8s.io/v1.23.0/bin/windows/amd64/kubeadm.exe
    ```
-->
<ol>
<li>
<p>在 Windows 节点上升级 kubeadm：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-powershell" data-lang="powershell"><span style="color:#080;font-style:italic"># 将 v1.23.0 替换为你希望的版本</span>
curl.exe -Lo C:\k\kubeadm.exe https<span style="">:</span>//dl.k8s.io/<span style="color:#a2f">/bin/windows/amd64/kubeadm.exe
</code></pre></div></li>
</ol>
<!--
### Drain the node

1.  From a machine with access to the Kubernetes API,
    prepare the node for maintenance by marking it unschedulable and evicting the workloads:

    ```shell
    # replace <node-to-drain> with the name of your node you are draining
    kubectl drain <node-to-drain> -ignore-daemonsets
    ```

    You should see output similar to this:

    ```
    node/ip-172-31-85-18 cordoned
    node/ip-172-31-85-18 drained
    ```
-->
<h3 id="drain-the-node">腾空节点  </h3>
<ol>
<li>
<p>在一个能访问到 Kubernetes API 的机器上，将 Windows 节点标记为不可调度并
驱逐其上的所有负载，以便准备节点维护操作：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#080;font-style:italic"># 将 &lt;要腾空的节点&gt; 替换为你要腾空的节点的名称</span>
kubectl drain &lt;要腾空的节点&gt; -ignore-daemonsets
</code></pre></div><p>你应该会看到类似下面的输出：</p>
<pre><code>node/ip-172-31-85-18 cordoned
node/ip-172-31-85-18 drained
</code></pre></li>
</ol>
<!--
### Upgrade the kubelet configuration

1.  From the Windows node, call the following command to sync new kubelet configuration:

    ```powershell
    kubeadm upgrade node
    ```
-->
<h3 id="upgrade-the-kubelet-configuration">升级 kubelet 配置  </h3>
<ol>
<li>
<p>在 Windows 节点上，执行下面的命令来同步新的 kubelet 配置：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-powershell" data-lang="powershell">kubeadm upgrade node
</code></pre></div></li>
</ol>
<!--
### Upgrade kubelet

1.  From the Windows node, upgrade and restart the kubelet:

    ```powershell
    stop-service kubelet
    curl.exe -Lo C:\k\kubelet.exe https://dl.k8s.io/v1.23.0/bin/windows/amd64/kubelet.exe
    restart-service kubelet
    ```
-->
<h3 id="upgrade-kubelet">升级 kubelet  </h3>
<ol>
<li>
<p>在 Windows 节点上升级并重启 kubelet：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-powershell" data-lang="powershell"><span style="color:#a2f">stop-service</span> kubelet
curl.exe -Lo C:\k\kubelet.exe https<span style="">:</span>//dl.k8s.io/<span style="color:#a2f">/bin/windows/amd64/kubelet.exe
<span style="color:#a2f">restart-service</span> kubelet
</code></pre></div></li>
</ol>
<!--
### Uncordon the node

1.  From a machine with access to the Kubernetes API,
bring the node back online by marking it schedulable:

    ```shell
    # replace <node-to-drain> with the name of your node
    kubectl uncordon <node-to-drain>
    ```
-->
<h3 id="uncordon-the-node">对节点执行 uncordon 操作  </h3>
<ol>
<li>
<p>从一台能够访问到 Kubernetes API 的机器上，通过将节点标记为可调度，使之
重新上线：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#080;font-style:italic"># 将 &lt;要腾空的节点&gt; 替换为你的节点名称</span>
kubectl uncordon &lt;要腾空的节点&gt;
</code></pre></div></li>
</ol>
<!--
### Upgrade kube-proxy

1. From a machine with access to the Kubernetes API, run the following,
again replacing v1.23.0 with your desired version:

    ```shell
    curl -L https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/kube-proxy.yml | sed 's/VERSION/v1.23.0/g' | kubectl apply -f -
    ```
-->
<h3 id="upgrade-kube-proxy">升级 kube-proxy  </h3>
<ol>
<li>
<p>在一台可访问 Kubernetes API 的机器上和，将 v1.23.0 替换成你
期望的版本后再次执行下面的命令：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">curl -L https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/kube-proxy.yml | sed <span style="color:#b44">&#39;s/VERSION/v1.23.0/g&#39;</span> | kubectl apply -f -
</code></pre></div></li>
</ol>

</div>



    
	
  



          </main>
        </div>
      </div>
      
<footer class="d-print-none">
  <div class="footer__links">
    <nav>
      
      
      
      <a class="text-white" href="/zh/docs/home/">主页</a>
      
      <a class="text-white" href="/zh/blog/">博客</a>
      
      <a class="text-white" href="/zh/training/">培训</a>
      
      <a class="text-white" href="/zh/partners/">合作伙伴</a>
      
      <a class="text-white" href="/zh/community/">社区</a>
      
      <a class="text-white" href="/zh/case-studies/">案例分析</a>
      
    </nav>
  </div>
  <div class="container-fluid">
    <div class="row">
      <div class="col-6 col-sm-2 text-xs-center order-sm-2">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="User mailing list" aria-label="User mailing list">
    <a class="text-white" target="_blank" href="https://discuss.kubernetes.io">
      <i class="fa fa-envelope"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Twitter" aria-label="Twitter">
    <a class="text-white" target="_blank" href="https://twitter.com/kubernetesio">
      <i class="fab fa-twitter"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Calendar" aria-label="Calendar">
    <a class="text-white" target="_blank" href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io">
      <i class="fas fa-calendar-alt"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Youtube" aria-label="Youtube">
    <a class="text-white" target="_blank" href="https://youtube.com/kubernetescommunity">
      <i class="fab fa-youtube"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-6 col-sm-2 text-right text-xs-center order-sm-3">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="GitHub" aria-label="GitHub">
    <a class="text-white" target="_blank" href="https://github.com/kubernetes/kubernetes">
      <i class="fab fa-github"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Slack" aria-label="Slack">
    <a class="text-white" target="_blank" href="https://slack.k8s.io">
      <i class="fab fa-slack"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Contribute" aria-label="Contribute">
    <a class="text-white" target="_blank" href="https://git.k8s.io/community/contributors/guide">
      <i class="fas fa-edit"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Stack Overflow" aria-label="Stack Overflow">
    <a class="text-white" target="_blank" href="https://stackoverflow.com/questions/tagged/kubernetes">
      <i class="fab fa-stack-overflow"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-12 col-sm-8 text-center order-sm-2">
        <small class="text-white">&copy; 2024 The Kubernetes Authors | Documentation Distributed under <a href="https://git.k8s.io/website/LICENSE" class="light-text">CC BY 4.0</a></small>
        <br/>
        <small class="text-white">Copyright &copy; 2024 The Linux Foundation &reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href="https://www.linuxfoundation.org/trademark-usage" class="light-text">Trademark Usage page</a></small>
        <br/>
        <small class="text-white">ICP license: 京ICP备17074266号-3</small>
        
        
          
        
      </div>
    </div>
  </div>
</footer>


    </div>
    
<script src="/js/popper-1.14.3.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="/js/bootstrap-4.3.1.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>










<script src="/js/main.js"></script>






  </body>
</html>
